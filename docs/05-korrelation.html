<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Kapitel 5 Korrelationsanalyse | Einführung in die Statistik</title>
  <meta name="description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Kapitel 5 Korrelationsanalyse | Einführung in die Statistik" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="github-repo" content="krueger-t/eids" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kapitel 5 Korrelationsanalyse | Einführung in die Statistik" />
  
  <meta name="twitter:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  

<meta name="author" content="Tobias Krueger" />


<meta name="date" content="2021-11-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="04-streuung.html"/>
<link rel="next" href="06-wahrscheinlichkeit.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Einführung in die Statistik</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="part"><span><b>Grundlagen</b></span></li>
<li class="chapter" data-level="1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a><ul>
<li class="chapter" data-level="1.1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#statistik-im-empirischen-forschungsprozess"><i class="fa fa-check"></i><b>1.1</b> Statistik im empirischen Forschungsprozess</a></li>
<li class="chapter" data-level="1.2" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#warum-statistik"><i class="fa fa-check"></i><b>1.2</b> Warum Statistik?</a></li>
<li class="chapter" data-level="1.3" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#mathematische-notation-und-grundlagen"><i class="fa fa-check"></i><b>1.3</b> Mathematische Notation und Grundlagen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-begriffe.html"><a href="02-begriffe.html"><i class="fa fa-check"></i><b>2</b> Grundbegriffe und Datenerhebung</a><ul>
<li class="chapter" data-level="2.1" data-path="02-begriffe.html"><a href="02-begriffe.html#statistische-grundbegriffe"><i class="fa fa-check"></i><b>2.1</b> Statistische Grundbegriffe</a></li>
<li class="chapter" data-level="2.2" data-path="02-begriffe.html"><a href="02-begriffe.html#datenerhebung"><i class="fa fa-check"></i><b>2.2</b> Datenerhebung</a></li>
<li class="chapter" data-level="2.3" data-path="02-begriffe.html"><a href="02-begriffe.html#skalenniveaus"><i class="fa fa-check"></i><b>2.3</b> Skalenniveaus</a></li>
</ul></li>
<li class="part"><span><b>Deskriptive Statistik</b></span></li>
<li class="chapter" data-level="3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html"><i class="fa fa-check"></i><b>3</b> Häufigkeiten und Lageparameter</a><ul>
<li class="chapter" data-level="3.1" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#ziel-der-deskriptiven-statistik"><i class="fa fa-check"></i><b>3.1</b> Ziel der deskriptiven Statistik</a></li>
<li class="chapter" data-level="3.2" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#häufigkeiten"><i class="fa fa-check"></i><b>3.2</b> Häufigkeiten</a></li>
<li class="chapter" data-level="3.3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#lageparameter"><i class="fa fa-check"></i><b>3.3</b> Lageparameter</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-streuung.html"><a href="04-streuung.html"><i class="fa fa-check"></i><b>4</b> Streuungsparameter, Schiefe und Wölbung</a><ul>
<li class="chapter" data-level="4.1" data-path="04-streuung.html"><a href="04-streuung.html#streuungsparameter"><i class="fa fa-check"></i><b>4.1</b> Streuungsparameter</a></li>
<li class="chapter" data-level="4.2" data-path="04-streuung.html"><a href="04-streuung.html#schiefe-und-wölbung-von-häufigkeitsverteilungen"><i class="fa fa-check"></i><b>4.2</b> Schiefe und Wölbung von Häufigkeitsverteilungen</a></li>
<li class="chapter" data-level="4.3" data-path="04-streuung.html"><a href="04-streuung.html#standardisierung-z-transformation"><i class="fa fa-check"></i><b>4.3</b> Standardisierung (z-Transformation)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-korrelation.html"><a href="05-korrelation.html"><i class="fa fa-check"></i><b>5</b> Korrelationsanalyse</a><ul>
<li class="chapter" data-level="5.1" data-path="05-korrelation.html"><a href="05-korrelation.html#nominalskalierte-merkmale-kontingenztabelle-und-chi-quadrat-statistik"><i class="fa fa-check"></i><b>5.1</b> Nominalskalierte Merkmale: Kontingenztabelle und Chi-Quadrat Statistik</a></li>
<li class="chapter" data-level="5.2" data-path="05-korrelation.html"><a href="05-korrelation.html#ordinalskalierte-merkmale-rangkorrelationskoeffizient-nach-spearman"><i class="fa fa-check"></i><b>5.2</b> Ordinalskalierte Merkmale: Rangkorrelationskoeffizient nach Spearman</a></li>
<li class="chapter" data-level="5.3" data-path="05-korrelation.html"><a href="05-korrelation.html#metrische-merkmale-scatterplot-streudiagramm-und-korrelationskoeffizient-nach-bravais-pearson"><i class="fa fa-check"></i><b>5.3</b> Metrische Merkmale: Scatterplot (Streudiagramm) und Korrelationskoeffizient nach Bravais-Pearson</a></li>
</ul></li>
<li class="part"><span><b>Wahrscheinlichkeitstheorie</b></span></li>
<li class="chapter" data-level="6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html"><i class="fa fa-check"></i><b>6</b> Grundlagen der Wahrscheinlichkeitsrechnung</a><ul>
<li class="chapter" data-level="6.1" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvorgänge"><i class="fa fa-check"></i><b>6.1</b> Zufallsvorgänge</a></li>
<li class="chapter" data-level="6.2" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#ereignisse"><i class="fa fa-check"></i><b>6.2</b> Ereignisse</a></li>
<li class="chapter" data-level="6.3" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvariablen"><i class="fa fa-check"></i><b>6.3</b> Zufallsvariablen</a></li>
<li class="chapter" data-level="6.4" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#wahrscheinlichkeit-1"><i class="fa fa-check"></i><b>6.4</b> Wahrscheinlichkeit</a></li>
<li class="chapter" data-level="6.5" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#axiome-der-wahrscheinlichkeitstheorie-nach-kolmogorow"><i class="fa fa-check"></i><b>6.5</b> Axiome der Wahrscheinlichkeitstheorie nach Kolmogorow</a></li>
<li class="chapter" data-level="6.6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#rechenregeln"><i class="fa fa-check"></i><b>6.6</b> Rechenregeln</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="07-verteilungen.html"><a href="07-verteilungen.html"><i class="fa fa-check"></i><b>7</b> Verteilungen</a><ul>
<li class="chapter" data-level="7.1" data-path="07-verteilungen.html"><a href="07-verteilungen.html#von-der-empirischen-zur-theoretischen-verteilung"><i class="fa fa-check"></i><b>7.1</b> Von der empirischen zur theoretischen Verteilung</a></li>
<li class="chapter" data-level="7.2" data-path="07-verteilungen.html"><a href="07-verteilungen.html#parameter-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.2</b> Parameter theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.3" data-path="07-verteilungen.html"><a href="07-verteilungen.html#kenngrößen-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.3</b> Kenngrößen theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.4" data-path="07-verteilungen.html"><a href="07-verteilungen.html#distr"><i class="fa fa-check"></i><b>7.4</b> Wichtige Verteilungen und ihre Anwendungen</a></li>
</ul></li>
<li class="part"><span><b>Induktive Statistik</b></span></li>
<li class="chapter" data-level="8" data-path="08-schaetzen.html"><a href="08-schaetzen.html"><i class="fa fa-check"></i><b>8</b> Schätzen von Verteilungsparametern</a><ul>
<li class="chapter" data-level="8.1" data-path="08-schaetzen.html"><a href="08-schaetzen.html#anforderungen-an-schätzer"><i class="fa fa-check"></i><b>8.1</b> Anforderungen an Schätzer</a></li>
<li class="chapter" data-level="8.2" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-mu"><i class="fa fa-check"></i><b>8.2</b> Normalverteilung: Schätzer für <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-sigma"><i class="fa fa-check"></i><b>8.3</b> Normalverteilung: Schätzer für <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="08-schaetzen.html"><a href="08-schaetzen.html#qqplot"><i class="fa fa-check"></i><b>8.4</b> Quantil-Quantil-Diagramm (QQ-Plot)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-tests.html"><a href="09-tests.html"><i class="fa fa-check"></i><b>9</b> Statistische Tests</a><ul>
<li class="chapter" data-level="9.1" data-path="09-tests.html"><a href="09-tests.html#grundprinzipien-statistischer-tests"><i class="fa fa-check"></i><b>9.1</b> Grundprinzipien statistischer Tests</a></li>
<li class="chapter" data-level="9.2" data-path="09-tests.html"><a href="09-tests.html#ttest"><i class="fa fa-check"></i><b>9.2</b> t-Test (Vergleich von Mittelwerten)</a></li>
<li class="chapter" data-level="9.3" data-path="09-tests.html"><a href="09-tests.html#interpretation-des-p-wertes"><i class="fa fa-check"></i><b>9.3</b> Interpretation des p-Wertes</a></li>
<li class="chapter" data-level="9.4" data-path="09-tests.html"><a href="09-tests.html#ftest"><i class="fa fa-check"></i><b>9.4</b> F-Test (Vergleich von Varianzen)</a></li>
<li class="chapter" data-level="9.5" data-path="09-tests.html"><a href="09-tests.html#kstest"><i class="fa fa-check"></i><b>9.5</b> Verteilungstest (Kolmogorow-Smirnow-Test)</a></li>
<li class="chapter" data-level="9.6" data-path="09-tests.html"><a href="09-tests.html#chi2test"><i class="fa fa-check"></i><b>9.6</b> Unabhängigkeitstest (Chi-Quadrat-Test)</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-regression.html"><a href="10-regression.html"><i class="fa fa-check"></i><b>10</b> Lineare Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="10-regression.html"><a href="10-regression.html#definitionen"><i class="fa fa-check"></i><b>10.1</b> Definitionen</a></li>
<li class="chapter" data-level="10.2" data-path="10-regression.html"><a href="10-regression.html#beschreibung-vs.-vorhersage"><i class="fa fa-check"></i><b>10.2</b> Beschreibung vs. Vorhersage</a></li>
<li class="chapter" data-level="10.3" data-path="10-regression.html"><a href="10-regression.html#ausblick-weiterführende-lineare-modelle"><i class="fa fa-check"></i><b>10.3</b> Ausblick: Weiterführende lineare Modelle</a></li>
<li class="chapter" data-level="10.4" data-path="10-regression.html"><a href="10-regression.html#lineare-regression"><i class="fa fa-check"></i><b>10.4</b> Lineare Regression</a></li>
<li class="chapter" data-level="10.5" data-path="10-regression.html"><a href="10-regression.html#signifikanz-der-regression"><i class="fa fa-check"></i><b>10.5</b> Signifikanz der Regression</a></li>
<li class="chapter" data-level="10.6" data-path="10-regression.html"><a href="10-regression.html#konfidenzintervalle-und-signifikanz-der-parameter"><i class="fa fa-check"></i><b>10.6</b> Konfidenzintervalle und Signifikanz der Parameter</a></li>
<li class="chapter" data-level="10.7" data-path="10-regression.html"><a href="10-regression.html#güte-der-modellanpassung"><i class="fa fa-check"></i><b>10.7</b> Güte der Modellanpassung</a></li>
</ul></li>
<li class="appendix"><span><b>Referenzen</b></span></li>
<li class="chapter" data-level="" data-path="11-refs.html"><a href="11-refs.html"><i class="fa fa-check"></i>Literatur</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Einführung in die Statistik</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="korrelation" class="section level1">
<h1><span class="header-section-number">Kapitel 5</span> Korrelationsanalyse</h1>
<p>Lesen Sie hierzu bitte Kapitel 3.4.2 von <span class="citation">Zimmermann-Janschitz (<a href="#ref-zimmermann2014" role="doc-biblioref">2014</a>)</span>. Die Fragen, die uns besonders interessieren sind:</p>
<ul>
<li><em>Gibt es einen Zusammenhang zwischen zwei Merkmalen?</em></li>
<li><em>Wenn ja, wie kann dieser Zusammenhang charakterisiert werden?</em></li>
<li><em>Wie stark ist der Zusammenhang zwischen den Merkmalen?</em></li>
<li><em>Wie kann man den Zusammenhang visualisieren?</em></li>
</ul>
<p>Die Verfahren sind unterschiedlich für nominalskalierte, ordinalskalierte und metrische Merkmale. Wir werden diese jetzt nacheinander einführen. Die Themen können Sie in <span class="citation">Mittag (<a href="#ref-mittag2016" role="doc-biblioref">2016</a>)</span>, Kapitel 8 und 9 vertiefen.</p>
<div id="nominalskalierte-merkmale-kontingenztabelle-und-chi-quadrat-statistik" class="section level2">
<h2><span class="header-section-number">5.1</span> Nominalskalierte Merkmale: Kontingenztabelle und Chi-Quadrat Statistik</h2>
<p>Wir wollen diese Methode am Beispiel des Volksentscheids Tegel von 2017 verdeutlichen.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Der Beschlussentwurf lautete:</p>
<blockquote>
<p>“Der Flughafen Berlin-Tegel „Otto-Lilienthal“ ergänzt und entlastet den geplanten Flughafen Berlin Brandenburg „Willy Brandt“ (BER). Der Berliner Senat wird aufgefordert, sofort die Schließungsabsichten aufzugeben und alle Maßnahmen einzuleiten, die erforderlich sind, um den unbefristeten Fortbetrieb des Flughafens Tegel als Verkehrsflughafen zu sichern!”</p>
</blockquote>
<p>Wir stellen uns die Frage: <em>Gibt es einen Zusammenhang zwischen Abstimmungsverhalten und Bezirk?</em> Man könnte meinen, dass Anwohner:innen in der Einflugschneise von Tegel eher für “nein” stimmten (d.h. für die Schließung), Anwohner:innen in der Einflugschneise des neuen BER dagegen eher für “ja” (d.h. gegen die Schließung). Überlegungen wie diese motivieren unsere Fragestellung.</p>
<p>Die <strong>Kontingenztabelle</strong> (oder Kreuztabelle) zu diesem Beispiel finden Sie in Abbildung <a href="05-korrelation.html#fig:tegelh">5.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tegelh"></span>
<img src="figs/tegel_h.png" alt="Kontingenztabelle zum Abstimmungsverhalten im Volksentscheid Tegel 2017 nach Bezirk. &lt;br&gt;&lt;small&gt; Quelle: https://www.wahlen-berlin.de/wahlen/BU2017/afspraes/ve/index.html. &lt;/small&gt;" width="85%" />
<p class="caption">
Abbildung 5.1: Kontingenztabelle zum Abstimmungsverhalten im Volksentscheid Tegel 2017 nach Bezirk. <br><small> Quelle: <a href="https://www.wahlen-berlin.de/wahlen/BU2017/afspraes/ve/index.html" class="uri">https://www.wahlen-berlin.de/wahlen/BU2017/afspraes/ve/index.html</a>. </small>
</p>
</div>
<p>In dieser Tabelle stehen absolute Häufigkeiten (vgl. Kapitel <a href="03-haeufigkeit.html#haeufigkeit">3</a>) für alle Kombinationen von Merkmalsausprägungen der Variablen <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span>. <span class="math inline">\(X\)</span> bezeichnet “Bezirk” mit den Ausprägungen <span class="math inline">\(a_1, a_2, \ldots, a_n\)</span>. <span class="math inline">\(Y\)</span> bezeichnet “Abstimmungsverhalten” mit den Ausprägungen <span class="math inline">\(b_1\)</span> (“ja”) und <span class="math inline">\(b_2\)</span> (“nein”). Die Spalten- bzw. Zeilensummen sind die sogenannten Randverteilungen von <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span>. Ganz unten rechts steht der Stichprobenumfang (die Anzahl der Personen, die abgestimmt haben). Der Stichprobenumfang kann sowohl als Summe der Randverteilungswerte von <span class="math inline">\(X\)</span>, als auch als Summe der Randverteilungswerte von <span class="math inline">\(Y\)</span> errechnet werden.</p>
<p>Die allgemeine Notation der absoluten Häufigkeiten einer Kontingenztabelle finden Sie in Abbildung <a href="05-korrelation.html#fig:cth">5.2</a>. In dieser Notation stehen <span class="math inline">\(h_{\cdot j}\)</span> und <span class="math inline">\(h_{i \cdot}\)</span> für die Werte der beiden Randverteilungen.</p>
<div class="figure" style="text-align: center"><span id="fig:cth"></span>
<img src="figs/ct_h.png" alt="Notation der absoluten Häufigkeiten in einer Kontingenztabelle. &lt;br&gt;&lt;small&gt; Nach: @mittag2016. &lt;/small&gt;" width="60%" />
<p class="caption">
Abbildung 5.2: Notation der absoluten Häufigkeiten in einer Kontingenztabelle. <br><small> Nach: <span class="citation">Mittag (<a href="#ref-mittag2016" role="doc-biblioref">2016</a>)</span>. </small>
</p>
</div>
<p>Wir können die Kontingenztabelle für dieses Beispiel auch mit relativen Häufigkeiten darstellen (Abbildung <a href="05-korrelation.html#fig:tegelf">5.3</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:tegelf"></span>
<img src="figs/tegel_f.png" alt="Kontingenztabelle zum Abstimmungsverhalten im Volksentscheid Tegel mit relativen Häufigkeiten." width="85%" />
<p class="caption">
Abbildung 5.3: Kontingenztabelle zum Abstimmungsverhalten im Volksentscheid Tegel mit relativen Häufigkeiten.
</p>
</div>
<p>Als nächstes müssen wir den Begriff der <strong>bedingten relativen Häufigkeit</strong> einführen. Die bedingte relative Häufigkeit ist die Häufigkeit einer Ausprägung des einen Merkmals relativ zur Häufigkeit einer bestimmten Ausprägung des zweiten Merkmals, d.h. “bedingt” dadurch, dass wir uns auf eine Ausprägung des zweiten Merkmals festlegen. Relative Häufigkeiten existieren somit in zwei “Richtungen” in einer Kontingenztabelle (Abbildung <a href="05-korrelation.html#fig:ctf">5.4</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:ctf"></span>
<img src="figs/ct_fy.png" alt="Illustration relativer Häufigkeiten in einer Kontingenztabelle. Links: Absolute Häufigkeiten der Ausprägungen von $Y$ unter der Bedingung $X=a_i$. Rechts: Absolute Häufigkeiten der Ausprägungen von $X$ unter der Bedingung $Y=b_j$. &lt;br&gt;&lt;small&gt; Nach: @mittag2016. &lt;/small&gt;" width="50%" /><img src="figs/ct_fx.png" alt="Illustration relativer Häufigkeiten in einer Kontingenztabelle. Links: Absolute Häufigkeiten der Ausprägungen von $Y$ unter der Bedingung $X=a_i$. Rechts: Absolute Häufigkeiten der Ausprägungen von $X$ unter der Bedingung $Y=b_j$. &lt;br&gt;&lt;small&gt; Nach: @mittag2016. &lt;/small&gt;" width="50%" />
<p class="caption">
Abbildung 5.4: Illustration relativer Häufigkeiten in einer Kontingenztabelle. Links: Absolute Häufigkeiten der Ausprägungen von <span class="math inline">\(Y\)</span> unter der Bedingung <span class="math inline">\(X=a_i\)</span>. Rechts: Absolute Häufigkeiten der Ausprägungen von <span class="math inline">\(X\)</span> unter der Bedingung <span class="math inline">\(Y=b_j\)</span>. <br><small> Nach: <span class="citation">Mittag (<a href="#ref-mittag2016" role="doc-biblioref">2016</a>)</span>. </small>
</p>
</div>
<center>
Die Formeln dazu sind:
</center>
<p><span class="math display">\[f_Y\left(b_j|a_i\right)=\frac{h_{ij}}{h_{i\cdot}}\quad \text{mit}\quad j=1, 2, \ldots, m\]</span>
<span class="math inline">\(f_Y\left(b_j|a_i\right)\)</span> steht für die relative Häufigkeit einer Merkmalsausprägung <span class="math inline">\(b_j\)</span> von <span class="math inline">\(Y\)</span>, bedingt durch eine bestimme Ausprägung <span class="math inline">\(a_i\)</span> von <span class="math inline">\(X\)</span>. Die Bedingtheit wird mit dem Zeichen <span class="math inline">\(|\)</span> ausgedrückt.</p>
<center>
Und weiterhin:
</center>
<p><span class="math display">\[f_X\left(a_i|b_j\right)=\frac{h_{ij}}{h_{\cdot j}}\quad \text{mit}\quad i=1, 2, \ldots, k\]</span>
<span class="math inline">\(f_X\left(a_i|b_j\right)\)</span> steht für die relative Häufigkeit einer Merkmalsausprägung <span class="math inline">\(a_i\)</span> von <span class="math inline">\(X\)</span>, bedingt durch eine bestimme Ausprägung <span class="math inline">\(b_j\)</span> von <span class="math inline">\(Y\)</span>.</p>
<blockquote>
<p><strong>Beispiel: </strong></p>
<p>Die relative Häufigkeit von “ja” unter der Bedingung “Charlottenburg-Wilmersdorf” ist (vgl. <a href="05-korrelation.html#fig:tegelh">5.1</a>):
<span class="math display">\[f_Y\left(b_1|a_4\right)=\frac{h_{41}}{h_{4\cdot}}=\frac{109799}{158471}=0.69\]</span>
D.h. 69% der Stimmen in Charlottenburg-Wilmersdorf waren “ja” Stimmen.</p>
<p>Die relative Häufigkeit von “Charlottenburg-Wilmersdorf” unter der Bedingung “ja” dagegen ist:
<span class="math display">\[f_X\left(a_4|b_1\right)=\frac{h_{41}}{h_{\cdot 1}}=\frac{109799}{994916}=0.11\]</span>
D.h. 11% der “ja” Stimmen kamen aus Charlottenburg-Wilmersdorf.</p>
</blockquote>
<p><em>Was hat das alles mit dem Zusammenhang zwischen Abstimmungsverhalten und Bezirk zu tun?</em></p>
<p>Die bedingten relativen Häufigkeiten helfen uns, etwas über die Abhängigkeit bzw. Unabhängigkeit der beiden Merkmale zu sagen. Das läuft über das Konzept der <strong>empirischen Unabhängigkeit</strong>:</p>
<p>Intuitiv werden wir <strong>Unabhängigkeit</strong> von <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> als gegeben ansehen, wenn die Ausprägung eines Merkmals keinen Einfluss auf die Ausprägung des anderen Merkmals hat.
Dies bedeutet, dass eine bedingte Häufigkeitsverteilung für ein Merkmal nicht davon abhängt, welche Merkmalsausprägung für das andere Merkmal als Bedingung vorausgesetzt wird. D.h. der Anteil von Charlottenburg-Wilmersdorf an den “ja” Stimmen sollte etwa so groß sein wie der Anteil von Charlottenburg-Wilmersdorf an den “nein” Stimmen. Bzw. der Anteil der “ja” Stimmen in Charlottenburg-Wilmersdorf sollte etwa so groß sein wie der Anteil der “ja” Stimmen in jedem anderen Bezirk.</p>
<center>
<p>In Formeln ausgedrückt heißt das:
<span class="math display">\[f_X\left(a_i|b_1\right)=f_X\left(a_i|b_2\right)=\cdots=f_X\left(a_i|b_m\right)\]</span></p>
<p>Bzw.:
<span class="math display">\[\frac{h_{i1}}{h_{\cdot 1}}=\frac{h_{i2}}{h_{\cdot 2}}=\cdots=\frac{h_{im}}{h_{\cdot m}}=\frac{h_{i\cdot}}{n}\]</span></p>
<p>Allgemein formuliert:
<span class="math display">\[\frac{h_{ij}}{h_{\cdot j}}=\frac{h_{i\cdot}}{n}\]</span></p>
Das Umstellen dieser Gleichung nach <span class="math inline">\(h_{ij}\)</span> ergibt:
</center>
<p><span class="math display">\[h_{ij}=\frac{h_{i\cdot}\cdot h_{\cdot j}}{n}:=\tilde h_{ij}\]</span>
Diese absolute Häufigkeit, die wir mit <span class="math inline">\(\tilde h_{ij}\)</span> bezeichnen, ist die <em>bei empirischer Unabhängigkeit erwartete absolute Häufigkeit</em>. Das Zeichen <span class="math inline">\(:=\)</span> bedeutet “wird definiert als”. Wir haben uns also mit Hilfe der relativen Häufigkeiten in der Kontingenztabelle und unserer Konzeption der empirischen Unabhängigkeit neue, bei Unabhängigkeit erwartete absolute Häufigkeiten an jeder Stelle der Kontingenztabelle generiert. Diese können wir jetzt mit den tatsächlichen absoluten Häufigkeiten in der Kontingenztabelle vergleichen (Abbildung <a href="05-korrelation.html#fig:ctvergleich">5.5</a>). Sind die Abweichungen <em>klein</em> können wir von <strong>Unabhängigkeit</strong> der Merkmale ausgehen. Sind die Abweichungen <em>groß</em> können wir von <strong>Abhängigkeit</strong> ausgehen.</p>
<div class="figure" style="text-align: center"><span id="fig:ctvergleich"></span>
<img src="figs/ct_vergleich.png" alt="Vergleich der beobachteten absoluten Häufigkeiten $h_{ij}$ und der bei empirischer Unabhängigkeit erwarteten absoluten Häufigkeiten $\tilde h_{ij}$." width="85%" />
<p class="caption">
Abbildung 5.5: Vergleich der beobachteten absoluten Häufigkeiten <span class="math inline">\(h_{ij}\)</span> und der bei empirischer Unabhängigkeit erwarteten absoluten Häufigkeiten <span class="math inline">\(\tilde h_{ij}\)</span>.
</p>
</div>
<p>Als Vergleichsmaß wird die sogenannte <strong>Chi-Quadrat Statistik</strong> <span class="math inline">\(\mathcal{X}^2\)</span> (oder quadratische Kontingenz) verwendet, und das ist dann auch unser <strong>Zusammenhangsmaß für nominalskalierte Merkmale</strong>. <span class="math inline">\(\mathcal{X}^2\)</span> ergibt sich aus der Differenz der tatsächlichen Häufigkeiten <span class="math inline">\(h_{ij}\)</span> und den erwarteten Häufigkeiten bei empirischer Unabhängigkeit <span class="math inline">\(\tilde h_{ij}\)</span>:
<span class="math display">\[\mathcal{X}^2=\sum_{i=1}^{k}\sum_{j=1}^{m}\frac{\left(h_{ij}-\tilde h_{ij}\right)^2}{\tilde h_{ij}}\]</span></p>
<p>Bei Unabhängigkeit der Merkmale ist <span class="math inline">\(\mathcal{X}^2=0\)</span>. Bei vollständiger Abhängigkeit ist <span class="math inline">\(\mathcal{X}^2=\mathcal{X}_{max}^2\)</span>, wobei <span class="math inline">\(\mathcal{X}_{max}^2=n\cdot(M-1)\)</span> mit <span class="math inline">\(M=\min(k;m)\)</span>. D.h. der maximal mögliche Wert der <span class="math inline">\(\mathcal{X}^2\)</span> Statistik ergibt sich durch die Dimensionen der Kontingenztabelle, die Zeilenanzahl <span class="math inline">\(k\)</span> und die Spaltenanzahl <span class="math inline">\(m\)</span>. Dadurch können wir leider die Größenordnung der <span class="math inline">\(\mathcal{X}^2\)</span> Statistik schlecht intuitiv einordnen, was unser Beispiel verdeutlicht:</p>
<blockquote>
<p>Für den Volksentscheid Tegel ergibt sich ein Wert von <span class="math inline">\(\mathcal{X}^2=49895.1\)</span>, wobei <span class="math inline">\(\mathcal{X}_{max}^2=1732940\)</span>. Da <span class="math inline">\(\mathcal{X}^2\)</span> näher an <span class="math inline">\(0\)</span> ist als an <span class="math inline">\(1 732 940\)</span>, scheint die Abhängigkeit der Merkmale “Bezirk” und “Abstimmungsverhalten” gering zu sein. Ob sie dennoch <em>statistisch signifikant</em> ist können wir erst mit einem sogenannten <strong>Chi-Quadrat-Test</strong> beurteilen, den wir als Teil der schließenden Statistik in Kapitel <a href="09-tests.html#chi2test">9.6</a> kennenlernen.</p>
</blockquote>
</div>
<div id="ordinalskalierte-merkmale-rangkorrelationskoeffizient-nach-spearman" class="section level2">
<h2><span class="header-section-number">5.2</span> Ordinalskalierte Merkmale: Rangkorrelationskoeffizient nach Spearman</h2>
<p>Hier ist das Beispiel des Zusammenhangs von Grünflächenanteil und Bildungsgrad in Stadbezirken aus <span class="citation">Zimmermann-Janschitz (<a href="#ref-zimmermann2014" role="doc-biblioref">2014</a>)</span>, Kapitel 3.4.2, S. 274 - 278 sehr anschaulich. Das Merkmal “Grünflächenanteil” ist zwar metrisch skaliert, muss aber ordinal skaliert werden, um es mit dem Merkmal “Bildungsgrad” vergleichbar zu machen, das bereits ordinal vorliegt; siehe Tabelle 3.36 in <span class="citation">Zimmermann-Janschitz (<a href="#ref-zimmermann2014" role="doc-biblioref">2014</a>)</span>, S. 277.</p>
<p>Der <strong>Rangkorrelationskoeffizient nach Spearman</strong> <span class="math inline">\(r_s\)</span> für <span class="math inline">\(n\)</span> Wertepaare <span class="math inline">\(\left(x_i,y_i\right)\)</span> mit <span class="math inline">\(i=1, 2, \ldots, n\)</span> wird dann berechnet durch:
<span class="math display">\[r_s=1-\frac{6\cdot\sum_{i=1}^{n}d_i^2}{n\cdot\left(n^2-1\right)}\]</span>
Wobei <span class="math inline">\(d_i\)</span> die Differenz der Ränge der beiden Merkmale <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> ist.</p>
<p>Bei perfekter negativer Rangkorrelation ist <span class="math inline">\(r_s=-1\)</span>.</p>
<p>Bei perfekter positiver Rangkorrelation ist <span class="math inline">\(r_s=1\)</span>.</p>
<p>Wenn keine Rangkorrelation vorliegt ist <span class="math inline">\(r_s=0\)</span>.</p>
<p>Bei dem Grünflächenanteil/Bildungsgrad Beispiel von <span class="citation">Zimmermann-Janschitz (<a href="#ref-zimmermann2014" role="doc-biblioref">2014</a>)</span> ist <span class="math inline">\(r_s=0.84\)</span>, die beiden Merkmale sind also stark positiv korreliert. D.h. größere Anteile von Grünflächen sind tendenziell mit höheren Bildungsgraden assoziiert und kleinere Anteile von Grünflächen sind tendenziell mit geringeren Bildungsgraden assoziiert. <em>Überlegen Sie gerne, in welche Richtung hier die Kausalität wirkt.</em></p>
</div>
<div id="metrische-merkmale-scatterplot-streudiagramm-und-korrelationskoeffizient-nach-bravais-pearson" class="section level2">
<h2><span class="header-section-number">5.3</span> Metrische Merkmale: Scatterplot (Streudiagramm) und Korrelationskoeffizient nach Bravais-Pearson</h2>
<p>An dieser Stelle können wir zu unseren Reisedaten zurückkehren. Beide Merkmale (“Distanz” und “Zeit”) sind metrisch skaliert und somit können wir den <strong>Korrelationskoeffizienten nach Bravais-Pearson</strong> verwenden, der mehr Informationen über den Zusammenhang, nämlich <strong>Linearität</strong>, liefert. Einen ersten Eindruck verschafft der <strong>Scatterplot</strong> (auch Streudiagramm), den wir einfach mit der <code>plot()</code> Funktion in <em>R</em> generieren:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="05-korrelation.html#cb32-1"></a><span class="kw">plot</span>(reisedat<span class="op">$</span>distanz, reisedat<span class="op">$</span>zeit, </span>
<span id="cb32-2"><a href="05-korrelation.html#cb32-2"></a>     <span class="dt">xlab =</span> <span class="st">&quot;Entfernung (km)&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Reisezeit (min)&quot;</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-19-1.png" width="80%" /></p>
<p>An dieser Stelle fällt das Wertepaar <span class="math inline">\((16, 126)\)</span> oben, links der Mitte auf. Hierbei handelt es sich wahrscheinlich um eine Person, die eine vergleichsweise lange Strecke mit dem Fahrrad gefahren ist.</p>
<p><strong>Aufgabe:</strong> <em>Überlegen Sie kurz, wie stark die Korrelation hier sein wird! (Auflösung weiter unten.) Überlegen Sie außerdem, woher die Streuung in “Reisezeit” kommen könnte.</em></p>
<p>Die <em>lineare</em> Korrelation zweier metrischer Merkmale wird üblicherweise mit dem Produkt-Moment-<strong>Korrelationskoeffizient nach Bravais-Pearson</strong> <span class="math inline">\(r_{x,y}\)</span> für <span class="math inline">\(n\)</span> Wertepaare <span class="math inline">\(\left(x_i,y_i\right)\)</span> mit <span class="math inline">\(i=1, 2, \ldots, n\)</span> berechnet. Er ergibt sich aus den Standardabweichungen <span class="math inline">\(s_x\)</span> und <span class="math inline">\(s_y\)</span> und der standardisierten Kovarianz <span class="math inline">\(s_{x,y}\)</span> durch:
<span class="math display">\[r_{x,y}=\frac{s_{x,y}}{s_x\cdot s_y}=\frac{\frac{1}{n-1}\cdot\sum_{i=1}^{n}\left(x_i-\bar x\right)\cdot\left(y_i-\bar y\right)}{\sqrt{\frac{1}{n-1}\cdot\sum_{i=1}^{n}\left(x_i-\bar x\right)^2}\cdot\sqrt{\frac{1}{n-1}\cdot\sum_{i=1}^{n}\left(y_i-\bar y\right)^2}}\]</span></p>
<p>In <em>R</em> mit der <code>cor()</code> Funktion:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="05-korrelation.html#cb33-1"></a><span class="kw">cor</span>(reisedat<span class="op">$</span>distanz, reisedat<span class="op">$</span>zeit, <span class="dt">use =</span> <span class="st">&quot;complete.obs&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 0.7543</code></pre>
<p>Das Argument <code>use = "complete.obs"</code> teilt R mit, nur vollständige Datenpaare zu verwenden, d.h. ohne “NA”, ansonsten wäre der Output “NA”. Da hier nur vollständige Datenpaare vorhanden sind, ist das Argument nur vorsorglich gesetzt. Anstatt <code>method = "pearson"</code> sind ebenfalls <code>method = "spearman"</code> und <code>method = "kendall"</code> möglich; beides sind Rangkorrelationskoeffizienten.</p>
<p>In Abbildung <a href="05-korrelation.html#fig:pearson">5.6</a> sehen Sie Werte des Korrelationskoeffizienten für verschiedene Zusammenhänge. Bei augenscheinlich nicht-linearen Zusammenhängen wählt man üblicherweise einen Rangkorrelationskoeffizienten, der dann aussagekräftiger ist.</p>
<div class="figure" style="text-align: center"><span id="fig:pearson"></span>
<img src="figs/pearson.png" alt="Werte des Korrelationskoeffizienten für verschiedene Zusammenhänge. &lt;br&gt;&lt;small&gt; Quelle: https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Correlation_examples.png/440px-Correlation_examples.png. &lt;/small&gt;" width="80%" />
<p class="caption">
Abbildung 5.6: Werte des Korrelationskoeffizienten für verschiedene Zusammenhänge. <br><small> Quelle: <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Correlation_examples.png/440px-Correlation_examples.png" class="uri">https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Correlation_examples.png/440px-Correlation_examples.png</a>. </small>
</p>
</div>

</div>
</div>



<h3>Literatur</h3>
<div id="refs" class="references">
<div id="ref-mittag2016">
<p>Mittag, H. J. 2016. <em>Statistik (4. Auflage)</em>. Berlin: Springer Spektrum.</p>
</div>
<div id="ref-zimmermann2014">
<p>Zimmermann-Janschitz, S. 2014. <em>Statistik in Der Geographie</em>. Berlin: Springer Spektrum.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Die Daten sind <a href="https://www.wahlen-berlin.de/wahlen/BU2017/afspraes/ve/index.html" class="uri">https://www.wahlen-berlin.de/wahlen/BU2017/afspraes/ve/index.html</a> entnommen.<a href="05-korrelation.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="04-streuung.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="06-wahrscheinlichkeit.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
