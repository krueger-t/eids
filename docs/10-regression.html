<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Kapitel 10 Lineare Regression | Einführung in die Statistik</title>
  <meta name="description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Kapitel 10 Lineare Regression | Einführung in die Statistik" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="github-repo" content="krueger-t/eids" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kapitel 10 Lineare Regression | Einführung in die Statistik" />
  
  <meta name="twitter:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  

<meta name="author" content="Tobias Krueger" />


<meta name="date" content="2023-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="09-tests.html"/>
<link rel="next" href="11-refs.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Einführung in die Statistik</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="part"><span><b>Grundlagen</b></span></li>
<li class="chapter" data-level="1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a>
<ul>
<li class="chapter" data-level="1.1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#statistik-im-empirischen-forschungsprozess"><i class="fa fa-check"></i><b>1.1</b> Statistik im empirischen Forschungsprozess</a></li>
<li class="chapter" data-level="1.2" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#warum-statistik"><i class="fa fa-check"></i><b>1.2</b> Warum Statistik?</a></li>
<li class="chapter" data-level="1.3" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#mathematische-notation-und-grundlagen"><i class="fa fa-check"></i><b>1.3</b> Mathematische Notation und Grundlagen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-begriffe.html"><a href="02-begriffe.html"><i class="fa fa-check"></i><b>2</b> Grundbegriffe und Datenerhebung</a>
<ul>
<li class="chapter" data-level="2.1" data-path="02-begriffe.html"><a href="02-begriffe.html#statistische-grundbegriffe"><i class="fa fa-check"></i><b>2.1</b> Statistische Grundbegriffe</a></li>
<li class="chapter" data-level="2.2" data-path="02-begriffe.html"><a href="02-begriffe.html#datenerhebung"><i class="fa fa-check"></i><b>2.2</b> Datenerhebung</a></li>
<li class="chapter" data-level="2.3" data-path="02-begriffe.html"><a href="02-begriffe.html#skalenniveaus"><i class="fa fa-check"></i><b>2.3</b> Skalenniveaus</a></li>
</ul></li>
<li class="part"><span><b>Deskriptive Statistik</b></span></li>
<li class="chapter" data-level="3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html"><i class="fa fa-check"></i><b>3</b> Häufigkeiten und Lageparameter</a>
<ul>
<li class="chapter" data-level="3.1" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#ziel-der-deskriptiven-statistik"><i class="fa fa-check"></i><b>3.1</b> Ziel der deskriptiven Statistik</a></li>
<li class="chapter" data-level="3.2" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#häufigkeiten"><i class="fa fa-check"></i><b>3.2</b> Häufigkeiten</a></li>
<li class="chapter" data-level="3.3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#lageparameter"><i class="fa fa-check"></i><b>3.3</b> Lageparameter</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-streuung.html"><a href="04-streuung.html"><i class="fa fa-check"></i><b>4</b> Streuungsparameter, Schiefe und Wölbung</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-streuung.html"><a href="04-streuung.html#streuungsparameter"><i class="fa fa-check"></i><b>4.1</b> Streuungsparameter</a></li>
<li class="chapter" data-level="4.2" data-path="04-streuung.html"><a href="04-streuung.html#schiefe-und-wölbung-von-häufigkeitsverteilungen"><i class="fa fa-check"></i><b>4.2</b> Schiefe und Wölbung von Häufigkeitsverteilungen</a></li>
<li class="chapter" data-level="4.3" data-path="04-streuung.html"><a href="04-streuung.html#standardisierung-z-transformation"><i class="fa fa-check"></i><b>4.3</b> Standardisierung (z-Transformation)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-korrelation.html"><a href="05-korrelation.html"><i class="fa fa-check"></i><b>5</b> Korrelationsanalyse</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-korrelation.html"><a href="05-korrelation.html#nominalskalierte-merkmale-kontingenztabelle-und-chi-quadrat-statistik"><i class="fa fa-check"></i><b>5.1</b> Nominalskalierte Merkmale: Kontingenztabelle und Chi-Quadrat Statistik</a></li>
<li class="chapter" data-level="5.2" data-path="05-korrelation.html"><a href="05-korrelation.html#ordinalskalierte-merkmale-rangkorrelationskoeffizient-nach-spearman"><i class="fa fa-check"></i><b>5.2</b> Ordinalskalierte Merkmale: Rangkorrelationskoeffizient nach Spearman</a></li>
<li class="chapter" data-level="5.3" data-path="05-korrelation.html"><a href="05-korrelation.html#metrische-merkmale-scatterplot-streudiagramm-und-korrelationskoeffizient-nach-bravais-pearson"><i class="fa fa-check"></i><b>5.3</b> Metrische Merkmale: Scatterplot (Streudiagramm) und Korrelationskoeffizient nach Bravais-Pearson</a></li>
</ul></li>
<li class="part"><span><b>Wahrscheinlichkeitstheorie</b></span></li>
<li class="chapter" data-level="6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html"><i class="fa fa-check"></i><b>6</b> Grundlagen der Wahrscheinlichkeitsrechnung</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvorgänge"><i class="fa fa-check"></i><b>6.1</b> Zufallsvorgänge</a></li>
<li class="chapter" data-level="6.2" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#ereignisse"><i class="fa fa-check"></i><b>6.2</b> Ereignisse</a></li>
<li class="chapter" data-level="6.3" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvariablen"><i class="fa fa-check"></i><b>6.3</b> Zufallsvariablen</a></li>
<li class="chapter" data-level="6.4" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#wahrscheinlichkeit-1"><i class="fa fa-check"></i><b>6.4</b> Wahrscheinlichkeit</a></li>
<li class="chapter" data-level="6.5" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#axiome-der-wahrscheinlichkeitstheorie-nach-kolmogorow"><i class="fa fa-check"></i><b>6.5</b> Axiome der Wahrscheinlichkeitstheorie nach Kolmogorow</a></li>
<li class="chapter" data-level="6.6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#rechenregeln"><i class="fa fa-check"></i><b>6.6</b> Rechenregeln</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="07-verteilungen.html"><a href="07-verteilungen.html"><i class="fa fa-check"></i><b>7</b> Verteilungen</a>
<ul>
<li class="chapter" data-level="7.1" data-path="07-verteilungen.html"><a href="07-verteilungen.html#von-der-empirischen-zur-theoretischen-verteilung"><i class="fa fa-check"></i><b>7.1</b> Von der empirischen zur theoretischen Verteilung</a></li>
<li class="chapter" data-level="7.2" data-path="07-verteilungen.html"><a href="07-verteilungen.html#parameter-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.2</b> Parameter theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.3" data-path="07-verteilungen.html"><a href="07-verteilungen.html#kenngrößen-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.3</b> Kenngrößen theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.4" data-path="07-verteilungen.html"><a href="07-verteilungen.html#distr"><i class="fa fa-check"></i><b>7.4</b> Wichtige Verteilungen und ihre Anwendungen</a></li>
</ul></li>
<li class="part"><span><b>Induktive Statistik</b></span></li>
<li class="chapter" data-level="8" data-path="08-schaetzen.html"><a href="08-schaetzen.html"><i class="fa fa-check"></i><b>8</b> Schätzen von Verteilungsparametern</a>
<ul>
<li class="chapter" data-level="8.1" data-path="08-schaetzen.html"><a href="08-schaetzen.html#anforderungen-an-schätzer"><i class="fa fa-check"></i><b>8.1</b> Anforderungen an Schätzer</a></li>
<li class="chapter" data-level="8.2" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-mu"><i class="fa fa-check"></i><b>8.2</b> Normalverteilung: Schätzer für <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-sigma"><i class="fa fa-check"></i><b>8.3</b> Normalverteilung: Schätzer für <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="08-schaetzen.html"><a href="08-schaetzen.html#qqplot"><i class="fa fa-check"></i><b>8.4</b> Quantil-Quantil-Diagramm (QQ-Plot)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-tests.html"><a href="09-tests.html"><i class="fa fa-check"></i><b>9</b> Statistische Tests</a>
<ul>
<li class="chapter" data-level="9.1" data-path="09-tests.html"><a href="09-tests.html#grundprinzipien-statistischer-tests"><i class="fa fa-check"></i><b>9.1</b> Grundprinzipien statistischer Tests</a></li>
<li class="chapter" data-level="9.2" data-path="09-tests.html"><a href="09-tests.html#ttest"><i class="fa fa-check"></i><b>9.2</b> t-Test (Vergleich von Mittelwerten)</a></li>
<li class="chapter" data-level="9.3" data-path="09-tests.html"><a href="09-tests.html#interpretation-des-p-wertes"><i class="fa fa-check"></i><b>9.3</b> Interpretation des p-Wertes</a></li>
<li class="chapter" data-level="9.4" data-path="09-tests.html"><a href="09-tests.html#ftest"><i class="fa fa-check"></i><b>9.4</b> F-Test (Vergleich von Varianzen)</a></li>
<li class="chapter" data-level="9.5" data-path="09-tests.html"><a href="09-tests.html#kstest"><i class="fa fa-check"></i><b>9.5</b> Verteilungstest (Kolmogorow-Smirnow-Test)</a></li>
<li class="chapter" data-level="9.6" data-path="09-tests.html"><a href="09-tests.html#chi2test"><i class="fa fa-check"></i><b>9.6</b> Unabhängigkeitstest (Chi-Quadrat-Test)</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-regression.html"><a href="10-regression.html"><i class="fa fa-check"></i><b>10</b> Lineare Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-regression.html"><a href="10-regression.html#definitionen"><i class="fa fa-check"></i><b>10.1</b> Definitionen</a></li>
<li class="chapter" data-level="10.2" data-path="10-regression.html"><a href="10-regression.html#beschreibung-vs.-vorhersage"><i class="fa fa-check"></i><b>10.2</b> Beschreibung vs. Vorhersage</a></li>
<li class="chapter" data-level="10.3" data-path="10-regression.html"><a href="10-regression.html#ausblick-weiterführende-lineare-modelle"><i class="fa fa-check"></i><b>10.3</b> Ausblick: Weiterführende lineare Modelle</a></li>
<li class="chapter" data-level="10.4" data-path="10-regression.html"><a href="10-regression.html#lineare-regression"><i class="fa fa-check"></i><b>10.4</b> Lineare Regression</a></li>
<li class="chapter" data-level="10.5" data-path="10-regression.html"><a href="10-regression.html#signifikanz-der-regression"><i class="fa fa-check"></i><b>10.5</b> Signifikanz der Regression</a></li>
<li class="chapter" data-level="10.6" data-path="10-regression.html"><a href="10-regression.html#konfidenzintervalle-und-signifikanz-der-parameter"><i class="fa fa-check"></i><b>10.6</b> Konfidenzintervalle und Signifikanz der Parameter</a></li>
<li class="chapter" data-level="10.7" data-path="10-regression.html"><a href="10-regression.html#güte-der-modellanpassung"><i class="fa fa-check"></i><b>10.7</b> Güte der Modellanpassung</a></li>
</ul></li>
<li class="appendix"><span><b>Referenzen</b></span></li>
<li class="chapter" data-level="" data-path="11-refs.html"><a href="11-refs.html"><i class="fa fa-check"></i>Literatur</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Einführung in die Statistik</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Kapitel 10</span> Lineare Regression<a href="10-regression.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Für die lineare Regression kehren wir zu einer Frage aus Kapitel <a href="05-korrelation.html#korrelation">5</a> zurück: <em>Kann man Ihre Anreisezeit nach Adlershof mit der Entfernung zu Ihrem Wohnort statistisch vorhersagen?</em></p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="10-regression.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(reisedat<span class="sc">$</span>distanz, reisedat<span class="sc">$</span>zeit_morgens, </span>
<span id="cb126-2"><a href="10-regression.html#cb126-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Entfernung (km)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Reisezeit, morgens (min)&quot;</span>)</span>
<span id="cb126-3"><a href="10-regression.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(reisedat<span class="sc">$</span>distanz[<span class="dv">13</span>], reisedat<span class="sc">$</span>zeit_morgens[<span class="dv">13</span>], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb126-4"><a href="10-regression.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(reisedat<span class="sc">$</span>distanz[<span class="fu">c</span>(<span class="dv">30</span>,<span class="dv">37</span>,<span class="dv">63</span>,<span class="dv">71</span>)], reisedat<span class="sc">$</span>zeit_morgens[<span class="fu">c</span>(<span class="dv">30</span>,<span class="dv">37</span>,<span class="dv">63</span>,<span class="dv">71</span>)], <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-50-1.png" width="80%" /></p>
<p>Ich erstelle zwei neue Versionen der Daten, wo ich einmal den fraglichen Datenpunkt <span class="math inline">\((14.8, 1.2)\)</span> (oben in rot) und einmal zusätzlich die vier Punkte ganz rechts (oben in blau) rausnehme. Bei ersterem vermute ich eine falsche Dateneingabe in Stunden (statt Minuten). Bei letzteren vermute ich eine Anreise mit dem Auto, die dann nicht unbedingt mit den anderen Datenpunkten für öffentliche Verkehrsmittel (und Fahrrad) zusammenpasst. Ich werde die drei Versionen der Daten dann vergleichen.</p>
<p><img src="eids_files/figure-html/unnamed-chunk-51-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-51-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-51-3.png" width="33%" /></p>
<p>Wir erinnern uns, dass der Korrelationskoeffizient nach Bravais-Pearson aus Kapitel <a href="05-korrelation.html#korrelation">5</a> 0.82 war (für die Originaldaten). Das Ziel ist nun, eine Gerade durch die Punktwolke zu legen, die den <em>Trend</em> beschreibt, so dass der Abstand der Punkte von der Geraden minimal ist.</p>
<p>Es geht um <em>2 Variablen</em> (Merkmale):</p>
<ul>
<li>die <strong>abhängige Variable</strong> <span class="math inline">\(y\)</span> (im Bsp. Reisezeit)</li>
<li>die <strong>unabhängige Variable</strong> <span class="math inline">\(x\)</span> (im Bsp. Entfernung)</li>
</ul>
<p>Die Variablen müssen <em>metrisch</em> skaliert sein.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> Wir wollen das generelle Verhalten von <span class="math inline">\(y\)</span> mit <span class="math inline">\(x\)</span> beschreiben. Eine Gerade stellt dabei das einfachste lineare Modell dar.</p>
<div id="definitionen" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Definitionen<a href="10-regression.html#definitionen" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Im Falle einer einzigen unabhängigen Variable lautet die Gleichung des <strong>linearen Models</strong>:</p>
<p><span class="math display" id="eq:linmodsingle">\[\begin{equation}
y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i \quad \text{mit} \quad i=1,2,\ldots,n
\tag{10.1}
\end{equation}\]</span></p>
<p><span class="math inline">\(y_i\)</span> bezeichnet den Wert der <strong>abhängigen Variable</strong> für Datenpunkt <span class="math inline">\(i\)</span>, und <span class="math inline">\(x_i\)</span> den Wert der <strong>unabhängigen Variable</strong> für Datenpunkt <span class="math inline">\(i\)</span>. Der Parameter <span class="math inline">\(\beta_0\)</span> beschreibt den <strong>Achsenabschnitt</strong> der Geraden, also der Punkt, an dem die Gerade die y-Achse schneidet. Der Parameter <span class="math inline">\(\beta_1\)</span> beschreibt die <strong>Steigung</strong> der Geraden. <span class="math inline">\(\epsilon_i\)</span> stellt das <strong>Residuum</strong> (also den Fehler) für Datenpunkt <span class="math inline">\(i\)</span> dar (Abbildung <a href="10-regression.html#fig:linreg">10.1</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:linreg"></span>
<img src="eids_files/figure-html/linreg-1.png" alt="Lineare Regression: Definitionen." width="672" />
<p class="caption">
Abbildung 10.1: Lineare Regression: Definitionen.
</p>
</div>
</div>
<div id="beschreibung-vs.-vorhersage" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Beschreibung vs. Vorhersage<a href="10-regression.html#beschreibung-vs.-vorhersage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Der primäre Zweck einer Regressionsanalyse ist die Beschreibung (oder Erklärung) der Daten im Sinne einer allgemeinen Beziehung, die sich auf die Grundgesamtheit übertragen lässt, aus der diese Daten entnommen wurden. Da diese Beziehung eine Eigenschaft der Grundgesamtheit ist, sollte sie auch Vorhersagen ermöglichen. Hierbei ist jedoch Vorsicht geboten. Betrachten Sie den Zusammenhang von Jahr und Weltrekordzeit für die in Abbildung <a href="10-regression.html#fig:mile">10.2</a> dargestellten Daten (Meile, Herren). Wenn, wie hier, die Zeit die unabhängige Variable ist, wird die Regression zu einer Form der Trendanalyse, die in diesem Fall eine Abnahme der Rekordzeit mit den Jahren anzeigt. (Die <code>lm()</code> Funktion und ihren Output werden wir weiter unten kennenlernen, hier geht es um die Grafiken.)</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="10-regression.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten laden</span></span>
<span id="cb127-2"><a href="10-regression.html#cb127-2" aria-hidden="true" tabindex="-1"></a>mile <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Mile/data/mile.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb127-3"><a href="10-regression.html#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="co"># lineares Modell an Daten aus 1. Hälfte des 20. Jahrh. anpassen</span></span>
<span id="cb127-4"><a href="10-regression.html#cb127-4" aria-hidden="true" tabindex="-1"></a>mile_fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(seconds <span class="sc">~</span> year, <span class="at">data =</span> mile[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>,])</span>
<span id="cb127-5"><a href="10-regression.html#cb127-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Informationen zu Parameterschätzern extrahieren</span></span>
<span id="cb127-6"><a href="10-regression.html#cb127-6" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mile_fit1))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept) 912.2340   67.90140  13.435 3.615e-08
## year         -0.3439    0.03509  -9.798 9.059e-07</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="10-regression.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lineares Modell an kompletten Datensatz anpassen</span></span>
<span id="cb129-2"><a href="10-regression.html#cb129-2" aria-hidden="true" tabindex="-1"></a>mile_fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(seconds <span class="sc">~</span> year, <span class="at">data =</span> mile)</span>
<span id="cb129-3"><a href="10-regression.html#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mile_fit2))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept) 1006.876     21.532   46.76 1.361e-29
## year          -0.393      0.011  -35.73 3.780e-26</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="10-regression.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Modellanpassung für 1. Hälfte des 20. Jahrh. plotten</span></span>
<span id="cb131-2"><a href="10-regression.html#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>], mile<span class="sc">$</span>seconds[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>],</span>
<span id="cb131-3"><a href="10-regression.html#cb131-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2000</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb131-4"><a href="10-regression.html#cb131-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb131-5"><a href="10-regression.html#cb131-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb131-6"><a href="10-regression.html#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit1), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb131-7"><a href="10-regression.html#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Extrapolation für 2. Hälfte des 20. Jahrh. plotten</span></span>
<span id="cb131-8"><a href="10-regression.html#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year, mile<span class="sc">$</span>seconds,</span>
<span id="cb131-9"><a href="10-regression.html#cb131-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2000</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb131-10"><a href="10-regression.html#cb131-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb131-11"><a href="10-regression.html#cb131-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb131-12"><a href="10-regression.html#cb131-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit1), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb131-13"><a href="10-regression.html#cb131-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Modellanpassung für Gesamtdaten bis 2050 plotten</span></span>
<span id="cb131-14"><a href="10-regression.html#cb131-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year, mile<span class="sc">$</span>seconds,</span>
<span id="cb131-15"><a href="10-regression.html#cb131-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2050</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb131-16"><a href="10-regression.html#cb131-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb131-17"><a href="10-regression.html#cb131-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb131-18"><a href="10-regression.html#cb131-18" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit2), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mile"></span>
<img src="eids_files/figure-html/mile-1.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" /><img src="eids_files/figure-html/mile-2.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" /><img src="eids_files/figure-html/mile-3.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" />
<p class="caption">
Abbildung 10.2: Links: Trend des Weltrekords “Meile, Herren” in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: <span class="citation">Wainer (<a href="#ref-wainer2009" role="doc-biblioref">2009</a>)</span>
</p>
</div>
<p>Wir sehen, dass sich der Weltrekord in der ersten Hälfte des 20. Jahrhunderts linear verbesserte (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, links). Dieser Trend passt auch für die zweite Hälfte des 20. Jahrhunderts bemerkenswert gut (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, Mitte). Wie lange kann sich der Weltrekord jedoch noch mit der gleichen Rate verbessern (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, rechts)?</p>
<p>Dieses Beispiel zeigt deutlich die Anwendbarkeit von Regressionen für Vorhersagen innerhalb bestimmter Grenzen, zeigt jedoch gleichzeitig die Grenzen dieser einfachen Modelle für längere Vorhersagen (z.B. in Zeit und Raum). Im Falle des Weltrekords würden wir erwarten, dass die Verbesserungsrate mit der Zeit abnimmt, d.h. dass die Kurve abflacht, was ein nichtlineares Modell erfordert.</p>
</div>
<div id="ausblick-weiterführende-lineare-modelle" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Ausblick: Weiterführende lineare Modelle<a href="10-regression.html#ausblick-weiterführende-lineare-modelle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Wenn wir über das lineare Modell sprechen, ist die abhängige Variable immer metrisch skaliert, während die unabhängigen Variablen metrisch, nominal/ordinal oder gemischt sein können. Im Prinzip kann jede dieser Varianten mathematisch gleich behandelt werden, d.h. alle können z.B. mit der <code>lm()</code> Funktion in <em>R</em> analysiert werden. Allerdings haben sich historisch gesehen unterschiedliche Bezeichnungen für diese Varianten etabliert, die hier erwähnt werden sollen, um Verwirrung zu vermeiden (Tabellen <a href="10-regression.html#tab:varianten1">10.1</a> und <a href="10-regression.html#tab:varianten2">10.2</a>).</p>
<table>
<caption><span id="tab:varianten1">Tabelle 10.1: </span> Historische Namen für die Varianten des linearen Modells, je nachdem, ob die unabhängigen Variablen metrisch, nominal/ordinal oder gemischt sind. Die abhängige Variable ist immer metrisch skaliert.</caption>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">unabhängige Variable(n)<br>metrisch</th>
<th align="center">unabhängige Variable(n)<br>nominal/ordinal</th>
<th align="center">unabhängige Variable(n)<br>gemischt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Regression</td>
<td align="center">Varianzanalyse<br>(ANOVA)</td>
<td align="center">Kovarianzanalyse<br>(ANCOVA)</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:varianten2">Tabelle 10.2: </span> Historische Namen für Regression, je nachdem, ob wir eine oder mehrere unabhängige Variablen und eine oder mehrere abhängige Variablen haben.</caption>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">1 unabhängige Variable</th>
<th align="center">&gt;1 unabhängige Variable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>1 abhängige Variable</strong></td>
<td align="center">Regression</td>
<td align="center">Multiple Regression</td>
</tr>
<tr class="even">
<td align="center"><strong>&gt;1 abhängige Variable</strong></td>
<td align="center">Multivariate Regression</td>
<td align="center">Multivariate multiple Regression</td>
</tr>
</tbody>
</table>
</div>
<div id="lineare-regression" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Lineare Regression<a href="10-regression.html#lineare-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Wie soll nun die Gerade durch die Punktwolke gelegt werden, d.h. welche Werte sollen Achsenabschnitt <span class="math inline">\(\beta_0\)</span> und Steigung <span class="math inline">\(\beta_1\)</span> annehmen? Typischerweise werden Regressionsprobleme gelöst, indem die Summe der quadratischen Abweichungen zwischen der Regressionsgeraden und den Datenpunkten minimiert wird - die sogenannte <strong>Kleinste-Quadrate-Schätzung</strong>.</p>
<p>Die Summe der quadratischen Abweichungen wird auch als <span class="math inline">\(SSE\)</span> bezeichnet (Sum of Squared Errors). Grafisch gesehen probieren wir in Abbildung <a href="10-regression.html#fig:linreg">10.1</a> verschiedene Geraden mit unterschiedlichen Achsenabschnitten <span class="math inline">\(\beta_0\)</span> und Steigungen <span class="math inline">\(\beta_1\)</span> aus und wählen diejenige, bei der die Summe aller vertikalen Abstände <span class="math inline">\(\epsilon_i\)</span> zum Quadrat am kleinsten ist. Mathematisch ist <span class="math inline">\(SSE\)</span> definiert als:</p>
<p><span class="math display" id="eq:sse">\[\begin{equation}
SSE=\sum_{i=1}^{n}\left(\epsilon_i\right)^2=\sum_{i=1}^{n}\left(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\right)^2
\tag{10.2}
\end{equation}\]</span></p>
<p>Das Residuum <span class="math inline">\(\epsilon_i\)</span> ist also gleich <span class="math inline">\(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\)</span>, dem vertikalen Abstand zwischen Datenpunkt und Regressionsgerade.</p>
<p>Im Fall der linearen Regression kann <span class="math inline">\(SSE\)</span> analytisch minimiert werden, was z.B. bei nichtlinearen Modellen nicht der Fall ist. Analytisch finden wir das Minimum von <span class="math inline">\(SSE\)</span> wo dessen partielle Ableitungen in Bezug auf die beiden Modellparameter beide Null sind: <span class="math inline">\(\frac{\partial SSE}{\partial \beta_0}=0\)</span> und <span class="math inline">\(\frac{\partial SSE}{\partial \beta_1}=0\)</span>. Unter Anwendung der Definition von <span class="math inline">\(SEE\)</span> aus Gleichung <a href="10-regression.html#eq:sse">(10.2)</a> und der Summenregel<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> und der Kettenregel<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>, die Sie noch aus der Schule kennen werden, erhalten wir:</p>
<p><span class="math display" id="eq:sseb0">\[\begin{equation}
\frac{\partial SSE}{\partial \beta_0}=-2 \cdot \sum_{i=1}^{n}\left(y_i-\beta_0-\beta_1 \cdot x_i\right)=0
\tag{10.3}
\end{equation}\]</span>
<span class="math display" id="eq:sseb1">\[\begin{equation}
\frac{\partial SSE}{\partial \beta_1}=-2 \cdot \sum_{i=1}^{n}x_i \cdot \left(y_i-\beta_0-\beta_1 \cdot x_i\right)=0
\tag{10.4}
\end{equation}\]</span></p>
<p>Gleichungen <a href="10-regression.html#eq:sseb0">(10.3)</a> und <a href="10-regression.html#eq:sseb1">(10.4)</a> bilden ein Gleichungssystem mit zwei Gleichungen und zwei Unbekannten, das wir eindeutig lösen können. Zuerst lösen wir Gleichung <a href="10-regression.html#eq:sseb0">(10.3)</a> nach <span class="math inline">\(\beta_0\)</span> auf (nachdem wir durch -2 geteilt haben):</p>
<p><span class="math display" id="eq:b01">\[\begin{equation}
\sum_{i=1}^{n}y_i-n \cdot \beta_0-\beta_1 \cdot \sum_{i=1}^{n}x_i=0
\tag{10.5}
\end{equation}\]</span>
<span class="math display" id="eq:b02">\[\begin{equation}
n \cdot \beta_0=\sum_{i=1}^{n}y_i-\beta_1 \cdot \sum_{i=1}^{n}x_i
\tag{10.6}
\end{equation}\]</span>
<span class="math display" id="eq:b03">\[\begin{equation}
\beta_0=\bar{y}-\beta_1 \cdot \bar{x}
\tag{10.7}
\end{equation}\]</span></p>
<p>Formal sind das jetzt Parameter<em>schätzer</em> (das “Dach”-Symbol bezeichnet Schätzer):
<span class="math display" id="eq:b04">\[\begin{equation}
\hat\beta_0=\bar{y}-\hat\beta_1 \cdot \bar{x}
\tag{10.8}
\end{equation}\]</span></p>
<p>Sodann setzen wir Gleichung <a href="10-regression.html#eq:b04">(10.8)</a> in Gleichung <a href="10-regression.html#eq:sseb1">(10.4)</a> ein (nachdem wir durch -2 geteilt haben):</p>
<p><span class="math display" id="eq:insert1">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\beta_0 \cdot x_i-\beta_1 \cdot x_i^2\right)=0
\tag{10.9}
\end{equation}\]</span>
<span class="math display" id="eq:insert2">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i+\hat\beta_1 \cdot \bar{x} \cdot x_i-\hat\beta_1 \cdot x_i^2\right)=0
\tag{10.10}
\end{equation}\]</span></p>
<p>Schließlich lösen wir Gleichung <a href="10-regression.html#eq:insert2">(10.10)</a> nach <span class="math inline">\(\beta_1\)</span> auf:</p>
<p><span class="math display" id="eq:b11">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i\right)-\hat\beta_1 \cdot \sum_{i=1}^{n}\left(x_i^2-\bar{x} \cdot x_i\right)=0
\tag{10.11}
\end{equation}\]</span>
<span class="math display" id="eq:b12">\[\begin{equation}
\hat\beta_1=\frac{\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i\right)}{\sum_{i=1}^{n}\left(x_i^2-\bar{x} \cdot x_i\right)}
\tag{10.12}
\end{equation}\]</span></p>
<p>Über eine Reihe von Schritten, die ich hier überspringe, erhalten wir:</p>
<p><span class="math display" id="eq:b13">\[\begin{equation}
\hat\beta_1=\frac{SSXY}{SSX}
\tag{10.13}
\end{equation}\]</span></p>
<p><span class="math inline">\(SSX=\sum_{i=1}^{n}\left(x_i-\bar{x}\right)^2\)</span> ist ein Maß für die Varianz der Daten in <span class="math inline">\(x\)</span>-Richtung. <span class="math inline">\(SSXY=\sum_{i=1}^{n}\left(x_i-\bar{x}\right) \cdot \left(y_i-\bar{y}\right)\)</span> ist ein Maß für die Kovarianz der Daten. Es gibt auch <span class="math inline">\(SSY=\sum_{i=1}^{n}\left(y_i-\bar{y}\right)^2\)</span>, das entsprechend ein Maß für die Varianz der Daten in <span class="math inline">\(y\)</span>-Richtung ist. Gleichung <a href="10-regression.html#eq:b13">(10.13)</a> ist eine exakte Lösung für <span class="math inline">\(\hat\beta_1\)</span>.</p>
<p>Wir setzen nun Gleichung <a href="10-regression.html#eq:b13">(10.13)</a> in Gleichung <a href="10-regression.html#eq:b04">(10.8)</a> ein und haben eine exakte Lösung für <span class="math inline">\(\hat\beta_0\)</span>. Berechnen wir nun die Parameter für unsere drei Reisedatenverianten mit der <code>lm()</code> Funktion:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="10-regression.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lineare Regression der Reisedaten</span></span>
<span id="cb132-2"><a href="10-regression.html#cb132-2" aria-hidden="true" tabindex="-1"></a>reise_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(zeit_morgens <span class="sc">~</span> distanz, <span class="at">data =</span> reisedat)</span>
<span id="cb132-3"><a href="10-regression.html#cb132-3" aria-hidden="true" tabindex="-1"></a>reise_fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(zeit_morgens <span class="sc">~</span> distanz, <span class="at">data =</span> reisedat2)</span>
<span id="cb132-4"><a href="10-regression.html#cb132-4" aria-hidden="true" tabindex="-1"></a>reise_fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(zeit_morgens <span class="sc">~</span> distanz, <span class="at">data =</span> reisedat3)</span>
<span id="cb132-5"><a href="10-regression.html#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Informationen über geschätzte Parameterwerte ausgeben</span></span>
<span id="cb132-6"><a href="10-regression.html#cb132-6" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   28.379     2.4808   11.44 4.113e-18
## distanz        1.532     0.1225   12.50 5.029e-20</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="10-regression.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit2))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   29.115     2.2577   12.90 1.309e-20
## distanz        1.527     0.1112   13.74 4.775e-22</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="10-regression.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit3))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   16.045     2.7399   5.856 1.404e-07
## distanz        2.545     0.1833  13.888 8.499e-22</code></pre>
<p>In der ersten Spalte (“Estimate”) dieses Outputs finden Sie die Werte der Parameterschätzer, wobei “(Intercept)” für <span class="math inline">\(\beta_0\)</span> steht und “distanz” (in diesem Fall) für <span class="math inline">\(\beta_1\)</span>. Anhand von <span class="math inline">\(\beta_1\)</span> können wir ablesen, dass sich pro km Entfernung die Reisezeit um 1.5min (bzw. 2.5min) erhöht. Der Achsenabschnitt <span class="math inline">\(\beta_0\)</span> hat keine direkte Entsprechung.<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> Auf die anderen Spalten werden wir weiter unten zu sprechen kommen. Plotten wir nun die so ermittelte Regressionsgeraden <span class="math inline">\(y_i=28.4+1.5\cdot x_i+\epsilon_i\)</span>, <span class="math inline">\(y_i=29.1+1.5\cdot x_i+\epsilon_i\)</span> und <span class="math inline">\(y_i=16.0+2.5\cdot x_i+\epsilon_i\)</span>:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-54-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-54-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-54-3.png" width="33%" /></p>
<p>Wie man sieht, macht das Weglassen des Datenpunktes <span class="math inline">\((14.8, 1.2)\)</span> keinen grossen Unterschied, das Weglassen der vier Punke ganz rechts schon: Die Steigung ist für die übrigen Punkte steiler.</p>
</div>
<div id="signifikanz-der-regression" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Signifikanz der Regression<a href="10-regression.html#signifikanz-der-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nun, da wir Werte für die Regressionsparameter haben, müssen wir uns fragen, ob diese Werte statistisch signifikant sind oder ob sie durch Zufall aus dem (angenommenen) Zufallsprozess der Stichprobenziehung entstanden sein könnten. Dazu testen wir formal, ob die vom Modell erklärte Varianz in den Daten signifikant größer als die nicht erklärte Varianz ist. Das ist ein F-Test-Problem (vgl. Kapitel <a href="09-tests.html#ftest">9.4</a>), das wir über die sogenannte Varianzanalyse (ANOVA) angehen. ANOVA beginnt mit der Erstellung der ANOVA-Tabelle (Tabelle <a href="10-regression.html#tab:anova">10.3</a>). Dies geschieht in <em>R</em> im Hintergrund und wird selten explizit betrachtet; tun wir es hier aber trotzdem, damit wir verstehen was passiert.</p>
<table style="width:100%;">
<caption><span id="tab:anova">Tabelle 10.3: </span> ANOVA-Tabelle der linearen Regression.</caption>
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Varianz-<br>quelle</th>
<th align="center">Quadrat-<br>summe</th>
<th align="center">Freiheits-<br>grad (<span class="math inline">\(df\)</span>)</th>
<th align="center">Varianz</th>
<th align="center">F-Statistik (<span class="math inline">\(F_s\)</span>)</th>
<th align="center">p-Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Regression</td>
<td align="center"><span class="math inline">\(SSR=\\SSY-SSE\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(\frac{SSR}{df_{SSR}}\)</span></td>
<td align="center"><span class="math inline">\(\frac{\frac{SSR}{df_{SSR}}}{s^2}\)</span></td>
<td align="center"><span class="math inline">\(1-F\left(F_s,1,n-2\right)\)</span></td>
</tr>
<tr class="even">
<td align="center">Fehler</td>
<td align="center"><span class="math inline">\(SSE\)</span></td>
<td align="center"><span class="math inline">\(n-2\)</span></td>
<td align="center"><span class="math inline">\(\frac{SSE}{df_{SSE}}=s^2\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Gesamt</td>
<td align="center"><span class="math inline">\(SSY\)</span></td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Schauen wir uns zunächst die zweiten Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> an: <span class="math inline">\(SSY=\sum_{i=1}^{n}\left(y_i-\bar{y}\right)^2\)</span> ist ein Maß für die Gesamtvarianz der Daten (in <span class="math inline">\(y\)</span>-Richtung), d.h. wie stark die Datenpunkte um den Gesamtmittelwert streuen (Abbildung <a href="10-regression.html#fig:ssysse">10.3</a>, links). <span class="math inline">\(SSE=\sum_{i=1}^{n}\left(\epsilon_i\right)^2=\sum_{i=1}^{n}\left(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\right)^2\)</span> ist ein Maß für die Fehlervarianz, d.h. wie stark die Datenpunkte um die Regressionsgerade streuen (Abbildung <a href="10-regression.html#fig:ssysse">10.3</a>, rechts). Das ist die Varianz, die nach der Modellanpassung übrig ist (“nicht erklärt”). <span class="math inline">\(SSR=SSY-SSE\)</span> ist folglich ein Maß für die vom Modell erklärte Varianz.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ssysse"></span>
<img src="eids_files/figure-html/ssysse-1.png" alt="Variation der Datenpunkte um den Mittelwert, zusammengefasst durch $SSY$ (links), und um die Regressionsgerade, zusammengefasst durch $SSE$ (rechts)." width="50%" /><img src="eids_files/figure-html/ssysse-2.png" alt="Variation der Datenpunkte um den Mittelwert, zusammengefasst durch $SSY$ (links), und um die Regressionsgerade, zusammengefasst durch $SSE$ (rechts)." width="50%" />
<p class="caption">
Abbildung 10.3: Variation der Datenpunkte um den Mittelwert, zusammengefasst durch <span class="math inline">\(SSY\)</span> (links), und um die Regressionsgerade, zusammengefasst durch <span class="math inline">\(SSE\)</span> (rechts).
</p>
</div>
<p>In der dritten Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> stehen die Freiheitsgrade der drei Varianzterme. Diese können als Anzahl der Werte in einer Stichprobe, die für die Berechnung der jeweiligen Parameter frei zur Verfügung stehen, verstanden werden (vgl. Kapitel <a href="04-streuung.html#streuung">4</a>): In die Berechnung von <span class="math inline">\(SSY\)</span> geht <span class="math inline">\(\bar y\)</span> ein, für dessen Berechnung die Werte der Stichprobe bereits einmal verwendet wurden; dadurch ist die Anzahl Freiheitsgrade <span class="math inline">\(df_{SSY}=n-1\)</span>. In die Berechnung von <span class="math inline">\(SSE\)</span> gehen <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> ein (Gleichung <a href="10-regression.html#eq:sse">(10.2)</a>), d.h. die Anzahl Freiheitsgrade ist <span class="math inline">\(df_{SSE}=n-2\)</span>. Für <span class="math inline">\(SSR\)</span> gilt dann einfach <span class="math inline">\(df_{SSR}=df_{SSY}-df_{SSE}=1\)</span>. Die Freiheitsgrade werden verwendet, um die Varianzterme in der vierten Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> zu normalisieren, wobei <span class="math inline">\(s^2\)</span> Fehlervarianz genannt wird.</p>
<p>In der fünften Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> finden wir das Verhältnis von zwei Varianzen; Regressionsvarianz über Fehlervarianz. Von einer signifikanten Regression erwarten wir, dass die (durch das Modell erklärte) Regressionsvarianz viel größer ist als die (durch das Modell nicht erklärte) Fehlervarianz. Dies ist ein F-Test Problem, bei dem getestet wird, ob sich die durch das Modell <em>erklärte</em> Varianz <strong>signifikant</strong> von der durch das Modell <em>nicht erklärten</em> Varianz unterscheidet. Das Verhältnis der beiden Varianzen dient als F-Statistik <span class="math inline">\(F_s\)</span> (vgl. Kapitel <a href="09-tests.html#ftest">9.4</a>).</p>
<p>Die sechste Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> gibt dann den p-Wert des F-Tests an, d.h. die Wahrscheinlichkeit, <span class="math inline">\(F_s\)</span> oder einen größeren Wert (d.h. <strong>ein noch besseres Modell</strong>) zufällig zu erhalten, wenn die Nullhypothese <span class="math inline">\(H_0\)</span> wahr ist (vgl. Kapitel <a href="09-tests.html#ftest">9.4</a>). Im Fall der linearen Regression ist <span class="math inline">\(H_0:\frac{SSR}{df_{SSR}}=s^2\)</span>, d.h. die beiden Varianzen sind gleich, und <span class="math inline">\(H_1:\frac{SSR}{df_{SSR}}&gt;s^2\)</span>, d.h. die erklärte Varianz ist größer als die nicht erklärte.</p>
Wie in Kapitel <a href="09-tests.html#ftest">9.4</a> bereits diskutiert folgt <span class="math inline">\(F_s\)</span> einer F-Verteilung unter der Nullhypothese, hier mit den Parametern <span class="math inline">\(1\)</span> und <span class="math inline">\(n-2\)</span> (Abbildung <a href="10-regression.html#fig:fcdf">10.4</a>). Die blaue Linie in Abbildung <a href="10-regression.html#fig:fcdf">10.4</a> markiert einen bestimmten Wert von <span class="math inline">\(F_s\)</span> (hier <span class="math inline">\(8\)</span>) und den entsprechenden Wert der Verteilungsfunktion der F-Verteilung (<span class="math inline">\(F\left(F_s,1,n-2\right)\)</span>). Der p-Wert ist <span class="math inline">\(\Pr\left(Z&gt; F_s\right)=1-F\left(F_s,1,n-2\right)\)</span> und beschreibt die Wahrscheinlichkeit, dieses oder ein größeres Varianzverhältnis zufällig (aufgrund der zufälligen Stichprobenziehung) zu erhalten, selbst wenn die beiden Varianzen tatsächlich gleich sind.
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fcdf"></span>
<img src="eids_files/figure-html/fcdf-1.png" alt="Verteilungsfunktion der F-Verteilung der F-Statistik $F_s$. Blau: Bestimmter Wert für $F_s$ und entsprechender Wert der Verteilungsfunktion." width="80%" />
<p class="caption">
Abbildung 10.4: Verteilungsfunktion der F-Verteilung der F-Statistik <span class="math inline">\(F_s\)</span>. Blau: Bestimmter Wert für <span class="math inline">\(F_s\)</span> und entsprechender Wert der Verteilungsfunktion.
</p>
</div>
<p>Für die Regression der Reisedaten ist der p-Wert wesentlich kleiner als das konventionelle Signifikanzniveau <span class="math inline">\(\alpha=0.01\)</span>, daher lehnen wir die die Nullhypothese ab und bezeichnen die Regression als statistisch signifikant. Schauen wir uns die ANOVA-Tabelle fuer das Beispiel in den drei Datenvarianten an:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="10-regression.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(reise_fit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: zeit_morgens
##           Df Sum Sq Mean Sq F value Pr(&gt;F)    
## distanz    1  27936   27936     156 &lt;2e-16 ***
## Residuals 75  13403     179                   
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="10-regression.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(reise_fit2)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: zeit_morgens
##           Df Sum Sq Mean Sq F value Pr(&gt;F)    
## distanz    1  27751   27751     189 &lt;2e-16 ***
## Residuals 74  10884     147                   
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="10-regression.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(reise_fit3)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: zeit_morgens
##           Df Sum Sq Mean Sq F value Pr(&gt;F)    
## distanz    1  18506   18506     193 &lt;2e-16 ***
## Residuals 70   6716      96                   
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Im Vergleich zu Tabelle <a href="10-regression.html#tab:anova">10.3</a> lässt <em>R</em> die letzte Zeile (<span class="math inline">\(SSY\)</span>) weg und tauscht die Spalten “Quadratsumme” und “Freiheitsgrad”.</p>
</div>
<div id="konfidenzintervalle-und-signifikanz-der-parameter" class="section level2 hasAnchor" number="10.6">
<h2><span class="header-section-number">10.6</span> Konfidenzintervalle und Signifikanz der Parameter<a href="10-regression.html#konfidenzintervalle-und-signifikanz-der-parameter" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Da die Modellanpassung nicht perfekt ist, haben die Parameterschätzer Standardfehler, d.h. sie werden wie andere statistische Kennzahlen als Realisationen eines Zufallsprozesses interpretiert. Das führt uns zu Konfidenzintervallen und t-Tests auf Signifikanz der einzelnen Parameter.</p>
<p>Der <strong>Standardfehlern</strong> für <span class="math inline">\(\hat\beta_0\)</span> ist:
<span class="math display" id="eq:seb0">\[\begin{equation}
s_{\hat\beta_0}=\sqrt{\frac{\sum_{i=1}^{n}x_i^2}{n} \cdot \frac{s^2}{SSX}}
\tag{10.14}
\end{equation}\]</span></p>
<p>Wenn wir diese Formel in ihre einzelnen Teile zerlegen, sehen wir: Je mehr Datenpunkte <span class="math inline">\(n\)</span> wir haben, desto kleiner ist der Standardfehler, d.h. desto mehr Vertrauen haben wir in die Schätzung. Außerdem gilt, je größer die Variation in <span class="math inline">\(x\)</span> (<span class="math inline">\(SSX\)</span>), desto kleiner der Standardfehler. Beide Effekte machen intuitiv Sinn: Je mehr Datenpunkte wir haben und je mehr Ausprägungen von <span class="math inline">\(x\)</span> wir abgedeckt haben, desto sicherer können wir sein, dass unsere Stichprobe aussagekräftig für die Grundgesamtheit ist. Umgekehrt gilt: Je größer die Fehlervarianz <span class="math inline">\(s^2\)</span>, d.h. je kleiner die Erklärungskraft unseres Modells, desto größer der Standardfehler. Und je mehr <span class="math inline">\(x\)</span>-Datenpunkte von Null entfernt sind, d.h. je größer <span class="math inline">\(\sum_{i=1}^{n}x_i^2\)</span>, desto geringer ist unser Vertrauen in den Achsenabschnitt (wo <span class="math inline">\(x=0\)</span> ist) und damit steigt der Standardfehler.</p>
<p>Der Standardfehler für <span class="math inline">\(\hat\beta_1\)</span> ist:
<span class="math display" id="eq:seb1">\[\begin{equation}
s_{\hat\beta_1}=\sqrt{\frac{s^2}{SSX}}
\tag{10.15}
\end{equation}\]</span>
Hier gilt die gleiche Interpretation wie zuvor, außer dass es keinen Einfluss der Größe der <span class="math inline">\(x\)</span>-Datenpunkte gibt.</p>
<p>Wir können auch einen Standardfehler für neue Vorhersagen <span class="math inline">\(\hat y\)</span> für gegebene <span class="math inline">\(\hat x\)</span> festlegen:
<span class="math display" id="eq:sey">\[\begin{equation}
s_{\hat y}=\sqrt{s^2 \cdot \left(\frac{1}{n}+\frac{\left(\hat x-\bar x\right)^2}{SSX}\right)}
\tag{10.16}
\end{equation}\]</span></p>
<p>Dieselbe Interpretation gilt auch hier, nur dass jetzt ein zusätzlicher Term <span class="math inline">\(\left(\hat x-\bar x\right)^2\)</span> auftaucht, der besagt, je weiter der neue <span class="math inline">\(x\)</span>-Wert vom Zentrum der ursprünglichen Daten (den Trainings- oder Kalibrierungsdaten) entfernt ist, desto größer ist der Standardfehler der neuen Vorhersage, d.h. desto geringer ist die Zuversicht, dass sie korrekt ist.</p>
<blockquote>
<p>Anmerkung: Die Formeln für die Standardfehler ergeben sich aus den grundlegenden Annahmen der linearen Regression, auf die wir weiter unten eingehen werden. Die mathematische Herleitung lassen wir hier aus.</p>
</blockquote>
<p>Aus den Standardfehlern können wir <strong>Konfidenzintervalle</strong> für die Parameterschätzer wie folgt berechnen (vgl. Konfidenzintervall des Mittelwertschätzers (Kapitel <a href="08-schaetzen.html#schaetzen">8</a>)):
<span class="math display" id="eq:cib01">\[\begin{equation}
\Pr\left(\hat\beta_0-t_{n-2;0.975} \cdot s_{\hat\beta_0}\leq \beta_0\leq \hat\beta_0+t_{n-2;0.975} \cdot s_{\hat\beta_0}\right)=0.95
\tag{10.17}
\end{equation}\]</span></p>
<p>Gleichung <a href="10-regression.html#eq:cib01">(10.17)</a> ist das zentrale 95%-Konfidenzintervall, in dem der wahre Parameterwert, hier <span class="math inline">\(\beta_0\)</span>, mit einer Wahrscheinlichkeit von 0.95 liegt.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a></p>
<p>Wir können das Intervall auch wie folgt schreiben:
<span class="math display" id="eq:cib02">\[\begin{equation}
KI=\left[\hat\beta_0-t_{n-2;0.975} \cdot s_{\hat\beta_0};\hat\beta_0+t_{n-2;0.975} \cdot s_{\hat\beta_0}\right]
\tag{10.18}
\end{equation}\]</span></p>
<p>Wie bei dem Konfidenzintervall des Mittelwertschätzers (Kapitel <a href="08-schaetzen.html#schaetzen">8</a>) liegt das Konfidenzintervall symmetrisch um den Parameterschätzwert <span class="math inline">\(\hat\beta_0\)</span> und ergibt sich aus einer t-Verteilung mit dem Parameter <span class="math inline">\(n-2\)</span>, deren Breite durch den Standardfehler <span class="math inline">\(s_{\hat\beta_0}\)</span> moduliert wird. Erinnern Sie sich, dass die Breite der t-Verteilung ebenfalls durch den Stichprobenumfang kontrolliert wird und mit zunehmendem <span class="math inline">\(n\)</span> immer schmaler wird.</p>
<p>Die gleichen Formeln gelten für <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(y\)</span>:
<span class="math display" id="eq:cib1">\[\begin{equation}
\Pr\left(\hat\beta_1-t_{n-2;0.975} \cdot s_{\hat\beta_1}\leq \beta_1\leq \hat\beta_1+t_{n-2;0.975} \cdot s_{\hat\beta_1}\right)=0.95
\tag{10.19}
\end{equation}\]</span>
<span class="math display" id="eq:ciy">\[\begin{equation}
\Pr\left(\hat y-t_{n-2;0.975} \cdot s_{\hat y}\leq y\leq \hat y+t_{n-2;0.975} \cdot s_{\hat y}\right)=0.95
\tag{10.20}
\end{equation}\]</span></p>
<p>Die Formeln für die Konfidenzintervalle (Gleichungen <a href="10-regression.html#eq:cib01">(10.17)</a>, <a href="10-regression.html#eq:cib1">(10.19)</a> und <a href="10-regression.html#eq:ciy">(10.20)</a>) ergeben sich aus den Grundannahmen der linearen Regression (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>): Die Residuen sind <em>unabhängig identisch verteilt (u.i.v.)</em> gemäß einer <em>Normalverteilung</em>, d.h. <span class="math inline">\(\epsilon_i\sim N(0,\sigma)\)</span>, und <em>das lineare Modell ist korrekt</em>. Dann lässt sich mathematisch zeigen, dass <span class="math inline">\(\frac{\hat\beta_0-\beta_0}{s_{\hat\beta_0}}\)</span>, <span class="math inline">\(\frac{\hat\beta_1-\beta_1}{s_{\hat\beta_1}}\)</span> und <span class="math inline">\(\frac{\hat y-y}{s_{\hat y}}\)</span> <span class="math inline">\(t_{n-2}\)</span>-verteilt sind (t-Verteilung mit <span class="math inline">\(n-2\)</span> Freiheitsgraden). Da das zentrale 95%-Konfidenzintervall einer <span class="math inline">\(t_{n-2}\)</span>-verteilten Zufallsvariablen <span class="math inline">\(Z\)</span> <span class="math inline">\(\Pr\left(-t_{n-2;0.975}\leq Z\leq t_{n-2;0. 975}\right)=0.95\)</span> ist (Abbildung <a href="08-schaetzen.html#fig:kiz">8.2</a>), können wir jeden der oben genannten drei Terme für <span class="math inline">\(Z\)</span> einsetzen und die Ungleichung umstellen, um zu den Gleichungen <a href="10-regression.html#eq:cib01">(10.17)</a>, <a href="10-regression.html#eq:cib1">(10.19)</a> und <a href="10-regression.html#eq:ciy">(10.20)</a> zu gelangen (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>).</p>
<p>Die Signifikanz der Parameterschätzer wird mit Hilfe eines t-Tests ermittelt (vgl. Kapitel <a href="09-tests.html#ttest">9.2</a>). Die <strong>Nullhypothese</strong> ist, dass die wahren Parameterwerte gleich Null sind, d.h. die Parameterschätzer <em>nicht</em> signifikant sind:
<span class="math display" id="eq:h0b0">\[\begin{equation}
H_0:\beta_0=0
\tag{10.21}
\end{equation}\]</span>
<span class="math display" id="eq:h0b1">\[\begin{equation}
H_0:\beta_1=0
\tag{10.22}
\end{equation}\]</span></p>
<p>Diese Hypothese wird gegen die <strong>Alternativhypothese</strong> getestet, dass die wahren Parameterwerte <em>un</em>gleich Null sind, d.h. dass die Parameterschätzer signifikant sind:
<span class="math display" id="eq:h1b0">\[\begin{equation}
H_1:\beta_0\neq 0
\tag{10.23}
\end{equation}\]</span>
<span class="math display" id="eq:h1b1">\[\begin{equation}
H_1:\beta_1\neq 0
\tag{10.24}
\end{equation}\]</span></p>
<p>Die Teststatistiken sind:
<span class="math display" id="eq:tsb0">\[\begin{equation}
t_s=\frac{\hat\beta_0-0}{s_{\hat\beta_0}}\sim t_{n-2}
\tag{10.25}
\end{equation}\]</span>
<span class="math display" id="eq:tsb1">\[\begin{equation}
t_s=\frac{\hat\beta_1-0}{s_{\hat\beta_1}}\sim t_{n-2}
\tag{10.26}
\end{equation}\]</span></p>
<p>Die t-Verteilungen der Teststatistiken ergeben sich wiederum aus den oben erwähnten Regressionsannahmen. Die Annahmen sind die gleichen wie beim üblichen t-Test der Mittelwerte (Kapitel <a href="09-tests.html#ttest">9.2</a>), außer dass im Fall der linearen Regression die Residuen als u.i.v. normal angenommen werden, während im Fall der Mittelwerte die tatsächlichen Datenpunkte <span class="math inline">\(y\)</span> als u.i.v. normal angenommen werden.</p>
<p>Analog zum üblichen 2-seitigen t-Test ist der p-Wert definiert als:
<span class="math display" id="eq:pv">\[\begin{equation}
2 \cdot \Pr\left(t&gt;|t_s|\right)=2 \cdot \left(1-F_t\left(|t_s|\right)\right)
\tag{10.27}
\end{equation}\]</span></p>
<p>Mit einem konventionellen Signifikanzniveau von <span class="math inline">\(\alpha=0.01\)</span> gelangen wir zu einem kritischen Wert der Teststatistik <span class="math inline">\(t_c=t_{n-2;0.995}\)</span>, bei dessen Überschreitung, bzw. Unterschreitung von <span class="math inline">\(-t_c\)</span>, wir die Nullhypothese ablehnen und die Parameterschätzer als signifikant bezeichnen.</p>
<p>Jetzt verstehen wir auch die restlichen Informationen des Outputs der <code>lm()</code> Funktion (s. oben):</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="10-regression.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   28.379     2.4808   11.44 4.113e-18
## distanz        1.532     0.1225   12.50 5.029e-20</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="10-regression.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit2))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   29.115     2.2577   12.90 1.309e-20
## distanz        1.527     0.1112   13.74 4.775e-22</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="10-regression.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit3))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   16.045     2.7399   5.856 1.404e-07
## distanz        2.545     0.1833  13.888 8.499e-22</code></pre>
<p>Wie bereits oben erwähnt steht die Zeile “(Intercept)” für <span class="math inline">\(\beta_0\)</span> und die Zeile “distanz” (in diesem Fall) für <span class="math inline">\(\beta_1\)</span>. In Spalte “Estimate” stehen die Werte der Parameterschätzer. In Spalte “Std. Error” stehen deren Standardfehler (Gleichungen <a href="10-regression.html#eq:seb0">(10.14)</a> und <a href="10-regression.html#eq:seb1">(10.15)</a>). In Spalte “t value” stehen die entsprechenden Werte der Teststatistik (Gleichungen <a href="10-regression.html#eq:tsb0">(10.25)</a> und <a href="10-regression.html#eq:tsb1">(10.26)</a>). In Spalte “Pr(&gt;|t|)” stehen die p-Werte der t-Tests auf Signifikanz der Parameter (Gleichung <a href="10-regression.html#eq:pv">(10.27)</a>). Wir sehen, dass in unserem Beispiel (für alle drei Datenvarianten) beide Parameter signifikant sind (die p-Werte sind wesentlich kleiner als das konventionelle <span class="math inline">\(\alpha=0.01\)</span>).</p>
</div>
<div id="güte-der-modellanpassung" class="section level2 hasAnchor" number="10.7">
<h2><span class="header-section-number">10.7</span> Güte der Modellanpassung<a href="10-regression.html#güte-der-modellanpassung" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Die Signifikanz der Parameter der Regression ist eine Sache. Wie gut aber ist das Modell im Beschreiben der Daten? D.h. wieviel von der Varianz in den Daten wird vom Modell erklärt? Die Güte der Modellanpassung kann in erster Linie mit dem <strong>Bestimmtheitsmaß</strong> (<span class="math inline">\(r^2\)</span>) begutachtet werden, welches als Anteil der Varianz (in <span class="math inline">\(y\)</span>-Richtung) definiert ist, der durch das Modell erklärt wird:
<span class="math display" id="eq:r2">\[\begin{equation}
r^2=\frac{SSY-SSE}{SSY}=1-\frac{SSE}{SSY}
\tag{10.28}
\end{equation}\]</span>
Das Bestimmtheitsmaß ist der Korrelationskoeffizient nach Bravais-Pearson zum Quadrat (vgl. Kapitel <a href="05-korrelation.html#korrelation">5</a>).</p>
<p>Wie wir an Gleichung <a href="10-regression.html#eq:r2">(10.28)</a> sehen, wenn das Modell nicht mehr Variation als die Gesamtvariation um den Mittelwert erklärt, d.h. <span class="math inline">\(SSE=SSY\)</span> ist, dann ist <span class="math inline">\(r^2=0\)</span>. Umgekehrt, wenn das Modell perfekt zu den Daten passt, d.h. <span class="math inline">\(SSE=0\)</span> ist, dann ist <span class="math inline">\(r^2=1\)</span>. Werte dazwischen stellen unterschiedliche Grade der Anpassungsgüte dar. Das kann wiederum mit Abbildung <a href="10-regression.html#fig:ssysse">10.3</a> veranschaulicht werden, wobei der linke Teil <span class="math inline">\(SSY\)</span> und der rechte Teil <span class="math inline">\(SSE\)</span> verdeutlicht.</p>
<p>Wenn es darum geht, Modelle unterschiedlicher Komplexität (d.h. mit mehr oder weniger Parametern) mit <span class="math inline">\(r^2\)</span> zu vergleichen, dann ist es sinnvoll, das Bestimmtheitsmaß mit der Anzahl der Modellparameter zu korrigieren, da komplexere Modelle (mehr Parameter) automatisch zu besseren Anpassungen führen, einfach aufgrund der größeren Freiheitsgrade, die komplexere Modelle bei der Anpassung der Daten haben. Dies führt zum <strong>korrigierten <span class="math inline">\(r^2\)</span></strong>:
<span class="math display" id="eq:adjr2">\[\begin{equation}
\bar r^2=1-\frac{\frac{SSE}{df_{SSE}}}{\frac{SSY}{df_{SSY}}}=1-\frac{SSE}{SSY} \cdot \frac{df_{SSY}}{df_{SSE}}
\tag{10.29}
\end{equation}\]</span></p>
<p>Rechnen wir <span class="math inline">\(r^2\)</span> und <span class="math inline">\(\bar r^2\)</span> für die Regression der Reisedaten aus:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="10-regression.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.6758</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="10-regression.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6715</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="10-regression.html#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit2)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.7183</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="10-regression.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit2)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.7145</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="10-regression.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit3)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.7337</code></pre>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="10-regression.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reise_fit3)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.7299</code></pre>
<p>D.h. bei der Regression der Originaldaten werden rund 68% der Varianz in den Reisezeit-Daten durch das lineare Modell mit Entfernung als Prädiktor erklärt. Lässt man den fraglichen Datenpunkt <span class="math inline">\((14.8, 1.2)\)</span> weg, vebessert sich die Güte auf 72% - das ist für die Auswirkung eines einzigen Datenpunktes nicht unerheblich. Lässt man ausserdem die weiteren vier Datenpunkte ganz rechts weg dann verbessert sich die Güte geringfügig auf 73%.</p>
<p>Aber was heißt Güte der Modellanpassung? Sind alle Modellannahmen erfüllt? Folgende Annahmen ergeben sich aus der <strong>Maximum-Likelihood-Theorie</strong> (vgl. Schätzen von Verteilungsparametern, Kapitel <a href="08-schaetzen.html#schaetzen">8</a>):</p>
<ul>
<li>Die Residuen sind <strong>unabhängig</strong>, in diesem Fall gibt es keine serielle Korrelation in der Residuengrafik - dies kann mit dem Durbin-Watson-Test getestet werden</li>
<li>Die Residuen sind <strong>normalverteilt</strong> - dies kann visuell mit Hilfe des Quantil-Quantil-Diagramms (QQ-Plot) und dem Residuen-Histogramm beurteilt werden, und kann mit dem Kolmogorov-Smirnov-Test (Kapitel <a href="09-tests.html#kstest">9.5</a>) und dem Shapiro-Wilk-Test getestet werden</li>
<li>Die Varianz ist für alle Residuen konstant (die Residuen sind <strong>homoskedastisch</strong>), d.h. es erfolgt kein “Auffächern” der Residuen</li>
</ul>
<p>Sind diese Annahmen nicht erfüllt, können wir auf Datentransformation, gewichtete Regression oder Generalisierte Lineare Modelle zurückgreifen. Letzteres ist wird im Master <em>Global Change Geography</em> unterrichtet.</p>
<p>Eine erste nützliche diagnostische Darstellung ist die der Residuen in Serie, d.h. nach Index <span class="math inline">\(i\)</span>, um zu sehen, ob es ein Muster aufgrund des Datenerfassungsprozesses gibt. Für unser Beispiel:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-58-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-58-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-58-3.png" width="33%" /></p>
<p>Die Residuen zeigen für keine der Datenvarianten ein erkennbares Muster, das gegen die Unabhängigkeit der Residuen sprechen würde.</p>
<p>Wir sollten auch die Residuen nach dem modellierten Wert von <span class="math inline">\(y\)</span> plotten, um zu sehen, ob es ein Muster als Funktion der Größenordnung von <span class="math inline">\(y\)</span> gibt:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-59-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-59-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-59-3.png" width="33%" /></p>
<p>Hier gibt es jetzt v.a. im ersten und zweite Fall systematische Unter- und Überschätzungen, die gegen eine Linearität des Zusammenhangs sprechen. Lassen wir die vier Datenpunkte ganz rechts weg, passt das lineare Modell besser. Wenn diese vier Datenpunkte tatsächlich einem anderen Transportmodus entstammen, dann wäre das eine plausible Strategie.</p>
<p>Die Annahme, dass die Residuen normalverteilt sind, kann anhand des QQ-Plots beurteilt werden (vgl. Kapitel <a href="08-schaetzen.html#qqplot">8.4</a>):</p>
<p><img src="eids_files/figure-html/unnamed-chunk-60-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-60-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-60-3.png" width="33%" /></p>
<p>Die Residuen zeigen flachere Flanken (“heavier tails”) als die Normalverteilung, zumindest auf der positiven (rechten) Seite. Vgl. <a href="https://xiongge.shinyapps.io/QQplots/" class="uri">https://xiongge.shinyapps.io/QQplots/</a>. Das kann man auch am Histogramm der Residuen sehen, einer weiteren nützlichen Darstellung:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-61-1.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-61-2.png" width="33%" /><img src="eids_files/figure-html/unnamed-chunk-61-3.png" width="33%" /></p>

</div>
</div>



<h3>Literatur<a href="11-refs.html#literatur" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-wainer2009" class="csl-entry">
Wainer, H. 2009. <em>Picturing the Uncertain World</em>. Princeton: Princeton University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="20">
<li id="fn20"><p>Das ist korrekt wenn wir von linearer Regression im engen Sinn sprechen, obwohl Regressionsprobleme mit nominal oder ordinal skalierten unabhängigen Variablen mathematisch identisch sind. Auch Regressionsprobleme mit nominal oder ordinal skalierten <em>abhängigen</em> Variablen sind mathematisch ähnlich. Das wird im Masterstudiengang <em>Global Change Geography</em> gelehrt.<a href="10-regression.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Summenregel: wenn <span class="math inline">\(y=u(t) \pm v(t)\)</span> dann <span class="math inline">\(\frac{dy}{dt}=\frac{du}{dt} \pm \frac{dv}{dt}\)</span><a href="10-regression.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Kettenregel: wenn <span class="math inline">\(y=f[g(t)]\)</span> dann <span class="math inline">\(\frac{dy}{dt}=\frac{df[g]}{dg} \cdot \frac{dg}{dt}\)</span>, d.h. “äußere mal innere Ableitung”<a href="10-regression.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Wenn wir jedoch die unabhängige Variable “distanz” zentrieren würden, d.h. von allen Datenpunkten den Mittelwert abziehen würden, dann ergäbe sich ein Achsenabschnitt, der die Entfernung für die mittlere Entfernung darstellen würde.<a href="10-regression.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Wahrscheinlichkeit heisst hier wieder, dass bei wiederholtem Stichprobenziehen in 95% der Fälle das so konstruierte Konfidenzintervall den wahren Wert <span class="math inline">\(\beta_0\)</span> umschließt und in 5% der Fälle nicht.<a href="10-regression.html#fnref24" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="09-tests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-refs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
