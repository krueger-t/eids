<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Kapitel 10 Lineare Regression | Einführung in die Statistik</title>
  <meta name="description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Kapitel 10 Lineare Regression | Einführung in die Statistik" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="github-repo" content="krueger-t/eids" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kapitel 10 Lineare Regression | Einführung in die Statistik" />
  
  <meta name="twitter:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  

<meta name="author" content="Tobias Krueger" />


<meta name="date" content="2025-01-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="09-tests.html"/>
<link rel="next" href="11-refs.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Einführung in die Statistik</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="part"><span><b>Grundlagen</b></span></li>
<li class="chapter" data-level="1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a>
<ul>
<li class="chapter" data-level="1.1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#statistik-im-empirischen-forschungsprozess"><i class="fa fa-check"></i><b>1.1</b> Statistik im empirischen Forschungsprozess</a></li>
<li class="chapter" data-level="1.2" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#warum-statistik"><i class="fa fa-check"></i><b>1.2</b> Warum Statistik?</a></li>
<li class="chapter" data-level="1.3" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html#mathematische-notation-und-grundlagen"><i class="fa fa-check"></i><b>1.3</b> Mathematische Notation und Grundlagen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-begriffe.html"><a href="02-begriffe.html"><i class="fa fa-check"></i><b>2</b> Grundbegriffe und Datenerhebung</a>
<ul>
<li class="chapter" data-level="2.1" data-path="02-begriffe.html"><a href="02-begriffe.html#statistische-grundbegriffe"><i class="fa fa-check"></i><b>2.1</b> Statistische Grundbegriffe</a></li>
<li class="chapter" data-level="2.2" data-path="02-begriffe.html"><a href="02-begriffe.html#datenerhebung"><i class="fa fa-check"></i><b>2.2</b> Datenerhebung</a></li>
<li class="chapter" data-level="2.3" data-path="02-begriffe.html"><a href="02-begriffe.html#skalenniveaus"><i class="fa fa-check"></i><b>2.3</b> Skalenniveaus</a></li>
</ul></li>
<li class="part"><span><b>Deskriptive Statistik</b></span></li>
<li class="chapter" data-level="3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html"><i class="fa fa-check"></i><b>3</b> Häufigkeiten und Lageparameter</a>
<ul>
<li class="chapter" data-level="3.1" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#ziel-der-deskriptiven-statistik"><i class="fa fa-check"></i><b>3.1</b> Ziel der deskriptiven Statistik</a></li>
<li class="chapter" data-level="3.2" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#häufigkeiten"><i class="fa fa-check"></i><b>3.2</b> Häufigkeiten</a></li>
<li class="chapter" data-level="3.3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html#lageparameter"><i class="fa fa-check"></i><b>3.3</b> Lageparameter</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-streuung.html"><a href="04-streuung.html"><i class="fa fa-check"></i><b>4</b> Streuungsparameter, Schiefe und Wölbung</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-streuung.html"><a href="04-streuung.html#streuungsparameter"><i class="fa fa-check"></i><b>4.1</b> Streuungsparameter</a></li>
<li class="chapter" data-level="4.2" data-path="04-streuung.html"><a href="04-streuung.html#schiefe-und-wölbung-von-häufigkeitsverteilungen"><i class="fa fa-check"></i><b>4.2</b> Schiefe und Wölbung von Häufigkeitsverteilungen</a></li>
<li class="chapter" data-level="4.3" data-path="04-streuung.html"><a href="04-streuung.html#standardisierung-z-transformation"><i class="fa fa-check"></i><b>4.3</b> Standardisierung (z-Transformation)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-korrelation.html"><a href="05-korrelation.html"><i class="fa fa-check"></i><b>5</b> Korrelationsanalyse</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-korrelation.html"><a href="05-korrelation.html#nominalskalierte-merkmale-kontingenztabelle-und-chi-quadrat-statistik"><i class="fa fa-check"></i><b>5.1</b> Nominalskalierte Merkmale: Kontingenztabelle und Chi-Quadrat Statistik</a></li>
<li class="chapter" data-level="5.2" data-path="05-korrelation.html"><a href="05-korrelation.html#ordinalskalierte-merkmale-rangkorrelationskoeffizient-nach-spearman"><i class="fa fa-check"></i><b>5.2</b> Ordinalskalierte Merkmale: Rangkorrelationskoeffizient nach Spearman</a></li>
<li class="chapter" data-level="5.3" data-path="05-korrelation.html"><a href="05-korrelation.html#metrische-merkmale-scatterplot-streudiagramm-und-korrelationskoeffizient-nach-bravais-pearson"><i class="fa fa-check"></i><b>5.3</b> Metrische Merkmale: Scatterplot (Streudiagramm) und Korrelationskoeffizient nach Bravais-Pearson</a></li>
</ul></li>
<li class="part"><span><b>Wahrscheinlichkeitstheorie</b></span></li>
<li class="chapter" data-level="6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html"><i class="fa fa-check"></i><b>6</b> Grundlagen der Wahrscheinlichkeitsrechnung</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvorgänge"><i class="fa fa-check"></i><b>6.1</b> Zufallsvorgänge</a></li>
<li class="chapter" data-level="6.2" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#ereignisse"><i class="fa fa-check"></i><b>6.2</b> Ereignisse</a></li>
<li class="chapter" data-level="6.3" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#zufallsvariablen"><i class="fa fa-check"></i><b>6.3</b> Zufallsvariablen</a></li>
<li class="chapter" data-level="6.4" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#wahrscheinlichkeit-1"><i class="fa fa-check"></i><b>6.4</b> Wahrscheinlichkeit</a></li>
<li class="chapter" data-level="6.5" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#axiome-der-wahrscheinlichkeitstheorie-nach-kolmogorow"><i class="fa fa-check"></i><b>6.5</b> Axiome der Wahrscheinlichkeitstheorie nach Kolmogorow</a></li>
<li class="chapter" data-level="6.6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html#rechenregeln"><i class="fa fa-check"></i><b>6.6</b> Rechenregeln</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="07-verteilungen.html"><a href="07-verteilungen.html"><i class="fa fa-check"></i><b>7</b> Verteilungen</a>
<ul>
<li class="chapter" data-level="7.1" data-path="07-verteilungen.html"><a href="07-verteilungen.html#von-der-empirischen-zur-theoretischen-verteilung"><i class="fa fa-check"></i><b>7.1</b> Von der empirischen zur theoretischen Verteilung</a></li>
<li class="chapter" data-level="7.2" data-path="07-verteilungen.html"><a href="07-verteilungen.html#parameter-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.2</b> Parameter theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.3" data-path="07-verteilungen.html"><a href="07-verteilungen.html#kenngrößen-theoretischer-verteilungen"><i class="fa fa-check"></i><b>7.3</b> Kenngrößen theoretischer Verteilungen</a></li>
<li class="chapter" data-level="7.4" data-path="07-verteilungen.html"><a href="07-verteilungen.html#distr"><i class="fa fa-check"></i><b>7.4</b> Wichtige Verteilungen und ihre Anwendungen</a></li>
</ul></li>
<li class="part"><span><b>Induktive Statistik</b></span></li>
<li class="chapter" data-level="8" data-path="08-schaetzen.html"><a href="08-schaetzen.html"><i class="fa fa-check"></i><b>8</b> Schätzen von Verteilungsparametern</a>
<ul>
<li class="chapter" data-level="8.1" data-path="08-schaetzen.html"><a href="08-schaetzen.html#anforderungen-an-schätzer"><i class="fa fa-check"></i><b>8.1</b> Anforderungen an Schätzer</a></li>
<li class="chapter" data-level="8.2" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-mu"><i class="fa fa-check"></i><b>8.2</b> Normalverteilung: Schätzer für <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="08-schaetzen.html"><a href="08-schaetzen.html#normalverteilung-schätzer-für-sigma"><i class="fa fa-check"></i><b>8.3</b> Normalverteilung: Schätzer für <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="08-schaetzen.html"><a href="08-schaetzen.html#qqplot"><i class="fa fa-check"></i><b>8.4</b> Quantil-Quantil-Diagramm (QQ-Plot)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-tests.html"><a href="09-tests.html"><i class="fa fa-check"></i><b>9</b> Statistische Tests</a>
<ul>
<li class="chapter" data-level="9.1" data-path="09-tests.html"><a href="09-tests.html#grundprinzipien-statistischer-tests"><i class="fa fa-check"></i><b>9.1</b> Grundprinzipien statistischer Tests</a></li>
<li class="chapter" data-level="9.2" data-path="09-tests.html"><a href="09-tests.html#ttest"><i class="fa fa-check"></i><b>9.2</b> t-Test (Vergleich von Mittelwerten)</a></li>
<li class="chapter" data-level="9.3" data-path="09-tests.html"><a href="09-tests.html#interpretation-des-p-wertes"><i class="fa fa-check"></i><b>9.3</b> Interpretation des p-Wertes</a></li>
<li class="chapter" data-level="9.4" data-path="09-tests.html"><a href="09-tests.html#ftest"><i class="fa fa-check"></i><b>9.4</b> F-Test (Vergleich von Varianzen)</a></li>
<li class="chapter" data-level="9.5" data-path="09-tests.html"><a href="09-tests.html#anova"><i class="fa fa-check"></i><b>9.5</b> Varianzanalyse (ANOVA)</a></li>
<li class="chapter" data-level="9.6" data-path="09-tests.html"><a href="09-tests.html#kstest"><i class="fa fa-check"></i><b>9.6</b> Verteilungstest (Kolmogorow-Smirnow-Test)</a></li>
<li class="chapter" data-level="9.7" data-path="09-tests.html"><a href="09-tests.html#chi2test"><i class="fa fa-check"></i><b>9.7</b> Unabhängigkeitstest (Chi-Quadrat-Test)</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-regression.html"><a href="10-regression.html"><i class="fa fa-check"></i><b>10</b> Lineare Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-regression.html"><a href="10-regression.html#definitionen"><i class="fa fa-check"></i><b>10.1</b> Definitionen</a></li>
<li class="chapter" data-level="10.2" data-path="10-regression.html"><a href="10-regression.html#beschreibung-vs.-vorhersage"><i class="fa fa-check"></i><b>10.2</b> Beschreibung vs. Vorhersage</a></li>
<li class="chapter" data-level="10.3" data-path="10-regression.html"><a href="10-regression.html#ausblick-weiterführende-lineare-modelle"><i class="fa fa-check"></i><b>10.3</b> Ausblick: Weiterführende lineare Modelle</a></li>
<li class="chapter" data-level="10.4" data-path="10-regression.html"><a href="10-regression.html#lineare-regression"><i class="fa fa-check"></i><b>10.4</b> Lineare Regression</a></li>
<li class="chapter" data-level="10.5" data-path="10-regression.html"><a href="10-regression.html#erklärte-varianz"><i class="fa fa-check"></i><b>10.5</b> Erklärte Varianz</a></li>
<li class="chapter" data-level="10.6" data-path="10-regression.html"><a href="10-regression.html#konfidenzintervalle-der-parameterschätzer"><i class="fa fa-check"></i><b>10.6</b> Konfidenzintervalle der Parameterschätzer</a></li>
<li class="chapter" data-level="10.7" data-path="10-regression.html"><a href="10-regression.html#annahmen-der-regression"><i class="fa fa-check"></i><b>10.7</b> Annahmen der Regression</a></li>
<li class="chapter" data-level="10.8" data-path="10-regression.html"><a href="10-regression.html#anova_lm"><i class="fa fa-check"></i><b>10.8</b> ANOVA als Regressionsproblem</a></li>
</ul></li>
<li class="appendix"><span><b>Referenzen</b></span></li>
<li class="chapter" data-level="" data-path="11-refs.html"><a href="11-refs.html"><i class="fa fa-check"></i>Literatur</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Einführung in die Statistik</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Kapitel 10</span> Lineare Regression<a href="10-regression.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Für die lineare Regression kehren wir zunächst zu einer Frage aus Kapitel <a href="05-korrelation.html#korrelation">5</a> zurück: <em>Kann man Ihre Anreisezeit nach Adlershof mit der Entfernung zu Ihrem Wohnort statistisch vorhersagen?</em></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="10-regression.html#cb129-1" tabindex="-1"></a><span class="fu">plot</span>(reisedat<span class="sc">$</span>distanz, reisedat<span class="sc">$</span>zeit_morgens, </span>
<span id="cb129-2"><a href="10-regression.html#cb129-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Entfernung (km)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Reisezeit, morgens (min)&quot;</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-53-1.png" width="80%" /></p>
<p>Wir erinnern uns, dass der Korrelationskoeffizient nach Bravais-Pearson aus Kapitel <a href="05-korrelation.html#korrelation">5</a> 0.82 war. Das Ziel ist nun, eine Gerade durch die Punktwolke zu legen, die den <em>Trend</em> beschreibt, so dass der Abstand der Punkte von der Geraden minimal ist.</p>
<p>Es geht um <em>2 Variablen</em> (Merkmale):</p>
<ul>
<li>die <strong>abhängige Variable</strong> <span class="math inline">\(y\)</span> (im Bsp. Reisezeit)</li>
<li>die <strong>unabhängige Variable</strong> <span class="math inline">\(x\)</span> (im Bsp. Entfernung)</li>
</ul>
<p>Die Variablen müssen <em>metrisch</em> skaliert sein. Das ist korrekt wenn wir von linearer Regression im engen Sinn sprechen, obwohl Regressionsprobleme mit nominal oder ordinal skalierten <em>unabhängigen</em> Variablen mathematisch identisch sind. Das werden wir weiter unten, in Kapitel @ref(anova_lm), noch sehen. <a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> Wir wollen das generelle Verhalten von <span class="math inline">\(y\)</span> mit <span class="math inline">\(x\)</span> beschreiben. Eine Gerade stellt dabei das einfachste lineare Modell dar.</p>
<div id="definitionen" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Definitionen<a href="10-regression.html#definitionen" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Im Fall einer einzigen unabhängigen Variable lautet die Gleichung des <strong>linearen Models</strong>:</p>
<p><span class="math display" id="eq:linmodsingle">\[\begin{equation}
y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i \quad \text{mit} \quad i=1,2,\ldots,n
\tag{10.1}
\end{equation}\]</span></p>
<p><span class="math inline">\(y_i\)</span> bezeichnet den Wert der <strong>abhängigen Variable</strong> für Datenpunkt <span class="math inline">\(i\)</span>, und <span class="math inline">\(x_i\)</span> den Wert der <strong>unabhängigen Variable</strong> für Datenpunkt <span class="math inline">\(i\)</span>. Der Parameter <span class="math inline">\(\beta_0\)</span> beschreibt den <strong>Achsenabschnitt</strong> der Geraden, also der Punkt, an dem die Gerade die y-Achse schneidet. Der Parameter <span class="math inline">\(\beta_1\)</span> beschreibt die <strong>Steigung</strong> der Geraden. <span class="math inline">\(\epsilon_i\)</span> stellt das <strong>Residuum</strong> (man sagt auch Fehler) für Datenpunkt <span class="math inline">\(i\)</span> dar (Abbildung <a href="10-regression.html#fig:linreg">10.1</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:linreg"></span>
<img src="eids_files/figure-html/linreg-1.png" alt="Lineare Regression: Definitionen." width="672" />
<p class="caption">
Abbildung 10.1: Lineare Regression: Definitionen.
</p>
</div>
</div>
<div id="beschreibung-vs.-vorhersage" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Beschreibung vs. Vorhersage<a href="10-regression.html#beschreibung-vs.-vorhersage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Der primäre Zweck einer Regressionsanalyse ist die Beschreibung (oder Erklärung) der Daten im Sinn einer allgemeinen Beziehung, die sich auf die Grundgesamtheit übertragen lässt, aus der diese Daten entnommen wurden. Da diese Beziehung eine Eigenschaft der Grundgesamtheit ist, sollte sie auch Vorhersagen ermöglichen. Hierbei ist jedoch Vorsicht geboten. Betrachten Sie den Zusammenhang von Jahr und Weltrekordzeit für die in Abbildung <a href="10-regression.html#fig:mile">10.2</a> dargestellten Daten (“Meile, Herren”). Wenn, wie hier, die Zeit die unabhängige Variable ist, wird die Regression zu einer Form der Trendanalyse, die in diesem Fall eine Abnahme der Rekordzeit mit den Jahren anzeigt. (Die <code>lm()</code> Funktion und ihren Output werden wir weiter unten kennenlernen, hier geht es um die Grafiken.)</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="10-regression.html#cb130-1" tabindex="-1"></a><span class="co"># Daten laden</span></span>
<span id="cb130-2"><a href="10-regression.html#cb130-2" tabindex="-1"></a>mile <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Mile/data/mile.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb130-3"><a href="10-regression.html#cb130-3" tabindex="-1"></a><span class="co"># lineares Modell an Daten aus 1. Hälfte des 20. Jahrh. anpassen</span></span>
<span id="cb130-4"><a href="10-regression.html#cb130-4" tabindex="-1"></a>mile_fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(seconds <span class="sc">~</span> year, <span class="at">data =</span> mile[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>,])</span>
<span id="cb130-5"><a href="10-regression.html#cb130-5" tabindex="-1"></a><span class="co"># Informationen zu Parameterschätzern extrahieren</span></span>
<span id="cb130-6"><a href="10-regression.html#cb130-6" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mile_fit1))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept) 912.2340   67.90140  13.435 3.615e-08
## year         -0.3439    0.03509  -9.798 9.059e-07</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="10-regression.html#cb132-1" tabindex="-1"></a><span class="co"># lineares Modell an kompletten Datensatz anpassen</span></span>
<span id="cb132-2"><a href="10-regression.html#cb132-2" tabindex="-1"></a>mile_fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(seconds <span class="sc">~</span> year, <span class="at">data =</span> mile)</span>
<span id="cb132-3"><a href="10-regression.html#cb132-3" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mile_fit2))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept) 1006.876     21.532   46.76 1.361e-29
## year          -0.393      0.011  -35.73 3.780e-26</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="10-regression.html#cb134-1" tabindex="-1"></a><span class="co"># Modellanpassung für 1. Hälfte des 20. Jahrh. plotten</span></span>
<span id="cb134-2"><a href="10-regression.html#cb134-2" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>], mile<span class="sc">$</span>seconds[mile<span class="sc">$</span>year<span class="sc">&lt;</span><span class="dv">1950</span>],</span>
<span id="cb134-3"><a href="10-regression.html#cb134-3" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2000</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb134-4"><a href="10-regression.html#cb134-4" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb134-5"><a href="10-regression.html#cb134-5" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb134-6"><a href="10-regression.html#cb134-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit1), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb134-7"><a href="10-regression.html#cb134-7" tabindex="-1"></a><span class="co"># Extrapolation für 2. Hälfte des 20. Jahrh. plotten</span></span>
<span id="cb134-8"><a href="10-regression.html#cb134-8" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year, mile<span class="sc">$</span>seconds,</span>
<span id="cb134-9"><a href="10-regression.html#cb134-9" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2000</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb134-10"><a href="10-regression.html#cb134-10" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb134-11"><a href="10-regression.html#cb134-11" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb134-12"><a href="10-regression.html#cb134-12" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit1), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb134-13"><a href="10-regression.html#cb134-13" tabindex="-1"></a><span class="co"># Modellanpassung für Gesamtdaten bis 2050 plotten</span></span>
<span id="cb134-14"><a href="10-regression.html#cb134-14" tabindex="-1"></a><span class="fu">plot</span>(mile<span class="sc">$</span>year, mile<span class="sc">$</span>seconds,</span>
<span id="cb134-15"><a href="10-regression.html#cb134-15" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1900</span>, <span class="dv">2050</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">260</span>),</span>
<span id="cb134-16"><a href="10-regression.html#cb134-16" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">type =</span> <span class="st">&#39;p&#39;</span>,</span>
<span id="cb134-17"><a href="10-regression.html#cb134-17" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weltrekord, Meile, Herren (Sekunden)&quot;</span>)</span>
<span id="cb134-18"><a href="10-regression.html#cb134-18" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(mile_fit2), <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mile"></span>
<img src="eids_files/figure-html/mile-1.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" /><img src="eids_files/figure-html/mile-2.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" /><img src="eids_files/figure-html/mile-3.png" alt="Links: Trend des Weltrekords &quot;Meile, Herren&quot; in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: @wainer2009" width="33%" />
<p class="caption">
Abbildung 10.2: Links: Trend des Weltrekords “Meile, Herren” in der ersten Hälfte des 20. Jahrhunderts (Beschreibung). Mitte: Extrapolation des Trends für die zweite Hälfte des 20. Jahrhunderts (Vorhersage). Rechts: Extrapolation des Trends bis zum Jahr 2050 (längere Vorhersage). Nach: <span class="citation">Wainer (<a href="#ref-wainer2009">2009</a>)</span>
</p>
</div>
<p>Wir sehen, dass sich der Weltrekord in der ersten Hälfte des 20. Jahrhunderts linear verbesserte (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, links). Dieser Trend passt auch für die zweite Hälfte des 20. Jahrhunderts bemerkenswert gut (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, Mitte). Wie lange kann sich der Weltrekord jedoch noch mit der gleichen Rate verbessern (Abbildung <a href="10-regression.html#fig:mile">10.2</a>, rechts)?</p>
<p>Dieses Beispiel zeigt deutlich die Anwendbarkeit von Regressionen für Vorhersagen, zeigt jedoch gleichzeitig die Grenzen dieser einfachen Modelle für längere Vorhersagen (z.B. in Zeit und Raum). Im Fall des Weltrekords würden wir erwarten, dass die Verbesserungsrate mit der Zeit abnimmt, d.h. dass die Kurve abflacht, was ein nichtlineares Modell erfordert.</p>
</div>
<div id="ausblick-weiterführende-lineare-modelle" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Ausblick: Weiterführende lineare Modelle<a href="10-regression.html#ausblick-weiterführende-lineare-modelle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Wenn wir über das lineare Modell sprechen, ist die abhängige Variable immer metrisch skaliert, während die unabhängigen Variablen metrisch, nominal/ordinal oder gemischt sein können. Im Prinzip kann jede dieser Varianten mathematisch gleich behandelt werden, d.h. alle können z.B. mit der <code>lm()</code> Funktion in <em>R</em> analysiert werden. Allerdings haben sich historisch gesehen unterschiedliche Bezeichnungen für diese Varianten etabliert, die hier erwähnt werden sollen, um Verwirrung zu vermeiden (Tabellen <a href="10-regression.html#tab:varianten1">10.1</a> und <a href="10-regression.html#tab:varianten2">10.2</a>). Wie Sie sehen, kann auch die Varianzanalyse (ANOVA) aus Kapitel <a href="09-tests.html#anova">9.5</a> als ein Spezialfall des linearen Modells verstanden werden, worauf wir weiter unten in Kapitel @ref(anova_lm) noch eingehen werden.</p>
<table>
<caption><span id="tab:varianten1">Tabelle 10.1: </span> Historische Namen für die Varianten des linearen Modells, je nachdem, ob die unabhängigen Variablen metrisch, nominal/ordinal oder gemischt sind. Die abhängige Variable ist immer metrisch skaliert.</caption>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">unabhängige Variable(n)<br>metrisch</th>
<th align="center">unabhängige Variable(n)<br>nominal/ordinal</th>
<th align="center">unabhängige Variable(n)<br>gemischt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Regression</td>
<td align="center">Varianzanalyse<br>(ANOVA)</td>
<td align="center">Kovarianzanalyse<br>(ANCOVA)</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:varianten2">Tabelle 10.2: </span> Historische Namen für Regression, je nachdem, ob wir eine oder mehrere unabhängige Variablen und eine oder mehrere abhängige Variablen haben.</caption>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">1 unabhängige Variable</th>
<th align="center">&gt;1 unabhängige Variable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>1 abhängige Variable</strong></td>
<td align="center">Regression</td>
<td align="center">Multiple Regression</td>
</tr>
<tr class="even">
<td align="center"><strong>&gt;1 abhängige Variable</strong></td>
<td align="center">Multivariate Regression</td>
<td align="center">Multivariate multiple Regression</td>
</tr>
</tbody>
</table>
</div>
<div id="lineare-regression" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Lineare Regression<a href="10-regression.html#lineare-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Erstmal zurück zur linearen Regression im engen Sinn. Wie soll die Gerade durch die Punktwolke gelegt werden, d.h. welche Werte sollen Achsenabschnitt <span class="math inline">\(\beta_0\)</span> und Steigung <span class="math inline">\(\beta_1\)</span> annehmen? Typischerweise werden Regressionsprobleme gelöst, indem die Summe der quadratischen Abweichungen zwischen der Regressionsgeraden und den Datenpunkten minimiert wird - die sogenannte <strong>Kleinste-Quadrate-Schätzung</strong>. Die Summe der quadratischen Abweichungen kennen wir schon von der Definition der Varianz (Kapitel <a href="04-streuung.html#streuung">4</a>) und von der ANOVA (Kapitel <a href="09-tests.html#anova">9.5</a>).</p>
<p>Die Summe der quadratischen Abweichungen wird wie gesagt als <span class="math inline">\(SSE\)</span> bezeichnet (Sum of Squared Errors). Grafisch gesehen probieren wir in Abbildung <a href="10-regression.html#fig:linreg">10.1</a> verschiedene Geraden mit unterschiedlichen Achsenabschnitten <span class="math inline">\(\beta_0\)</span> und Steigungen <span class="math inline">\(\beta_1\)</span> aus und wählen diejenige, bei der die Summe aller vertikalen Abstände <span class="math inline">\(\epsilon_i\)</span> zum Quadrat am kleinsten ist. Mathematisch ist <span class="math inline">\(SSE\)</span> in diesem Fall:</p>
<p><span class="math display" id="eq:sse">\[\begin{equation}
SSE=\sum_{i=1}^{n}\left(\epsilon_i\right)^2=\sum_{i=1}^{n}\left(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\right)^2
\tag{10.2}
\end{equation}\]</span></p>
<p>Das Residuum <span class="math inline">\(\epsilon_i\)</span> ist also gleich <span class="math inline">\(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\)</span>, dem vertikalen Abstand zwischen Datenpunkt und Regressionsgerade.</p>
<p>Im Fall der linearen Regression kann <span class="math inline">\(SSE\)</span> analytisch minimiert werden, was z.B. bei nichtlinearen Modellen nicht der Fall ist. Analytisch finden wir das Minimum von <span class="math inline">\(SSE\)</span> wo dessen partielle Ableitungen in Bezug auf die beiden Modellparameter beide Null sind: <span class="math inline">\(\frac{\partial SSE}{\partial \beta_0}=0\)</span> und <span class="math inline">\(\frac{\partial SSE}{\partial \beta_1}=0\)</span>. Unter Anwendung der Definition von <span class="math inline">\(SEE\)</span> aus Gleichung <a href="10-regression.html#eq:sse">(10.2)</a> und der Summenregel<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> und der Kettenregel<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>, die Sie noch aus der Schule kennen werden, erhalten wir:</p>
<p><span class="math display" id="eq:sseb0">\[\begin{equation}
\frac{\partial SSE}{\partial \beta_0}=-2 \cdot \sum_{i=1}^{n}\left(y_i-\beta_0-\beta_1 \cdot x_i\right)=0
\tag{10.3}
\end{equation}\]</span>
<span class="math display" id="eq:sseb1">\[\begin{equation}
\frac{\partial SSE}{\partial \beta_1}=-2 \cdot \sum_{i=1}^{n}x_i \cdot \left(y_i-\beta_0-\beta_1 \cdot x_i\right)=0
\tag{10.4}
\end{equation}\]</span></p>
<p>Gleichungen <a href="10-regression.html#eq:sseb0">(10.3)</a> und <a href="10-regression.html#eq:sseb1">(10.4)</a> bilden ein Gleichungssystem mit zwei Gleichungen und zwei Unbekannten, das wir eindeutig lösen können. Zuerst lösen wir Gleichung <a href="10-regression.html#eq:sseb0">(10.3)</a> nach <span class="math inline">\(\beta_0\)</span> auf (nachdem wir durch -2 geteilt haben):</p>
<p><span class="math display" id="eq:b01">\[\begin{equation}
\sum_{i=1}^{n}y_i-n \cdot \beta_0-\beta_1 \cdot \sum_{i=1}^{n}x_i=0
\tag{10.5}
\end{equation}\]</span>
<span class="math display" id="eq:b02">\[\begin{equation}
n \cdot \beta_0=\sum_{i=1}^{n}y_i-\beta_1 \cdot \sum_{i=1}^{n}x_i
\tag{10.6}
\end{equation}\]</span>
<span class="math display" id="eq:b03">\[\begin{equation}
\beta_0=\bar{y}-\beta_1 \cdot \bar{x}
\tag{10.7}
\end{equation}\]</span></p>
<p>Formal sind das jetzt Parameter<em>schätzer</em> (das “Dach”-Symbol bezeichnet Schätzer):
<span class="math display" id="eq:b04">\[\begin{equation}
\hat\beta_0=\bar{y}-\hat\beta_1 \cdot \bar{x}
\tag{10.8}
\end{equation}\]</span></p>
<p>Sodann setzen wir Gleichung <a href="10-regression.html#eq:b04">(10.8)</a> in Gleichung <a href="10-regression.html#eq:sseb1">(10.4)</a> ein (nachdem wir durch -2 geteilt haben):</p>
<p><span class="math display" id="eq:insert1">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\beta_0 \cdot x_i-\beta_1 \cdot x_i^2\right)=0
\tag{10.9}
\end{equation}\]</span>
<span class="math display" id="eq:insert2">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i+\hat\beta_1 \cdot \bar{x} \cdot x_i-\hat\beta_1 \cdot x_i^2\right)=0
\tag{10.10}
\end{equation}\]</span></p>
<p>Schließlich lösen wir Gleichung <a href="10-regression.html#eq:insert2">(10.10)</a> nach <span class="math inline">\(\beta_1\)</span> auf:</p>
<p><span class="math display" id="eq:b11">\[\begin{equation}
\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i\right)-\hat\beta_1 \cdot \sum_{i=1}^{n}\left(x_i^2-\bar{x} \cdot x_i\right)=0
\tag{10.11}
\end{equation}\]</span>
<span class="math display" id="eq:b12">\[\begin{equation}
\hat\beta_1=\frac{\sum_{i=1}^{n}\left(x_i \cdot y_i-\bar{y} \cdot x_i\right)}{\sum_{i=1}^{n}\left(x_i^2-\bar{x} \cdot x_i\right)}
\tag{10.12}
\end{equation}\]</span></p>
<p>Über eine Reihe von Schritten, die ich hier überspringe, erhalten wir:</p>
<p><span class="math display" id="eq:b13">\[\begin{equation}
\hat\beta_1=\frac{SSXY}{SSX}
\tag{10.13}
\end{equation}\]</span></p>
<p><span class="math inline">\(SSX=\sum_{i=1}^{n}\left(x_i-\bar{x}\right)^2\)</span> ist ein Maß für die Varianz der Daten in <span class="math inline">\(x\)</span>-Richtung. <span class="math inline">\(SSXY=\sum_{i=1}^{n}\left(x_i-\bar{x}\right) \cdot \left(y_i-\bar{y}\right)\)</span> ist ein Maß für die Kovarianz der Daten. In Kapitel <a href="09-tests.html#anova">9.5</a> hatten wir noch <span class="math inline">\(SSY=\sum_{i=1}^{n}\left(y_i-\bar{y}\right)^2\)</span>, das entsprechend ein Maß für die Varianz der Daten in <span class="math inline">\(y\)</span>-Richtung ist. Gleichung <a href="10-regression.html#eq:b13">(10.13)</a> ist eine exakte Lösung für <span class="math inline">\(\hat\beta_1\)</span>.</p>
<p>Wir setzen nun Gleichung <a href="10-regression.html#eq:b13">(10.13)</a> in Gleichung <a href="10-regression.html#eq:b04">(10.8)</a> ein und haben eine exakte Lösung für <span class="math inline">\(\hat\beta_0\)</span>. Berechnen wir nun die Parameter für unsere Reisedaten mit der <code>lm()</code> Funktion:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="10-regression.html#cb135-1" tabindex="-1"></a><span class="co"># lineare Regression der Reisedaten</span></span>
<span id="cb135-2"><a href="10-regression.html#cb135-2" tabindex="-1"></a>reise_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(zeit_morgens <span class="sc">~</span> distanz, <span class="at">data =</span> reisedat)</span>
<span id="cb135-3"><a href="10-regression.html#cb135-3" tabindex="-1"></a><span class="co"># Informationen über geschätzte Parameterwerte ausgeben</span></span>
<span id="cb135-4"><a href="10-regression.html#cb135-4" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   24.405     3.4399   7.095 2.033e-09
## distanz        2.078     0.1932  10.760 1.918e-15</code></pre>
<p>In der ersten Spalte (“Estimate”) dieses Outputs finden Sie die Werte der Parameterschätzer, wobei “(Intercept)” für <span class="math inline">\(\beta_0\)</span> steht und “distanz” (in diesem Fall) für <span class="math inline">\(\beta_1\)</span>. Anhand von <span class="math inline">\(\beta_1\)</span> können wir ablesen, dass sich pro km Entfernung die Reisezeit um 2.1min erhöht. Der Achsenabschnitt <span class="math inline">\(\beta_0\)</span> hat keine direkte Entsprechung.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> Auf die anderen Spalten werden wir weiter unten zu sprechen kommen. Plotten wir nun die so ermittelte Regressionsgerade <span class="math inline">\(y_i=24.4+2.1\cdot x_i+\epsilon_i\)</span>:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
</div>
<div id="erklärte-varianz" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Erklärte Varianz<a href="10-regression.html#erklärte-varianz" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nun, da wir Werte für die Regressionsparameter haben, testen wir üblicherweise formal, ob die vom Modell erklärte Varianz in den Daten größer als die nicht erklärte Varianz ist (bezogen auf die Grundgesamtheit). Das ist ein ANOVA-Problem (Kapitel <a href="09-tests.html#anova">9.5</a>). Die ANOVA-Tabelle (in diesem Fall Tabelle <a href="10-regression.html#tab:anova">10.3</a>) wird in <em>R</em> im Hintergrund aufgestellt und selten explizit betrachtet; tun wir es hier aber trotzdem, damit wir verstehen, was passiert.</p>
<table style="width:100%;">
<caption><span id="tab:anova">Tabelle 10.3: </span> ANOVA-Tabelle der linearen Regression.</caption>
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Varianz-<br>quelle</th>
<th align="center">Quadrat-<br>summe</th>
<th align="center">Freiheits-<br>grad (<span class="math inline">\(df\)</span>)</th>
<th align="center">Varianz</th>
<th align="center">F-Statistik (<span class="math inline">\(F_s\)</span>)</th>
<th align="center">p-Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Regression</td>
<td align="center"><span class="math inline">\(SSR=\\SSY-SSE\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(\frac{SSR}{df_{SSR}}\)</span></td>
<td align="center"><span class="math inline">\(\frac{\frac{SSR}{df_{SSR}}}{s^2}\)</span></td>
<td align="center"><span class="math inline">\(1-F\left(F_s,1,n-2\right)\)</span></td>
</tr>
<tr class="even">
<td align="center">Residuum</td>
<td align="center"><span class="math inline">\(SSE\)</span></td>
<td align="center"><span class="math inline">\(n-2\)</span></td>
<td align="center"><span class="math inline">\(\frac{SSE}{df_{SSE}}=s^2\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Gesamt</td>
<td align="center"><span class="math inline">\(SSY\)</span></td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Analog zur ANOVA-Tabelle aus Kapitel <a href="09-tests.html#anova">9.5</a> (Tabelle <a href="09-tests.html#tab:einfaktoriell">9.1</a>), ist <span class="math inline">\(SSY=\sum_{i=1}^{n}\left(y_i-\bar{y}\right)^2\)</span> ein Maß für die Gesamtvarianz der Daten (in <span class="math inline">\(y\)</span>-Richtung), d.h. wie stark die Datenpunkte um den Gesamtmittelwert streuen (Abbildung <a href="10-regression.html#fig:ssysse">10.3</a>, links). <span class="math inline">\(SSE=\sum_{i=1}^{n}\left(\epsilon_i\right)^2=\sum_{i=1}^{n}\left(y_i-\left(\beta_0+\beta_1 \cdot x_i\right)\right)^2\)</span> ist ein Maß für die Fehlervarianz, d.h. wie stark die Datenpunkte um die Regressionsgerade streuen (Abbildung <a href="10-regression.html#fig:ssysse">10.3</a>, rechts). Das ist die Varianz, die nach der Modellanpassung übrig ist (“nicht erklärt”). <span class="math inline">\(SSR=SSY-SSE\)</span> ist folglich ein Maß für die vom Modell erklärte Varianz. Im Fall der ANOVA in Kapitel <a href="09-tests.html#anova">9.5</a> sprechen wir hier von <span class="math inline">\(SSA\)</span>; das Modell ist dann der “Faktor” (kategorische Variable).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ssysse"></span>
<img src="eids_files/figure-html/ssysse-1.png" alt="Variation der Datenpunkte um den Mittelwert, zusammengefasst durch $SSY$ (links), und um die Regressionsgerade, zusammengefasst durch $SSE$ (rechts)." width="50%" /><img src="eids_files/figure-html/ssysse-2.png" alt="Variation der Datenpunkte um den Mittelwert, zusammengefasst durch $SSY$ (links), und um die Regressionsgerade, zusammengefasst durch $SSE$ (rechts)." width="50%" />
<p class="caption">
Abbildung 10.3: Variation der Datenpunkte um den Mittelwert, zusammengefasst durch <span class="math inline">\(SSY\)</span> (links), und um die Regressionsgerade, zusammengefasst durch <span class="math inline">\(SSE\)</span> (rechts).
</p>
</div>
<p>In der dritten Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> stehen die Freiheitsgrade der drei Varianzterme. Diese können wie gehabt als Anzahl der Werte in einer Stichprobe, die für die Berechnung der jeweiligen Parameter frei zur Verfügung stehen, verstanden werden (vgl. Kapitel <a href="04-streuung.html#streuung">4</a> und Kapitel <a href="09-tests.html#anova">9.5</a>): In die Berechnung von <span class="math inline">\(SSY\)</span> geht <span class="math inline">\(\bar y\)</span> ein, für dessen Berechnung die Werte der Stichprobe bereits einmal verwendet wurden; dadurch ist die Anzahl Freiheitsgrade <span class="math inline">\(df_{SSY}=n-1\)</span>. In die Berechnung von <span class="math inline">\(SSE\)</span> gehen <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> ein (Gleichung <a href="10-regression.html#eq:sse">(10.2)</a>), d.h. die Anzahl Freiheitsgrade ist <span class="math inline">\(df_{SSE}=n-2\)</span>. Für <span class="math inline">\(SSR\)</span> gilt dann einfach <span class="math inline">\(df_{SSR}=df_{SSY}-df_{SSE}=1\)</span>. Die Freiheitsgrade werden verwendet, um die Varianzterme in der vierten Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> zu normalisieren, d.h. auf die Skala einer Varianz zu bringen, wobei <span class="math inline">\(s^2\)</span> Fehlervarianz genannt wird.</p>
<p>In der fünften Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> finden wir das Verhältnis von zwei Varianzen; Regressionsvarianz über Fehlervarianz. Von einer aussagekräftigen Regression erwarten wir, dass die (durch das Modell erklärte) Regressionsvarianz viel größer ist als die (durch das Modell nicht erklärte) Fehlervarianz. Dies ist ein F-Test Problem (vgl. Kapitel <a href="09-tests.html#anova">9.5</a>), bei dem getestet wird, ob sich die durch das Modell <em>erklärte</em> Varianz von der durch das Modell <em>nicht erklärten</em> Varianz (bezogen auf die Grundgesamtheit) unterscheidet. Das Verhältnis der beiden Varianzen dient als F-Statistik <span class="math inline">\(F_s\)</span>.</p>
<p>Die sechste Spalte der Tabelle <a href="10-regression.html#tab:anova">10.3</a> gibt dann den p-Wert des F-Tests an, d.h. die Wahrscheinlichkeit, <span class="math inline">\(F_s\)</span> oder einen größeren Wert (d.h. <strong>ein noch besseres Modell</strong>) zufällig zu erhalten, wenn die Nullhypothese <span class="math inline">\(H_0\)</span> wahr ist (vgl. Kapitel <a href="09-tests.html#anova">9.5</a>). Im Fall der linearen Regression ist <span class="math inline">\(H_0:\frac{SSR}{df_{SSR}}=s^2\)</span>, d.h. die beiden Varianzen sind gleich, und <span class="math inline">\(H_1:\frac{SSR}{df_{SSR}}&gt;s^2\)</span>, d.h. die erklärte Varianz ist größer als die nicht erklärte.</p>
Wie in Kapitel <a href="09-tests.html#ftest">9.4</a> bereits diskutiert folgt <span class="math inline">\(F_s\)</span> einer F-Verteilung unter der Nullhypothese, hier mit den Parametern <span class="math inline">\(1\)</span> und <span class="math inline">\(n-2\)</span> (Abbildung <a href="10-regression.html#fig:fcdf">10.4</a>). Die blaue Linie in Abbildung <a href="10-regression.html#fig:fcdf">10.4</a> markiert einen bestimmten Wert von <span class="math inline">\(F_s\)</span> (in diesem Beispiel <span class="math inline">\(8\)</span>) und den entsprechenden Wert der Verteilungsfunktion der F-Verteilung (<span class="math inline">\(F\left(F_s,1,n-2\right)\)</span>). Der p-Wert ist <span class="math inline">\(\Pr\left(Z&gt; F_s\right)=1-F\left(F_s,1,n-2\right)\)</span> und beschreibt die Wahrscheinlichkeit, dieses oder ein größeres Varianzverhältnis zufällig (aufgrund der zufälligen Stichprobenziehung) zu erhalten, selbst wenn die beiden Varianzen tatsächlich gleich sind.
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fcdf"></span>
<img src="eids_files/figure-html/fcdf-1.png" alt="Verteilungsfunktion der F-Verteilung der F-Statistik $F_s$. Blau: Bestimmter Wert für $F_s$ und entsprechender Wert der Verteilungsfunktion." width="80%" />
<p class="caption">
Abbildung 10.4: Verteilungsfunktion der F-Verteilung der F-Statistik <span class="math inline">\(F_s\)</span>. Blau: Bestimmter Wert für <span class="math inline">\(F_s\)</span> und entsprechender Wert der Verteilungsfunktion.
</p>
</div>
<p>Für die Regression der Reisedaten ist der p-Wert wesentlich kleiner als das konventionelle Signifikanzniveau <span class="math inline">\(\alpha=0.01\)</span>, daher lehnen wir die Nullhypothese ab und bezeichnen die Regression als “statistisch signifikant” in der klassischen Interpretation. Schauen wir uns die ANOVA-Tabelle für das Beispiel an:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="10-regression.html#cb137-1" tabindex="-1"></a><span class="fu">anova</span>(reise_fit)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: zeit_morgens
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## distanz    1  18253   18253     116 1.9e-15 ***
## Residuals 58   9144     158                    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Im Vergleich zu Tabelle <a href="10-regression.html#tab:anova">10.3</a> lässt <em>R</em> die letzte Zeile (<span class="math inline">\(SSY\)</span>) weg und tauscht die Spalten “Quadratsumme” und “Freiheitsgrad”.</p>
<p>Der Anteil der Varianz (in <span class="math inline">\(y\)</span>-Richtung), der durch das Modell erklärt wird, wird außerdem mit dem <strong>Bestimmtheitsmaß</strong> (<span class="math inline">\(r^2\)</span>) ausgedrückt:
<span class="math display" id="eq:r2">\[\begin{equation}
r^2=\frac{SSY-SSE}{SSY}=1-\frac{SSE}{SSY}
\tag{10.14}
\end{equation}\]</span>
Das Bestimmtheitsmaß ist der Korrelationskoeffizient nach Bravais-Pearson zum Quadrat (vgl. Kapitel <a href="05-korrelation.html#korrelation">5</a>).</p>
<p>Wie wir an Gleichung <a href="10-regression.html#eq:r2">(10.14)</a> sehen, wenn das Modell nicht mehr Variation als die Gesamtvariation um den Mittelwert erklärt, d.h. <span class="math inline">\(SSE=SSY\)</span> ist, dann ist <span class="math inline">\(r^2=0\)</span>. Umgekehrt, wenn das Modell perfekt zu den Daten passt, d.h. <span class="math inline">\(SSE=0\)</span> ist, dann ist <span class="math inline">\(r^2=1\)</span>. Werte dazwischen stellen unterschiedliche Grade der Anpassungsgüte dar. Das kann wiederum mit Abbildung <a href="10-regression.html#fig:ssysse">10.3</a> veranschaulicht werden, wobei der linke Teil <span class="math inline">\(SSY\)</span> und der rechte Teil <span class="math inline">\(SSE\)</span> verdeutlicht.</p>
<p>Wenn es darum geht, Modelle unterschiedlicher Komplexität (d.h. mit mehr oder weniger Parametern) mit <span class="math inline">\(r^2\)</span> zu vergleichen, dann ist es sinnvoll, das Bestimmtheitsmaß mit der Anzahl der Modellparameter zu korrigieren, da komplexere Modelle (mehr Parameter) automatisch zu besseren Anpassungen führen, einfach aufgrund der größeren Freiheitsgrade, die komplexere Modelle bei der Anpassung an die Daten haben. Dies führt zum <strong>korrigierten <span class="math inline">\(r^2\)</span></strong>:
<span class="math display" id="eq:adjr2">\[\begin{equation}
\bar r^2=1-\frac{\frac{SSE}{df_{SSE}}}{\frac{SSY}{df_{SSY}}}=1-\frac{SSE}{SSY} \cdot \frac{df_{SSY}}{df_{SSE}}
\tag{10.15}
\end{equation}\]</span></p>
<p>Rechnen wir <span class="math inline">\(r^2\)</span> und <span class="math inline">\(\bar r^2\)</span> für die Regression der Reisedaten aus:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="10-regression.html#cb139-1" tabindex="-1"></a><span class="fu">summary</span>(reise_fit)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.6662</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="10-regression.html#cb141-1" tabindex="-1"></a><span class="fu">summary</span>(reise_fit)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6605</code></pre>
<p>D.h. es werden rund 67% der Varianz in den Reisezeit-Daten durch das lineare Modell mit Entfernung als Prädiktor erklärt.</p>
</div>
<div id="konfidenzintervalle-der-parameterschätzer" class="section level2 hasAnchor" number="10.6">
<h2><span class="header-section-number">10.6</span> Konfidenzintervalle der Parameterschätzer<a href="10-regression.html#konfidenzintervalle-der-parameterschätzer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Da die Modellanpassung nicht perfekt ist, haben die Parameterschätzer Standardfehler, d.h. sie werden wie andere statistische Kennzahlen als Realisationen eines Zufallsprozesses interpretiert. Das führt uns zu Konfidenzintervallen und t-Tests auf Signifikanz der einzelnen Parameter.</p>
<p>Der <strong>Standardfehlern</strong> für <span class="math inline">\(\hat\beta_0\)</span> ist:
<span class="math display" id="eq:seb0">\[\begin{equation}
s_{\hat\beta_0}=\sqrt{\frac{\sum_{i=1}^{n}x_i^2}{n} \cdot \frac{s^2}{SSX}}
\tag{10.16}
\end{equation}\]</span></p>
<p>Wenn wir diese Formel in ihre einzelnen Teile zerlegen, sehen wir: Je mehr Datenpunkte <span class="math inline">\(n\)</span> wir haben, desto kleiner ist der Standardfehler, d.h. desto mehr Vertrauen haben wir in die Schätzung. Außerdem gilt, je größer die Variation in <span class="math inline">\(x\)</span> (<span class="math inline">\(SSX\)</span>), desto kleiner der Standardfehler. Beide Effekte machen intuitiv Sinn: Je mehr Datenpunkte wir haben und je mehr Ausprägungen von <span class="math inline">\(x\)</span> wir abgedeckt haben, desto sicherer können wir sein, dass unsere Stichprobe aussagekräftig für die Grundgesamtheit ist. Umgekehrt gilt: Je größer die Fehlervarianz <span class="math inline">\(s^2\)</span>, d.h. je kleiner die Erklärungskraft unseres Modells, desto größer der Standardfehler. Und je mehr <span class="math inline">\(x\)</span>-Datenpunkte von Null entfernt sind, d.h. je größer <span class="math inline">\(\sum_{i=1}^{n}x_i^2\)</span>, desto geringer ist unser Vertrauen in den Achsenabschnitt (wo <span class="math inline">\(x=0\)</span> ist) und damit steigt der Standardfehler.</p>
<p>Der Standardfehler für <span class="math inline">\(\hat\beta_1\)</span> ist:
<span class="math display" id="eq:seb1">\[\begin{equation}
s_{\hat\beta_1}=\sqrt{\frac{s^2}{SSX}}
\tag{10.17}
\end{equation}\]</span>
Hier gilt die gleiche Interpretation wie zuvor, außer dass es keinen Einfluss der Größe der <span class="math inline">\(x\)</span>-Datenpunkte gibt.</p>
<p>Wir können auch einen Standardfehler für neue Vorhersagen <span class="math inline">\(\hat y\)</span> für gegebene <span class="math inline">\(\hat x\)</span> festlegen:
<span class="math display" id="eq:sey">\[\begin{equation}
s_{\hat y}=\sqrt{s^2 \cdot \left(\frac{1}{n}+\frac{\left(\hat x-\bar x\right)^2}{SSX}\right)}
\tag{10.18}
\end{equation}\]</span></p>
<p>Dieselbe Interpretation gilt auch hier, nur dass jetzt ein zusätzlicher Term <span class="math inline">\(\left(\hat x-\bar x\right)^2\)</span> auftaucht, der besagt, je weiter der neue <span class="math inline">\(x\)</span>-Wert vom Zentrum der ursprünglichen Daten (den Trainings- oder Kalibrierungsdaten) entfernt ist, desto größer ist der Standardfehler der neuen Vorhersage, d.h. desto geringer ist die Zuversicht, dass sie korrekt ist.</p>
<blockquote>
<p>Anmerkung: Die Formeln für die Standardfehler ergeben sich aus den grundlegenden Annahmen der linearen Regression, auf die wir weiter unten eingehen werden. Die mathematische Herleitung lassen wir hier aus.</p>
</blockquote>
<p>Aus den Standardfehlern können wir <strong>Konfidenzintervalle</strong> für die Parameterschätzer wie folgt berechnen (vgl. Konfidenzintervall des Mittelwertschätzers (Kapitel <a href="08-schaetzen.html#schaetzen">8</a>)):
<span class="math display" id="eq:cib01">\[\begin{equation}
\Pr\left(\hat\beta_0-t_{n-2;0.975} \cdot s_{\hat\beta_0}\leq \beta_0\leq \hat\beta_0+t_{n-2;0.975} \cdot s_{\hat\beta_0}\right)=0.95
\tag{10.19}
\end{equation}\]</span></p>
<p>Gleichung <a href="10-regression.html#eq:cib01">(10.19)</a> ist das zentrale 95%-Konfidenzintervall, in dem der wahre Parameterwert, hier <span class="math inline">\(\beta_0\)</span>, mit einer Wahrscheinlichkeit von 0.95 liegt.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<p>Wir können das Intervall auch wie folgt schreiben:
<span class="math display" id="eq:cib02">\[\begin{equation}
KI=\left[\hat\beta_0-t_{n-2;0.975} \cdot s_{\hat\beta_0};\hat\beta_0+t_{n-2;0.975} \cdot s_{\hat\beta_0}\right]
\tag{10.20}
\end{equation}\]</span></p>
<p>Wie bei dem Konfidenzintervall des Mittelwertschätzers (Kapitel <a href="08-schaetzen.html#schaetzen">8</a>) liegt das Konfidenzintervall symmetrisch um den Parameterschätzer <span class="math inline">\(\hat\beta_0\)</span> und ergibt sich aus einer t-Verteilung mit dem Parameter <span class="math inline">\(n-2\)</span> (Freiheitsgrade), deren Breite durch den Standardfehler <span class="math inline">\(s_{\hat\beta_0}\)</span> moduliert wird. Erinnern Sie sich, dass die Breite der t-Verteilung ebenfalls durch den Stichprobenumfang kontrolliert wird und mit zunehmendem <span class="math inline">\(n\)</span> immer schmaler wird.</p>
<p>Die gleichen Formeln gelten für <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(y\)</span>:
<span class="math display" id="eq:cib1">\[\begin{equation}
\Pr\left(\hat\beta_1-t_{n-2;0.975} \cdot s_{\hat\beta_1}\leq \beta_1\leq \hat\beta_1+t_{n-2;0.975} \cdot s_{\hat\beta_1}\right)=0.95
\tag{10.21}
\end{equation}\]</span>
<span class="math display" id="eq:ciy">\[\begin{equation}
\Pr\left(\hat y-t_{n-2;0.975} \cdot s_{\hat y}\leq y\leq \hat y+t_{n-2;0.975} \cdot s_{\hat y}\right)=0.95
\tag{10.22}
\end{equation}\]</span></p>
<p>Die Formeln für die Konfidenzintervalle (Gleichungen <a href="10-regression.html#eq:cib01">(10.19)</a>, <a href="10-regression.html#eq:cib1">(10.21)</a> und <a href="10-regression.html#eq:ciy">(10.22)</a>) ergeben sich aus den Grundannahmen der linearen Regression (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>): Die Residuen sind <em>unabhängig identisch verteilt (u.i.v.)</em> gemäß einer <em>Normalverteilung</em>, d.h. <span class="math inline">\(\epsilon_i\sim N(0,\sigma)\)</span>, und <em>das lineare Modell ist korrekt</em>. Dann lässt sich mathematisch zeigen, dass <span class="math inline">\(\frac{\hat\beta_0-\beta_0}{s_{\hat\beta_0}}\)</span>, <span class="math inline">\(\frac{\hat\beta_1-\beta_1}{s_{\hat\beta_1}}\)</span> und <span class="math inline">\(\frac{\hat y-y}{s_{\hat y}}\)</span> <span class="math inline">\(t_{n-2}\)</span>-verteilt sind (t-Verteilung mit <span class="math inline">\(n-2\)</span> Freiheitsgraden). Da das zentrale 95%-Konfidenzintervall einer <span class="math inline">\(t_{n-2}\)</span>-verteilten Zufallsvariablen <span class="math inline">\(Z\)</span> <span class="math inline">\(\Pr\left(-t_{n-2;0.975}\leq Z\leq t_{n-2;0. 975}\right)=0.95\)</span> ist (Abbildung <a href="08-schaetzen.html#fig:kiz">8.2</a>), können wir jeden der oben genannten drei Terme für <span class="math inline">\(Z\)</span> einsetzen und die Ungleichung umstellen, um zu den Gleichungen <a href="10-regression.html#eq:cib01">(10.19)</a>, <a href="10-regression.html#eq:cib1">(10.21)</a> und <a href="10-regression.html#eq:ciy">(10.22)</a> zu gelangen (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>).</p>
<p>Die Unsicherheit der Parameterschätzer wird mit Hilfe eines t-Tests ermittelt (vgl. Kapitel <a href="09-tests.html#ttest">9.2</a>). Die <strong>Nullhypothese</strong> ist, dass die wahren Parameterwerte (bezogen auf die Grundgesamtheit) gleich Null sind:
<span class="math display" id="eq:h0b0">\[\begin{equation}
H_0:\beta_0=0
\tag{10.23}
\end{equation}\]</span>
<span class="math display" id="eq:h0b1">\[\begin{equation}
H_0:\beta_1=0
\tag{10.24}
\end{equation}\]</span></p>
<p>Diese Hypothese wird gegen die <strong>Alternativhypothese</strong> getestet, dass die wahren Parameterwerte <em>un</em>gleich Null sind:
<span class="math display" id="eq:h1b0">\[\begin{equation}
H_1:\beta_0\neq 0
\tag{10.25}
\end{equation}\]</span>
<span class="math display" id="eq:h1b1">\[\begin{equation}
H_1:\beta_1\neq 0
\tag{10.26}
\end{equation}\]</span></p>
<p>Die Teststatistiken sind:
<span class="math display" id="eq:tsb0">\[\begin{equation}
t_s=\frac{\hat\beta_0-0}{s_{\hat\beta_0}}\sim t_{n-2}
\tag{10.27}
\end{equation}\]</span>
<span class="math display" id="eq:tsb1">\[\begin{equation}
t_s=\frac{\hat\beta_1-0}{s_{\hat\beta_1}}\sim t_{n-2}
\tag{10.28}
\end{equation}\]</span></p>
<p>Die t-Verteilungen der Teststatistiken ergeben sich wiederum aus den oben erwähnten Regressionsannahmen. Die Annahmen sind die gleichen wie beim üblichen t-Test der Mittelwerte (Kapitel <a href="09-tests.html#ttest">9.2</a>), außer dass im Fall der linearen Regression die Residuen als u.i.v. normal angenommen werden, während im Fall der Mittelwerte die tatsächlichen Datenpunkte <span class="math inline">\(y\)</span> als u.i.v. normal angenommen werden.</p>
<p>Analog zum üblichen 2-seitigen t-Test ist der p-Wert definiert als:
<span class="math display" id="eq:pv">\[\begin{equation}
2 \cdot \Pr\left(t&gt;|t_s|\right)=2 \cdot \left(1-F_t\left(|t_s|\right)\right)
\tag{10.29}
\end{equation}\]</span></p>
<p>Mit einem konventionellen Signifikanzniveau von <span class="math inline">\(\alpha=0.01\)</span> gelangen wir zu einem kritischen Wert der Teststatistik <span class="math inline">\(t_c=t_{n-2;0.995}\)</span>, bei dessen Überschreitung, bzw. Unterschreitung von <span class="math inline">\(-t_c\)</span>, wir die Nullhypothese ablehnen und die Parameterschätzer in der klassischen Interpretation als “signifikant” bezeichnen.</p>
<p>Jetzt verstehen wir auch die restlichen Informationen des Outputs der <code>lm()</code> Funktion (s. oben):</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="10-regression.html#cb143-1" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(reise_fit))</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)   24.405     3.4399   7.095 2.033e-09
## distanz        2.078     0.1932  10.760 1.918e-15</code></pre>
<p>Wie bereits oben erwähnt steht die Zeile “(Intercept)” für <span class="math inline">\(\beta_0\)</span> und die Zeile “distanz” (in diesem Fall) für <span class="math inline">\(\beta_1\)</span>. In der Spalte “Estimate” stehen die Werte der Parameterschätzer. In der Spalte “Std. Error” stehen deren Standardfehler (Gleichungen <a href="10-regression.html#eq:seb0">(10.16)</a> und <a href="10-regression.html#eq:seb1">(10.17)</a>). In der Spalte “t value” stehen die entsprechenden Werte der Teststatistik (Gleichungen <a href="10-regression.html#eq:tsb0">(10.27)</a> und <a href="10-regression.html#eq:tsb1">(10.28)</a>). In der Spalte “Pr(&gt;|t|)” stehen die p-Werte der t-Tests (Gleichung <a href="10-regression.html#eq:pv">(10.29)</a>). Wir sehen, dass in unserem Beispiel beide Parameter in der klassischen Interpretation “signifikant” sind (die p-Werte sind wesentlich kleiner als das konventionelle <span class="math inline">\(\alpha=0.01\)</span>).</p>
<p>Mit der Information der Konfidenzintervalle der Parameterschätzer und der Vorhersagen können wir jetzt die Regressionsgerade mit Konfidenzintervall darstellen. Nur dann ist die Darstellung vollständig. Es gibt zwei Arten von Konfidenzintervallen: das Konfidenzintervall der Regressionsgeraden, in das die Konfidenzintervalle der beiden Parameterschätzer (Gleichungen <a href="10-regression.html#eq:cib01">(10.19)</a> und <a href="10-regression.html#eq:cib1">(10.21)</a>) eingehen, und das Konfidenzintervall tatsächlicher Werte der abhängigen Variable <span class="math inline">\(y\)</span> für Werte der unabhängigen Variable <span class="math inline">\(x\)</span>, d.h. das Konfidenzintervalle der Vorhersagen (Gleichung <a href="10-regression.html#eq:ciy">(10.22)</a>).</p>
<p>Das erste Konfidenzintervall beschreibt damit die Unsicherheit des Trends durch die Punktwolke, der meistens von primärem Interesse ist:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>Das zweite Konfidenzintervall beschreibt die Unsicherheit der Vorhersage neuer einzelner Werte von <span class="math inline">\(y\)</span>, die natürlich wesentlich größer ist:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
</div>
<div id="annahmen-der-regression" class="section level2 hasAnchor" number="10.7">
<h2><span class="header-section-number">10.7</span> Annahmen der Regression<a href="10-regression.html#annahmen-der-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Da die o.g. Schätzer und wahrscheinlichkeitstheoretischen Aussagen nur unter bestimmten Modellannahmen gültig sind, müssen wir diese Annahmen bei jeder Regression testen. Folgende Annahmen ergeben sich aus der <strong>Maximum-Likelihood-Theorie</strong> (vgl. Schätzen von Verteilungsparametern, Kapitel <a href="08-schaetzen.html#schaetzen">8</a>):</p>
<ul>
<li>Die Residuen sind <strong>unabhängig</strong>, in diesem Fall gibt es keine serielle Korrelation in der Residuengrafik - dies kann mit dem Durbin-Watson-Test getestet werden</li>
<li>Die Residuen sind <strong>normalverteilt</strong> - dies kann visuell mit Hilfe des Quantil-Quantil-Diagramms (QQ-Plot) und dem Residuen-Histogramm beurteilt werden, und kann mit dem Kolmogorov-Smirnov-Test (Kapitel <a href="09-tests.html#kstest">9.6</a>) und dem Shapiro-Wilk-Test getestet werden</li>
<li>Die Varianz ist für alle Residuen konstant (die Residuen sind <strong>homoskedastisch</strong>), d.h. es erfolgt kein “Auffächern” der Residuen</li>
</ul>
<p>Sind diese Annahmen nicht erfüllt, können wir auf Datentransformation, gewichtete Regression oder Generalisierte Lineare Modelle zurückgreifen. Letzteres wird z.B. im Master <em>Global Change Geography</em> unterrichtet.</p>
<p>Eine erste nützliche diagnostische Darstellung ist die der Residuen in Serie, d.h. nach Index <span class="math inline">\(i\)</span>, um zu sehen, ob es ein Muster aufgrund des Datenerfassungsprozesses gibt. Für unser Beispiel:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>Die Residuen zeigen kein erkennbares Muster, das gegen die Unabhängigkeit der Residuen sprechen würde.</p>
<p>Wir sollten auch die Residuen nach dem modellierten Wert von <span class="math inline">\(y\)</span> plotten, um zu sehen, ob es ein Muster als Funktion der Größenordnung von <span class="math inline">\(y\)</span> gibt:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>Hier gibt es jetzt systematische Unter- und Überschätzungen, die gegen eine Linearität des Zusammenhangs sprechen.</p>
<p>Die Annahme, dass die Residuen normalverteilt sind, kann anhand des QQ-Plots beurteilt werden (vgl. Kapitel <a href="08-schaetzen.html#qqplot">8.4</a>):</p>
<p><img src="eids_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Die Annahme normalverteilter Residuen erscheint plausibel. Vgl. <a href="https://xiongge.shinyapps.io/QQplots/" class="uri">https://xiongge.shinyapps.io/QQplots/</a>. Das kann man auch am Histogramm der Residuen sehen, einer weiteren nützlichen Darstellung:</p>
<p><img src="eids_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>Auch ein formaler KS-Test gibt keinen Anlass, die Normalverteilungsannahme der Residuen abzulehnen:</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="10-regression.html#cb145-1" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">residuals</span>(reise_fit)</span>
<span id="cb145-2"><a href="10-regression.html#cb145-2" tabindex="-1"></a><span class="fu">ks.test</span>(res, <span class="st">&quot;pnorm&quot;</span>, <span class="dv">0</span>, <span class="fu">sd</span>(res))</span></code></pre></div>
<pre><code>## 
##  Exact one-sample Kolmogorov-Smirnov test
## 
## data:  res
## D = 0.061, p-value = 1
## alternative hypothesis: two-sided</code></pre>
<p>Wir können also die Regressionsannahmen in unserem Fall als hinreichend erfüllt betrachten und mit den ermittelten Parameterschätzern und deren Unsicherheiten weiterarbeiten.</p>
</div>
<div id="anova_lm" class="section level2 hasAnchor" number="10.8">
<h2><span class="header-section-number">10.8</span> ANOVA als Regressionsproblem<a href="10-regression.html#anova_lm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>to be continued</p>

</div>
</div>



<h3>Literatur<a href="11-refs.html#literatur" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-wainer2009" class="csl-entry">
Wainer, H. 2009. <em>Picturing the Uncertain World</em>. Princeton: Princeton University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="21">
<li id="fn21"><p>Auch Regressionsprobleme mit nominal oder ordinal skalierten <em>abhängigen</em> Variablen sind mathematisch ähnlich. Das wird z.B. im Masterstudiengang <em>Global Change Geography</em> gelehrt.<a href="10-regression.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Summenregel: wenn <span class="math inline">\(y=u(t) \pm v(t)\)</span> dann <span class="math inline">\(\frac{dy}{dt}=\frac{du}{dt} \pm \frac{dv}{dt}\)</span><a href="10-regression.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Kettenregel: wenn <span class="math inline">\(y=f[g(t)]\)</span> dann <span class="math inline">\(\frac{dy}{dt}=\frac{df[g]}{dg} \cdot \frac{dg}{dt}\)</span>, d.h. “äußere mal innere Ableitung”<a href="10-regression.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Wenn wir jedoch die unabhängige Variable “distanz” zentrieren würden, d.h. von allen Datenpunkten den Mittelwert abziehen würden, dann ergäbe sich ein Achsenabschnitt, der die Reisezeit für die mittlere Entfernung darstellen würde.<a href="10-regression.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>Wahrscheinlichkeit heisst hier wieder, dass bei wiederholtem Stichprobenziehen in 95% der Fälle das so konstruierte Konfidenzintervall den wahren Wert <span class="math inline">\(\beta_0\)</span> umschließt und in 5% der Fälle nicht.<a href="10-regression.html#fnref25" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="09-tests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-refs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
