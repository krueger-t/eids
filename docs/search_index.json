[
["index.html", "Einf√ºhrung in die Statistik Vorwort", " Einf√ºhrung in die Statistik Tobias Krueger 2020-10-26 Vorwort Dies ist das Skript f√ºr den Kurs ‚ÄòEinf√ºhrung in die Statistik‚Äô am Geographischen Institut der Humboldt-Universit√§t zu Berlin. "],
["einfuehrung.html", "Chapter 1 Einf√ºhrung 1.1 Statistik im empirischen Forschungsprozess 1.2 Warum Statistik? 1.3 Organisatorisches 1.4 Mathematische Notation und Grundlagen", " Chapter 1 Einf√ºhrung Das Modul B3 Einf√ºhrung in die Statistik und das Fach Geographie besteht aus: Dem Seminar Einf√ºhrung in die Statistik mit Tobias Kr√ºger (regelm√§√üiges ZOOM-Treffen montags 11:00-12:30 - s. Moodle link) Dem Seminar Einf√ºhrung in die Geographie mit Christoph Schneider und Henning Nuissl Der PC-√úbung Statistische Datenverarbeitung mit Matthias Baumann, Sebastian Schubert, Heidi Kreibich, Abror Gafurov, Hoseung Jung, Friedrich Busch, Kassandra Jensch und Maeve Smyth (ab 27. November 3-st√ºndig freitags 09:00-12:00 - dazu mehr weiter unten) Das vorliegende Skript ist Grundlage des Seminars Einf√ºhrung in die Statistik und dient der theoretischen Vorbereitung der PC-√úbung Statistische Datenverarbeitung. Organisatorisches dazu weiter unten. Am Ende des Semesters haben Sie ein Grundverst√§ndnis der beschreibenden und der schlie√üenden Statistik erworben. Sie k√∂nnen folgende Methoden selbst√§ndig in der Software R anwenden und deren Ergebnisse interpretieren: - Beschreibung von Stichproben mit Zentralit√§ts- und Streuungsma√üen - Beschreibung der Korrelation zwischen Merkmalen - Sch√§tzen von Verteilungsparametern anhand von Stichproben - Test auf Unterschiede in Mittelwerten (t-Test) - Test auf Unterschiede in Varianzen (F-Test) - Test auf Unterschiede in Verteilungen (Kolmogorov-Smirnov-Test) - Test auf Unabh√§ngigkeit (Chi-Quadrat-Test) - Modellierung eines linearen Zusammenhangs zwischen Merkmalen (lineare Regression) - Graphisch Methoden wie Histogramm, Boxplot, Streudiagramm und Quantil-Quantil-Plot Zun√§chst aber ein paar einleitende Worte zur Statistik in der Geographie. 1.1 Statistik im empirischen Forschungsprozess Lesen Sie dazu bitte Kapitel 2.4 von Zimmermann-Janschitz (2014) - s. Moodle link. Gem√§√ü der dort gew√§hlten Kategorisierung befasst sich die Statistik haupts√§chlich mit Datenanalyse (Punkt 7), obwohl die angrenzenden Schritte ebenfalls wichtig sind. Auf Auswahl der Untersuchungseinheit (Punkt 4), Datenerhebung (Punkt 5) und Datenaufbereitung (Punkt 6) werden wir in Kapitel 2 n√§her eingehen. Punkt 8 (Interpretation und R√ºckschl√ºsse) wird durchgehend eine Rolle spielen. 1.2 Warum Statistik? Statistik ist Teil des physisch- und humangeographischen Methodenpakets. Da die Erkenntnisse der Geographie in vielen Teilen auf dem empirischen Forschungsprozess basieren ist statistische Analyse unumg√§nglich als Argumentationsunterst√ºtzung und als Beweissicherung. Au√üerdem dient sie der Best√§tigung oder Widerlegung theoretischer Ans√§tze und der Generierung neuer Informationen aus verf√ºgbaren Daten. In der Praxis dient Statistik h√§ufig als Entscheidungsgrundlage. Lesen Sie bitte Kapitel 2.3 von Zimmermann-Janschitz (2014) f√ºr konkrete Anwendungsbeispiele der Statistik in der Geographie. Aufgabe: Auf Moodle unter Woche 1 finden Sie ein kurzes Quiz zu diesem Kapitel. Bitte beantworten Sie die Fragen bis Ende der Woche. Dies werden wir jede Woche tun, als Lernstandskontrolle f√ºr Sie und als √úberblick f√ºr uns √ºber m√∂gliche Verst√§ndnisprobleme. Am Ende von Kapitel 2.3 in Zimmermann-Janschitz (2014) finden Sie au√üerdem eine Erkl√§rung der Teilbereiche der Statistik. Mit der deskriptiven (beschreibenden) Statistik besch√§ftigen wir uns in den Wochen 3-5. Dazu ist das Lehrbuch von Zimmermann-Janschitz (2014) wichtig. Mit der induktiven (schlie√üenden) Statistik besch√§figen wir uns in den Wochen 8-13. Die Br√ºcke zwischen diesen beiden Teilbereichen - wie es Zimmermann-Janschitz (2014) darstellt - ist die Wahrscheinlichkeitstheorie, mit deren Grundlagen wir uns in den Wochen 6-7 auseinandersetzen. 1.3 Organisatorisches Die Abfolge der Inhalte des Seminars und der PC-√úbung finden Sie in Tabelle 1.1. Table 1.1: Inhalte von Einf√ºhrung in die Statistik und Statistische Datenverarbeitung. Der gelesene Stoff wird am darauffolgenden Montag im Seminar diskutiert. Die PC-√úbung beginnt in Woche 4 am 27. November. Woche Lesen Diskutieren (Montagsseminar) PC-√úbung (Freitag) 1 Warum Statistik?; Organisatorisches; Mathematische Grundlagen - - 2 Datenerhebung; Grundbegriffe; Skalen Warum Statistik?; Organisatorisches; Mathematische Grundlagen - 3 Deskriptive Statistik 1 Datenerhebung; Grundbegriffe; Skalen - 4 Deskriptive Statistik 2 Deskriptive Statistik 1 Pre-√úbung 5 Deskriptive Statistik 3 Deskriptive Statistik 2 Einf√ºhrung in R 6 Grundlagen der Wahrscheinlichkeitsrechnung Deskriptive Statistik 3 Dateneingabe, Datenformate, Skalen 7 Verteilungen Grundlagen der Wahrscheinlichkeitsrechnung Deskriptive Statistik 8 Sch√§tzen von Verteilungsparametern Verteilungen Korrelation 9 Statistische Tests 1 Sch√§tzen von Verteilungsparametern Sch√§tzen von Verteilungsparametern 1 ‚Äúper Hand‚Äù in R 10 Statistische Tests 2 Statistische Tests 1 Sch√§tzen von Verteilungsparametern 2 in R 11 Statistische Tests 3 Statistische Tests 2 F- und t-Test 12 Lineare Regression 1 Statistische Tests 3 Kolmogorow-Smirnow- und Chi-Quadrat-Test 13 Lineare Regression 2 Lineare Regression 1 Lineare Regression 1 ‚Äúper Hand‚Äù in R 14 Klausurvorbereitung Lineare Regression 2 Lineare Regression 2 ‚Äúper Hand‚Äù in R 15 Statistik hinterfragen Klausurvorbereitung Lineare Regression 3 in R Der prinzipielle Lernmodus in diesem digitalen Semester ist das Lesen von Kapiteln aus dem vorliegenden Skript und aus zwei Lehrb√ºchern (Zimmermann-Janschitz (2014) und Mittag (2016)). Dazu gibt es kleine Quizzes jede Woche. Diese werden automatisch bewertet und sind Voraussetzung f√ºr den Erhalt der 3 Leistungspunkte des Seminars Einf√ºhrung in die Statistik. Im Seminar jeden Montag besteht die M√∂glichkeit, Fragen zu kl√§ren und den Stoff der vorherigen Woche zu diskutieren. Das Seminar findet √ºber ZOOM statt - s. permanenter link auf Moodle. Wichtig: Fragen und Diskussionsw√ºnsche m√ºssen bis Ende jeder Woche √ºber das Moodleforum eingereicht werden. Manche Fragen werden sich bereits √ºber das Forum kl√§ren lassen. Im Selbststudium - unterst√ºtzt durch das Seminar - erarbeiten Sie sich so die Theorie, welche dann in der PC-√úbung mittels der Software R zur Anwendung kommt. Die PC-√úbung findet ab 27. November immer freitags 09:00-12:00 statt, ebenfalls √ºber ZOOM. Wir werden mehrere thematische ZOOM-R√§ume anbieten, in die Sie nach Bedarf gehen k√∂nnen (Fragen zu Hausaufgaben, Fragen zu R, Fragen zur Theorie, ‚Ä¶). In diesem Zeitfenster bearbeiten Sie jede Woche einen √úbungszettel. Die Lehrende stehen w√§hrend dessen in den ZOOM-R√§umen f√ºr Fragen zur Verf√ºgung. Ein L√∂sungszettel wird am Ende bereit gestellt. Abschlie√üend gibt es eine neue Hausaufgabe bis zur n√§chsten Woche. Der L√∂sungszettel wird vor der n√§chsten √úbung bereit gestellt. Au√üerhalb des Zeitfensters am Freitag beantworten wir Fragen √ºber das Moodle Forum. In den Hausaufgaben wird in der √úbung Erprobtes auf einen anderen Datensatz angewendet oder erweitert. Die Hausaufgaben sind Voraussetzung f√ºr den Erhalt der 3 Leistungspunkte der PC-√úbung Statistische Datenverarbeitung. Die Abgabe erfolgt √ºber einen Abgabelink auf Moodle bis zum n√§chsten Mittwoch 24:00. Das Abgabeformat (HTML via R Markdown) wird in der ersten PC-√úbung ausf√ºhrlich erkl√§rt und einge√ºbt. Es beinhaltet den R-Code, einen kurzen Text zur Beantwortung der Fragestellung bzw. Interpretation der Ergebnisse, sowie relevante (!) Abbildungen, Tabellen und Kenngr√∂√üen. Am Donnerstag wird das L√∂sungsblatt bereit gestellt. Unklarheiten und Probleme werden w√§hrend der n√§chsten √úbung gekl√§rt (eigener ZOOM-Raum). Ein kurzes Wort zu unseren Erwartungen: In diesem digitalen Semester wird selbst√§ndiges Lernen noch wichtiger sein als in Pr√§senzsemestern. Das Seminar entspricht mit 3 Leistungspunkten einem Aufwand von 90 Stunden, d.h. 6 Stunden pro Woche. Bei maximal 1,5 Stunden ‚ÄúPr√§senz‚Äù via ZOOM verbleiben mindestens 4,5 Stunden pro Woche f√ºr das Selbststudium des Skriptes und der ausgew√§hlten Lehrbuchkapitel. Die PC-√úbung entspricht mit 3 Leistungspunkten ebenfalls 90 Stunden, d.h. 7,5 Stunden pro Woche ab Semesterwoche 4. Bei 3 Stunden ‚ÄúPr√§senz‚Äù via ZOOM verbleiben weitere 4,5 Stunden pro Woche f√ºr Nachbereitung und Hausaufgaben. Insgesamt sollten Sie sich also auf 9 Stunden pro Woche selbstst√§ndiges Arbeiten f√ºr Statistik einstellen. Die Modulabschlusspr√ºfung ist dieses Jahr eine sogenannte take-home Klausur, die Sie - voraussichtlich in der 1. Semesterferienwoche - zuhause in einem vorgegeben Zeitrahmen selbst√§ndig bearbeiten. Ein Nachholtermin findet voraussichtlich in der letzten Semesterferienwoche statt. Die Anmeldung erfolgt gegen Semesterende √ºber AGNES bei Frau Schwedler. Die take-home Klausur wird stark an die √úbungen und Hausaufgaben angelehnt sein. Dazu wird es ein paar Fragen √ºber Moodle geben - √§hnlich der regelm√§√üigen Quizzes. Insgesamt werden sich 5/6 der zu erreichenden Punktzahl auf Einf√ºhrung in die Statistik beziehen und 1/6 auf Einf√ºhrung in die Geographie. 1.4 Mathematische Notation und Grundlagen In diesem Unterkapitel werden wichtige Begriffe eingef√ºhrt und wichtige mathematische Grundlagen aus der Schule wiederholt. Lesen Sie bitte dazu Kapitel 1.2 von Zimmermann-Janschitz (2014). Dort werden anhand des Beispieles der Kostenaufstellung f√ºr eine ‚ÄúStatistikexkursion‚Äù die Begriffe Variable, Index und Summe eingef√ºhrt. Variable wird synonym mit Merkmal verwendet. In den Zeilen der Tabelle 1.1 in Zimmermann-Janschitz (2014) stehen dann die einzelnen Merkmalswerte oder einfach nur Werte f√ºr die Untersuchungselemente (statistische Einheiten). Jede statistische Einheit ist gekennzeichnet durch einen eigenen Index. An dieser Stelle sei erg√§nzt, dass ein Index auch unterschiedliche Variablen bezeichnen kann, z.B. \\(x_1, x_2, \\ldots\\). Die Summe verschiedener Merkmalswerte wird wie folgt abgek√ºrzt: \\[\\begin{equation} \\sum_{i=1}^{n}x_i=x_1+x_2+\\ldots+x_{n-1}+x_n \\tag{1.1} \\end{equation}\\] Wobei das Summenzeichen \\(\\Sigma\\) die Anweisung symbolisiert, die Merkmalswerte \\(x_i\\) zu addieren, wobei der Index \\(i\\) von 1 bis zur Anzahl der Werte \\(n\\) l√§uft. Eine √§hnliche verk√ºrzte Schreibweise gibt es f√ºr das Produkt: \\[\\begin{equation} \\prod_{i=1}^{n}x_i=x_1 \\cdot x_2 \\cdot \\ldots \\cdot x_{n-1} \\cdot x_n \\tag{1.2} \\end{equation}\\] Hier gibt das Produktzeichen \\(\\Pi\\) die Anweisung, die Merkmalswerte \\(x_i\\) zu multiplizieren, wobei wiederum der Index \\(i\\) von 1 bis zur Anzahl der Werte \\(n\\) l√§uft. Manchmal wird das Multiplikationszeichen weggelassen und es findet sich nur ein kleiner Abstand zwischen den zu multiplizierenden Gr√∂√üen: \\[\\begin{equation} \\prod_{i=1}^{n}x_i=x_1 \\, x_2 \\, \\ldots \\, x_{n-1} \\, x_n \\tag{1.3} \\end{equation}\\] Diese Schreibweise, die man h√§ufig aus Platzgr√ºnden findet, impliziert in jedem Fall eine Multiplikation. Zwei weitere Begriffe, die Zimmermann-Janschitz (2014) nicht einf√ºhrt, sind f√ºr diese Lehrveranstaltung noch wichtig, Vektor und Matrix: In einem Reihenvektor sind Gr√∂√üen (z.B. Merkmalswerte) horizontal angeordnet: \\[\\mathbf{x} = \\begin{pmatrix} x_1 &amp; x_2 &amp; \\cdots &amp; x_n \\end{pmatrix}\\] In einem Spaltevektor sind die Gr√∂√üen vertikal angeordnet: \\[\\mathbf{x} = \\begin{pmatrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{pmatrix}\\] In einer Matrix sind Gr√∂√üen wie in einer Tabelle angeordnet, z.B. Merkmalswerte unterschiedlicher Variablen (Spalten): \\[\\mathbf{X} = \\begin{pmatrix} x_{1,1} &amp; x_{1,2} &amp; \\cdots &amp; x_{1,p}\\\\ x_{2,1} &amp; x_{2,2} &amp; \\cdots &amp; x_{2,p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ x_{n,1} &amp; x_{n,2} &amp; \\cdots &amp; x_{n,p} \\end{pmatrix}\\] Hier hat jeder Merkmalswert zwei Indices, einen f√ºr die statistische Einheit (hier bis Anzahl \\(n\\)) und einen f√ºr die Variable (hier bis Anzahl \\(p\\)). Vektoren und Matrizen werden in der Regel fett gedruckt, wobei Vektoren mit Kleinbuchstaben und Matrizen mit Gro√übuchstaben bezeichnet werden. Die Rechenregeln f√ºr Vektoren und Matrizen sind in der linearen Algebra zusammengefasst. Wir werden daraus nur Ausz√ºge in den letzten Semesterwochen verwenden. Aufgabe: Zu diesen Begriffen gibt es ebenfalls ein kleines Quiz zu beantworten - s. Moodle unter Woche 1. 1.4.1 Exponential- und Logarithmusfunktion Zwei mathematische Funktionen sind f√ºr diese Lehrveranstaltung besonders wichtig, die Exponential- und die Logarithmusfunktion. Die folgende Darstellung ist inspiriert von Gelman and Nolan (2002). Stellen Sie sich eine Am√∂be vor, die sich innerhalb einer Stunde teilt (Abbildung 1.1). Diese zwei Am√∂ben teilen sich jede in einer weiteren Stunde usw. Wie lautet die Gleichung f√ºr die Anzahl Am√∂ben, \\(y\\), als Funktion der Zeit, \\(t\\) (in Stunden)? Figure 1.1: Sich teilende Am√∂be. Quelle: http://www.gutenberg.org/files/18451/18451-h/images/illus002.jpg. Die Gleichung lautet: \\[\\begin{equation} y=2^t \\tag{1.4} \\end{equation}\\] Dies ist eine Exponentialfunktion mit Basis 2 and Exponent \\(t\\). Abbildung 1.2 zeigt zwei Plots dieser Funktion. (Den verwendeten R code werden sie im Verlauf der PC-√úbung verstehen.) t &lt;- seq(1, 6) y &lt;- 2^t plot(t, y, pch = 19, type = &#39;b&#39;) plot(t, log(y), pch = 19, type = &#39;b&#39;) Figure 1.2: Links: Plot von Gleichung 1.4. Right: Plot von Gleichung 1.4 auf logarithmischer Skala. Die Umkehrfunktion der Exponentialfunktion ist die Logarithmusfunktion: \\[\\begin{equation} log(y)=log(2^t)=t \\cdot log(2) \\tag{1.5} \\end{equation}\\] Da der Logarithmus von \\(y\\) eine lineare Funktion von \\(t\\) ist (Gleichung (1.5)), zeigt die rechte Seite von Abbildung 1.2 (\\(y\\) auf logarithmischer Skala) eine gerade Linie. √úbliche Basen der Logarithmusfunktion sind: \\[\\begin{equation} log_2\\left(2^t\\right)=lb\\left(2^t\\right)=t \\tag{1.6} \\end{equation}\\] Dies ist der sogenannte bin√§re Logarithmus (lb). \\[\\begin{equation} log_{10}\\left(10^t\\right)=lg\\left(10^t\\right)=t \\tag{1.7} \\end{equation}\\] Dies ist der sogenannte dekadische Logarithmus (lg). \\[\\begin{equation} log_e\\left(e^t\\right)=ln\\left(e^t\\right)=t \\tag{1.8} \\end{equation}\\] Dies ist der sogenannte nat√ºrliche Logarithmus (ln), wobei \\(e \\approx 2.7183\\) die Eulersche Zahl ist. Achtung: Programmiersprachen wie R nutzen oft eine andere Notation, der wir auch in diesem Kurs folgen: \\[\\begin{equation} ln()=log() \\tag{1.9} \\end{equation}\\] \\[\\begin{equation} e^t=\\exp(t) \\tag{1.10} \\end{equation}\\] Die Rechenregeln der Exponentialfunktion sind: \\[\\begin{equation} a^m \\cdot a^n=a^{m+n} \\tag{1.11} \\end{equation}\\] \\[\\begin{equation} a^n \\cdot b^n=(a \\cdot b)^n \\tag{1.12} \\end{equation}\\] \\[\\begin{equation} \\frac{a^m}{a^n}=a^{m-n} \\tag{1.13} \\end{equation}\\] \\[\\begin{equation} \\frac{a^n}{b^n}=\\left(\\frac{a}{b}\\right)^n \\tag{1.14} \\end{equation}\\] \\[\\begin{equation} \\left(a^m\\right)^n=a^{m \\cdot n} \\tag{1.15} \\end{equation}\\] Die Rechenregeln der Logarithmusfunktion sind: \\[\\begin{equation} log(u \\cdot v)=log(u)+log(v) \\tag{1.16} \\end{equation}\\] \\[\\begin{equation} log\\left(\\frac{u}{v}\\right)=log(u)-log(v) \\tag{1.17} \\end{equation}\\] \\[\\begin{equation} log\\left(u^r\\right)=r \\cdot log(u) \\tag{1.18} \\end{equation}\\] 1.4.2 Quadratische Funktion und Wurzelfunktion Abschlie√üend sei noch die quadratische Funktion erw√§hnt (Abbildung 1.3, links): \\[\\begin{equation} f(x)=x^2 \\tag{1.19} \\end{equation}\\] x &lt;- seq(0, 5, 0.1) plot(x, x^2, pch = 19, type = &#39;b&#39;) plot(x, sqrt(x^2), pch = 19, type = &#39;b&#39;) Figure 1.3: Links: Quadratische Funktion von \\(x\\). Right: Wurzelfunktion von \\(x^2\\) (Gleichung 1.20). Und ihre Umkehrfunktion, die Wurzelfunktion (Abbildung 1.3, rechts): \\[\\begin{equation} \\sqrt{x^2}=x \\tag{1.20} \\end{equation}\\] Literatur "],
["begriffe.html", "Chapter 2 Grundbegriffe und Datenerhebung 2.1 Statistische Grundbegriffe 2.2 Datenerhebung 2.3 Skalenniveaus", " Chapter 2 Grundbegriffe und Datenerhebung Lesen Sie hierzu bitte Kapitel 3.1.2 und 3.1.3 von Zimmermann-Janschitz (2014). Im folgenden finden Sie Leitfragen und Erg√§nzungen zu diesen Kapiteln. 2.1 Statistische Grundbegriffe Die statistische Masse umfasst all jene Elemente (Anzahl \\(N\\)), die f√ºr eine statistische Untersuchung Relevanz besitzen. F√ºr die Bestimmung der statistischen Masse sind inhaltliche, zeitliche und r√§umliche Abgrenzungskriterien erforderlich. Alternative Begriffe sind (die gel√§ufigsten fett gedruckt): statistische Grundmenge, Grundgesamtheit, Population, Kollektiv. Beispiele finden Sie in Zimmermann-Janschitz (2014), Kapitel 3.1.3. Die statistische Einheit \\(e_i\\) mit \\(i=1, \\ldots, n\\) stellt das Untersuchungselement und somit die kleinste, nicht weiter unterteilbare Einheit in einer statistischen Untersuchung dar. Diese statistische Einheit tr√§gt jene Information (auch als Merkmal \\(x\\) bezeichnet), die im Zentrum der statistischen Untersuchung steht. Alternative Begriffe sind, je nach Kontext: Untersuchungseinheit, Proband, Merkmalstr√§ger. Siehe Zimmermann-Janschitz (2014), Kapitel 3.1.3 f√ºr Beispiele. Jene Eigenschaft eines Untersuchungselements, die f√ºr die statistische Untersuchung von Bedeutung ist, wird als Merkmal \\(x\\) des Elements bezeichnet. Eine statistische Einheit weist mindestens ein Merkmal auf, kann aber ebenso durch mehrere Merkmale gekennzeichnet sein. Alternative Begriffe sind: Variable, Indikator. Beispiele finden Sie wiederum in Zimmermann-Janschitz (2014), Kapitel 3.1.3. Die Merkmalsauspr√§gungen \\(a_j\\) mit \\(j=1, \\ldots, m\\) eines Merkmals \\(x\\) umfassen jene Manifestationen, die ein Merkmal im Rahmen einer statistischen Untersuchung annehmen kann. Alternative Begriffe sind: Merkmalskategorien, Modalit√§ten. Z.B. kann das Merkmal Schneedeckenh√∂he Werte von null (kein Schnee vorhanden) bis zu mehreren Metern einnehmen. Der Merkmalswert \\(x_i\\) mit \\(i=1, \\ldots, n\\) schlie√ülich ist jener Wert, den ein Merkmal \\(x\\) in einer statistischen Untersuchung tats√§chlich annimmt. Alternative Begriffe sind: Beobachtungswert, Datum (Plural: Daten). Beispiel: Tats√§chliche Schneedeckenmessung an einem Punkt von 285,5cm. 2.2 Datenerhebung Leitfragen zu Zimmermann-Janschitz (2014), Kapitel 3.1.2: Was ist der Unterschied zwischen Prim√§rdaten und Sekund√§rdaten? Was sind die Vor- und Nachteile? Was sind Metadaten? Wozu sind sie wichtig? Was ist der Unterschied zwischen Gesamterhebung und Teilerhebung? Zur Prim√§rdatenerhebung h√∂ren Sie mehr von Henning Nuissl im Seminar Einf√ºhrung in die Geographie. An dieser Stelle aber noch ein paar Worte zur Auswahl einer Stichprobe aus einer Grundgesamtheit. Aus statistischer Perspektive sind dabei prinzipiell drei Aspekte zu beachten: Repr√§sentativit√§t: Eine Stichprobe sollte die Variabilit√§t der Grundgesamtheit m√∂glichst genau abbilden, z.B. bez√ºglich Demographien oder r√§umlicher Unterschiede. Zuf√§lligkeit: Jede Merkmalsauspr√§gung der Grundgesamtheit sollte die gleiche ‚ÄúChance‚Äù haben ausgew√§hlt zu werden. In der Praxis ist dies oft nur n√§herungsweise m√∂glich. Stichprobenumfang: Eine Stichprobe sollte ausreichend gro√ü sein. Mehr dazu in der schlie√üenden Statistik (Kapitel 8-12). 2.3 Skalenniveaus Die Skalenniveaus von Daten bestimmen den Informationsgehalt der Daten und damit das Analyse- und Interpretationspotenzial. In der Reihenfolge Nominalskala - Ordinalskala - metrische Skalen werden jeweils zus√§tzliche mathematische Operationen erschlossen (s. Zimmermann-Janschitz (2014), Tabelle 3.8, S. 79). Qualitative, klassifikatorische Merkmale befinden sich auf der Nominalskala. Die Kategorien k√∂nnen verbale Bezeichnungen oder Zahlencodes sein (Achtung: Die Zahl ist in dem Fall ein Code und keine nat√ºrliche Zahl mit der gerechnet werden kann.) Die zul√§ssige mathematische Operation ist der Vergleich, d.h. Merkmalswerte von statistischen Einheiten sind entweder gleich oder verschieden. Beispiel: Art des Vulkanausbruchs (Tabelle 2.1). Obwohl \\(1+2=3\\) ist, ist Lava plus Gestein nicht gleich Gas! Table 2.1: Art des Vulkanausbruchs. Lava Gestein Gas Asche 1 2 3 4 Qualitative, komparative Merkmale (Rangmerkmale) finden Sie auf der Ordinalskala. Wieder k√∂nnen die Kategorien verbale Bezeichnungen sein oder mittels Zahlen codiert. Die Zul√§ssigen mathematischen Operationen sind der Vergleich sowie Wertung/Reihung/Ordnung. Es sind keine Aussagen √ºber Distanz oder √Ñhnlichkeit benachbarter Merkmalsauspr√§gungen m√∂glich. Beispiel: Komfort der Unterkunft (Tabelle 2.2). Der Komfort eines ***Hotels ist gr√∂√üer als der Komfort eines *Hotels, aber nicht 3x so gro√ü! Table 2.2: Komfort der Unterkunft. Jugendherberge *Hotel **Hotel ***Hotel 0 1 2 3 Quantitative Merkmale befinden sich auf metrischen Skalen. Sie werden mit reellen Zahlen bezeichnet. Die zul√§ssigen mathematischen Operationen sind der Vergleich, Wertung/Reihung/Ordnung sowie Addition/Subtraktion und im Falle der Rationalskala auch Multiplikation/Division. Die Unterscheidung Intervallskala und Rationalskala (Verh√§ltnisskala) ist f√ºr uns nicht so wichtig. Intervallskalen fehlt ein nat√ºrlicher Nullpunkt und daher ist die Berechnung von Relationen nicht m√∂glich. Sie kann aber auf einen Referenznullpunkt umgerechnet werden, wodurch Multiplikation und Division m√∂glich wedren. Wenn wir also in diesem Kurs von einer metrischen Skala sprechen dann sind die mathematischen Operationen Vergleich, Wertung/Reihung/Ordnung, Addition/Subtraktion und Multiplikation/Division alle zul√§ssig. Literatur "],
["haeufigkeit.html", "Chapter 3 H√§ufigkeiten und Lageparameter 3.1 Ziel der deskriptiven Statistik 3.2 H√§ufigkeiten 3.3 Lageparameter", " Chapter 3 H√§ufigkeiten und Lageparameter Mit diesem Kapitel des Skriptes steigen wir in die deskriptive Statistik ein. Lesen Sie hierzu bitte Kapitel 3.2.1 und 3.2.2 von Zimmermann-Janschitz (2014). Im folgenden finden Sie wie gehabt Leitfragen und Erg√§nzungen zu diesen Kapiteln. 3.1 Ziel der deskriptiven Statistik Jene Eigenschaft eines Untersuchungselements, die f√ºr die statistische Untersuchung von Bedeutung ist, wird als Merkmal \\(x\\) des Elements bezeichnet. Der Merkmalswert \\(x_i\\) mit \\(i=1,\\ldots,n\\) ist jener Wert, den ein Merkmal \\(x\\) in einer statistischen Untersuchung tats√§chlich annimmt. Ziel der deskriptiven Statistik ist es, die Verteilung der Merkmalswerte eines Merkmals √ºber den m√∂glichen Wertebereich (Auspr√§gungen) mit einzelnen Parametern n√§her zu charakterisieren. Z.B. die Anzahl der Ausbr√ºche eines Vulkans an verschiedenen Tagen. Die Parameter sind: Lageparameter: Ma√üe der zentralen Tendenz einer Verteilung (s. dieses Kapitel) Streuungsparameter: Ma√üe der Variabilit√§t einer Verteilung (s. Kapitel 4) Schiefe und W√∂lbung einer Verteilung (s. Kapitel 4) Dazu brauchen wir erstmal Begriffe wie absolute H√§ufigkeit, relative H√§ufigkeit und Summenh√§ufigkeit sowie Diagramme wie Histogramme und Boxplots, die Verteilungen graphisch darstellen. 3.2 H√§ufigkeiten Schauen wir uns dazu die Reisedaten an, die die Studierenden im letzte Jahr eingegeben hatten, und zwar nur die Entfernungen (der R-Code wird in den PC-√úbungen schnell klar werden): # Ausgabe von dat$x # dies ist die Variable &quot;Entfernung (Luftlinie) zum Wohnort (m)&quot; dat$x ## [1] 11000.00 11080.00 4130.00 32630.00 12000.00 10180.00 5100.00 14380.00 ## [9] NA 18710.00 16341.00 12820.00 7370.00 NA 17630.00 13750.00 ## [17] 13070.00 15300.00 15150.00 20200.00 3890.00 NA NA 15770.00 ## [25] 11630.00 27300.00 8150.00 NA 9580.00 31310.00 NA 21030.00 ## [33] 9790.00 NA 23240.00 8640.00 12620.00 12045.00 10079.00 11200.00 ## [41] 52320.00 11200.00 13290.00 10220.00 1572.00 28580.00 15740.00 10110.00 ## [49] 15220.00 8900.00 1900.00 9650.00 11390.00 9360.00 3000.00 11376.00 ## [57] 12890.00 2500.00 NA 16760.00 18450.00 4570.00 15050.00 14300.00 ## [65] 13260.00 7950.00 NA 15730.00 NA 17830.00 10500.00 517.45 ## [73] 4780.00 13910.00 1027.00 9900.00 17000.00 13065.00 16930.00 16200.00 ## [81] 14420.00 NA 17380.00 6040.00 NA 10800.00 4365.00 15691.00 ## [89] 19520.00 29610.00 13480.00 15940.00 NA NA NA 13350.00 ## [97] 16350.00 3750.00 18000.00 12800.00 3710.00 32000.00 17760.00 4130.00 ## [105] 26560.00 13000.00 12000.00 27470.00 14980.00 10210.00 17440.00 3090.00 ## [113] 9000.00 25070.00 6990.00 6170.00 14470.00 10700.00 39510.00 17430.00 ## [121] 25360.00 21000.00 Das ist eine ungeordnete Reihe von 122 Datenpunkten, die sogenannten Rohdaten. ‚ÄúNA‚Äù steht f√ºr ‚Äúnot available‚Äù, d.h. fehlende Daten. Wenn wir die Rohdaten jetzt ordnen und in Klassen einteilen k√∂nnen wir absolute H√§ufigkeiten bestimmen, gewisserma√üen durch Abz√§hlen: # dat$x aufsteigend ordnen und ausgeben sort(dat$x) ## [1] 517.45 1027.00 1572.00 1900.00 2500.00 3000.00 3090.00 3710.00 ## [9] 3750.00 3890.00 4130.00 4130.00 4365.00 4570.00 4780.00 5100.00 ## [17] 6040.00 6170.00 6990.00 7370.00 7950.00 8150.00 8640.00 8900.00 ## [25] 9000.00 9360.00 9580.00 9650.00 9790.00 9900.00 10079.00 10110.00 ## [33] 10180.00 10210.00 10220.00 10500.00 10700.00 10800.00 11000.00 11080.00 ## [41] 11200.00 11200.00 11376.00 11390.00 11630.00 12000.00 12000.00 12045.00 ## [49] 12620.00 12800.00 12820.00 12890.00 13000.00 13065.00 13070.00 13260.00 ## [57] 13290.00 13350.00 13480.00 13750.00 13910.00 14300.00 14380.00 14420.00 ## [65] 14470.00 14980.00 15050.00 15150.00 15220.00 15300.00 15691.00 15730.00 ## [73] 15740.00 15770.00 15940.00 16200.00 16341.00 16350.00 16760.00 16930.00 ## [81] 17000.00 17380.00 17430.00 17440.00 17630.00 17760.00 17830.00 18000.00 ## [89] 18450.00 18710.00 19520.00 20200.00 21000.00 21030.00 23240.00 25070.00 ## [97] 25360.00 26560.00 27300.00 27470.00 28580.00 29610.00 31310.00 32000.00 ## [105] 32630.00 39510.00 52320.00 # Daten in km umrechnen und absolute H√§ufigkeiten bestimmen # f√ºr Klassen von 0 bis 55km mit Breite 5km hist(dat$x/1000, breaks = seq(0, 55, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) Diese Darstellung ist ein Histogramm. Dazu sp√§ter mehr. Das Ordnen geschieht bei der Erechnung des Histogramms automatisch, hier haben wir es nur der Anschaulichkeit halber eingef√ºgt. Die absolute H√§ufigkeit, bezeichnet mit \\(h_j\\) f√ºr \\(h\\left(a_j\\right)\\) und \\(j=1,\\ldots,m\\), gibt also die Anzahl der statistischen Einheiten in einer Stichprobe an, welche die Merkmalsauspr√§gung \\(a_j\\) f√ºr ein Merkmal \\(x\\) annehmen. In unserem Beispiel haben wir die Merkmalsauspr√§gungen durch Klassifizierung gewisserma√üen k√ºnstlich erzeugt da die Menge der Auspr√§gungen des Merkmals ‚ÄúEntfernung‚Äù ja nicht abz√§hlbar ist. Im Beispiel der Anzahl Vulkanausbr√ºche in Zimmermann-Janschitz (2014) gibt es dagegen abz√§hlbare Merkmalsauspr√§gungen. Die Summe der absoluten H√§ufigkeiten ist der Stichprobenumfang \\(n\\): \\[\\sum_{j=1}^{m}h_j=n \\quad\\text{mit}\\quad m\\leq n\\] Die relative H√§ufigkeit, bezeichnet mit \\(f_j\\) f√ºr \\(f\\left(a_j\\right)\\) und \\(j=1,\\ldots,m\\), gibt dann den Anteil der statistischen Einheiten an einer Stichprobe an, welche die Merkmalsauspr√§gung \\(a_j\\) f√ºr ein Merkmal \\(x\\) annehmen: \\[f_j=f\\left(a_j\\right)=\\frac{h\\left(a_j\\right)}{n}\\] Das Histogramm bleibt gleich, nur dass die vertikale Achse anders skaliert ist. Da das in der hist() Funktion nicht vorgesehen ist, ist der R-Code etwas l√§nger: # Histogramm berechnen ohne Output h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) # absolute in relative H√§ufigkeiten umrechnen h$counts &lt;- h$counts / sum(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;relative H√§ufigkeit&quot;) Interpretation: Der ersten Balken z.B. geht bis knapp unter 0.15, d.h. knapp 15% der Entfernungsdaten haben Werte zwischen 0 und 5km. Wenn wir uns das Histogramm der absoluten H√§ufigkeiten weiter oben anschauen dann sehen wir, dass das etwa 15 von 107 Datenpunkten (ohne ‚ÄúNA‚Äù) sind. Die Summe der relativen H√§ufigkeiten ist 1, was 100% entspricht: \\[\\sum_{j=1}^{m}f_j=1 \\quad\\text{mit}\\quad m\\leq n\\] Kommen wir nun zu den Summenh√§ufigkeiten, auch genannt kumulative H√§ufigkeit oder kumulierte H√§ufigkeit. Die absolute Summenh√§ufigkeit einer Merkmalsauspr√§gung \\(a_j\\) ist die Anzahl der Merkmalswerte, die kleiner oder gleich \\(a_j\\) sind. Die relative Summenh√§ufigkeit von \\(a_j\\) ist dementsprechend der Anteil der Merkmalswerte, die kleiner oder gleich \\(a_j\\) sind. Am besten visualisieren wir das kurz in R: # Histogramm berechnen ohne Output h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) # H√§ufigkeiten kumuliert aufsummieren h$counts &lt;- cumsum(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Summenh√§ufigkeit&quot;) # absolute Summenh√§ufigkeiten in relative umrechnen h$counts &lt;- h$counts / max(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;relative Summenh√§ufigkeit&quot;) Die H√§ufigkeiten der Klassen sind hier kumuliert aufsummiert, d.h. der letzte Balken ganz rechts hat die absolute H√∂he 107, die Gesamtzahl der Datenpunkte \\(n\\) (ohne ‚ÄúNA‚Äù), bzw. die relative H√∂he 1 (100%). Sehen die dazu auch das Beispiel in Zimmermann-Janschitz (2014), Tabelle 3.10 auf Seite 87. Abschlie√üend noch ein paar Worte zur Klassifizierung. √Ñquidistante Klassen, d.h. Klassen gleicher Breite, sind grunds√§tzlich zu bevorzugen. In R k√∂nnen Sie eine gew√ºnschte Anzahl Klassen angeben, die dann √§quidistant √ºber den Wertebereich verteilt werden. Das ist sinnvoll f√ºr einen ersten Eindruck. Die Grundeinstellung von 10 Klassen ist dabei meist ausreichend. Im Laufe der Analyse wird es manchmal sinnvoller sein, bestimmte Klassen vorzugeben, auch (oder gerade) wenn manche Klasse in der betrachteten Stichprobe nicht vorkommen. Auch das ist in R m√∂glich, in dem Sie die Klassengrenzen (‚Äúbreaks‚Äù) angeben. Probieren wir das in R aus: # Klassenbreite 5km hist(dat$x/1000, breaks = seq(0, 60, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) # Klassenbreite 10km hist(dat$x/1000, breaks = seq(0, 60, 10), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) # Klassenbreite 20km hist(dat$x/1000, breaks = seq(0, 60, 20), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) Je gr√∂√üer die Klassenbreite desto mehr Nuancen der Verteilung der Werte geht verloren. Je kleiner die Klassenbreite desto mehr L√ºcken entstehen im Histogramm und die generelle Form der Verteilung tritt in den Hintergrund. Eine geeignete mittlere Klassenbreite wird man nur durch Ausprobieren hinbekommen. Siehe aber Zimmermann-Janschitz (2014), S. 91-102 f√ºr Richtlinien zur Klassenbildung. 3.3 Lageparameter Lageparameter sind Ma√üe der zentralen Tendenz einer H√§ufigkeitsverteilung. Siehe Zimmermann-Janschitz (2014), Kapitel 3.2.2. Wichtig sind uns in dieser Veranstaltung der Modus, das arithmetische Mittel und der Median, weniger das harmonische Mittel und das geometrische Mittel, die Sie aber bei Zimmermann-Janschitz (2014) nachlesen k√∂nnen. Der Modus \\(\\bar x_{mod}\\) entspricht jener Merkmalsauspr√§gung \\(a_j\\), die in der H√§ufigkeitsverteilung (lokal) am h√§ufigsten vorkommt. In unseren Entfernungsdaten w√§re das der Wert 12.5: h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) # Gib Klassenmitte aus an der Stelle wo die H√§ufigkeiten gleich dem Maximum sind h$mids[h$counts==max(h$counts)] ## [1] 12.5 Bei ‚Äúk√ºnstlichen‚Äù Klassen wie in unserem Beispiel wird typischerweise die Mitte der h√§ufigsten Klasse angegeben. Sie sehen also, der Modus ist in diesem Fall abh√§ngig von der gew√§hlten Klassifizierung und nicht eindeutig. In der obigen Darstellung sehen wir au√üerdem ein zweites lokales Maximum bei 27.5, es handelt sich also in dieser Klassifizierung um eine bimodale Verteilung. Der generelle Begriff f√ºr mehrere Modi ist multimodal. Das arithmetische Mittel \\(\\bar x\\) der Merkmalswerte \\(x_1, x_2, \\ldots, x_n\\) ist die Summe aller Merkmalswerte \\(x_i\\) relative zur Stichprobengr√∂√üe \\(n\\): \\[\\bar x=\\frac{\\sum_{i=1}^{n}x_i}{n}\\] Liegen absolute oder relative H√§ufigkeiten f√ºr die Merkmalsauspr√§gungen \\(a_j\\) vor, kann das arithmetische Mittel \\(\\bar x\\) gewichtet berechnet werden: \\[\\bar x=\\frac{\\sum_{j=1}^{m}a_j\\cdot h_j}{n}=\\sum_{j=1}^{m}a_j\\cdot f_j\\quad\\text{mit}\\quad m\\leq n\\] Berechnen wir das arithmetische Mittel f√ºr unsere Entfernungsdaten mit der Funktion mean: # berechne arithmetisches Mittel f√ºr Variable &quot;Entfernung&quot; (x) in km, # wobei &quot;NA&quot; Werte ignoriert werden sollen (sonst w√§re die Ausgabe ebenfalls &quot;NA&quot;) mean(dat$x/1000, na.rm = TRUE) ## [1] 13.95896 Andere Mittelwerte sind das geometrische Mittel und das harmonische Mittel, siehe Zimmermann-Janschitz (2014), S. 126-134. Der Median \\(\\bar x_{med}\\) schlie√ülich entspricht jenem Merkmalswert \\(x_j\\) in einer H√§ufigkeitsverteilung, der eine geordnete Reihe von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) in zwei gleich gro√üe Wertebereiche teilt. F√ºr eine ungerade Anzahl von Merkmalswerten entspricht der Median dem mittleren Wert: \\[\\bar x_{med}=x_{\\frac{n+1}{2}}\\] F√ºr eine gerade Anzahl von Merkmalswerten wird der Median aus dem arithmetischen Mittel der beiden mittleren Werte errechnet: \\[\\bar x_{med}=\\frac{x_{\\frac{n}{2}}+x_{\\frac{n}{2}+1}}{2}\\] Berechnen wir den Median f√ºr unsere Entfernungsdaten mit der Funktion median: median(dat$x/1000, na.rm = TRUE) ## [1] 13.065 Der Median wird auch 0,5-Quantil genannt. Allgemein entspricht ein p-Quantil \\(\\bar x_p\\) mit \\(0\\leq p\\leq 1\\) jenem Merkmalswert \\(x_j\\) in einer H√§ufigkeitsverteilung, der eine geordnete Reihe von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) in zwei Wertebereiche teilt, so dass ein Anteil \\(p\\) der Werte kleiner oder gleich \\(x_j\\) ist. Ist das Produkt \\(n\\cdot p\\) nicht ganzzahlig, wird f√ºr \\(j\\) die dem Produkt n√§chstgr√∂√üere Zahl verwendet: \\[\\bar x_p=x_j\\] Ist das Produkt \\(n\\cdot p\\) ganzzahlig, dann ist \\(j=n\\cdot p\\): \\[\\bar x_p=\\frac{x_j+x_{j+1}}{2}\\] Auf Quantile werden wir im Zuge theoretischer Verteilungen noch n√§her zu sprechen kommen (Kapitel 7). Literatur "],
["streuung.html", "Chapter 4 Streuungsparameter, Schiefe und W√∂lbung 4.1 Streuungsparameter 4.2 Schiefe und W√∂lbung von H√§ufigkeitsverteilungen", " Chapter 4 Streuungsparameter, Schiefe und W√∂lbung 4.1 Streuungsparameter Lesen Sie dazu bitte Kapitel 3.2.3 von Zimmermann-Janschitz (2014). Streuungsparameter sind Ma√üe der Variabilit√§t einer H√§ufigkeitsverteilung. Uns interessieren hier v.a. Spannweite, Quartilsabstand, Varianz und Standardabweichung und Variationskoeffizient, weniger durchschnittliche absolute Abweichung, da wir leztere kaum in der Praxis sehen. Spannweite und Quartilsabstand lassen sich am besten mit einem sogenannten Box-Whisker-Plot, kurz einfach Boxplot, verdeutlichen (Abbildung 4.1). Ein Boxplot fasst die Verteilung der Werte eines Merkmals (in einer Stichprobe) zusammen. Die Spannweite ist der Abstand zwischen Minimum und Maximum der Merkmalswerte. Der Quartilsabstand ist der Abstand zwischen 0,25-Quantil und 0,75-Quantil; in diesem Bereich liegen 50% der Merkmalswerte (0,75-0,25). 0,25-Quantil, 0,5-Quantil (Median) und 0,75-Quantil heissen auch 1., 2. und 3. Quartil, weil sie den Wertebereich in vier gleichgro√üe Teile teilen: Zwischen Minimum und 0,25-Quantil liegen 25% der Merkmalswerte, zwischen 0,25-Quantil und Median 25%, zwischen Median und 0,75-Quantil 25% und zwischen 0,75-Quantil und Maximum ebenfalls 25%. Ebenso gibt es auch Quintile usw., diese sind aber in der Praxis kaum von Bedeutung. Ein Boxplot kann horizontal wie hier und vertikal dargestellt werden. Figure 4.1: Boxplot mit Quartilsabstand und Spannweite. Der Boxplot ist eine vereinfachte Darstellung eines Histogramms. Schauen Sie sich dazu bitte Kapitel 4.3.6 von Zimmermann-Janschitz (2014) an, besonders Abbildung 4.10. Sehen Sie welcher Boxplot in 4.10b zu welchem Histogramm in 4.10c geh√∂rt? Die Entsprechung k√∂nnen Sie auch in unseren Reisedaten sehen (hier sowohl ‚ÄúEntfernung‚Äù als auch ‚ÄúReisezeit‚Äù): # Histogramm &quot;Entfernung&quot; in km hist(dat$x/1000, breaks = seq(0, 55, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) # Histogramm &quot;Reisezeit&quot; in min hist(dat$t, breaks = seq(0, 120, 10), main = &quot;&quot;, xlab = &quot;Reisezeit (min)&quot;, ylab = &quot;absolute H√§ufigkeit&quot;) # Boxplot &quot;Entfernung&quot; in km boxplot(dat$x/1000, range = 0, horizontal = TRUE, ylim = c(0,55), xlab = &quot;Entfernung (km)&quot;) # Boxplot &quot;Reisezeit&quot; in min boxplot(dat$t, range = 0, horizontal = TRUE, ylim = c(0,120), xlab = &quot;Reisezeit (min)&quot;) ‚ÄúEntfernung‚Äù ist schief verteilt, die zentralen 50% der Verteilung - die ‚ÄúBox‚Äù im Boxplot - befinden sich links der Mitte. ‚ÄúReisezeit‚Äù dagegen ist ann√§hernd symmetrisch verteilt, mit der Box in Mitte des Plots. Es ist wichtig f√ºr das Verst√§ndnis von Verteilungen in Kapitel 7, dass sie den Zusammenhang zwischen Histogramm und Boxplot verstehen! Nun zu den weiteren Streuungsparametern. Die Varianz \\(s^2\\) ist die mittlere (‚Äúdurchschnittliche‚Äù) quadrierte Abweichung der Merkmalswerte \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) vom arithmetischen Mittel \\(\\bar x\\): \\[s^2=\\frac{\\sum_{i-1}^{n}\\left(x_i-\\bar x\\right)^2}{n-1}\\] Genau genommen ist das die korrigierte Varianz, wo durch \\(n-1\\) geteilt wird und nicht durch \\(n\\) wie man bei einer Mittelung erwarten w√ºrde. Das Teilen durch \\(n-1\\) garantiert eine optimale Sch√§tzung der Varianz der Grundgesamtheit anhand der Stichprobe - mehr dazu in der schlie√üenden Statistik. Der Nenner \\(n-1\\) wird Anzahl Freiheitsgrade genannt und bezeichnet die Anzahl der Werte in einer Stichprobe, die f√ºr die Berechnung des Parameters (hier Varianz) frei zur Verf√ºgung stehen. Im Fall der Varianz ist ein Wert der Stichprobe bereits ‚Äúbelegt‚Äù ‚Äì durch das arithmetische Mittel. Daher reduziert sich die Zahl der Elemente der Stichprobe, die in die Berechnung eingehen um eins. Die Standardabweichung \\(s\\) ist die Quadratwurzel der mittleren quadrierten Abweichung der Merkmalswerte \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) vom arithmetischen Mittel \\(\\bar x\\), d.h. die Quadratwurzel der Varianz: \\[s=\\sqrt{s^2}=\\sqrt{\\frac{\\sum_{i-1}^{n}\\left(x_i-\\bar x\\right)^2}{n-1}}\\] Die Standardabweichung besitzt die gleiche Einheit wie die Merkmalswerte und ist deshalb einfacher zu interpretieren als die Varianz. Sie dr√ºckt die Streuung der Merkmalswerte um den Mittelwert bzw. deren Abweichung vom Mittelwert in einer anschaulichen Gr√∂√üe aus. Je gr√∂√üer die Werte der Standardabweichung sind, desto mehr streuen die Daten. Der Variationskoeffizient \\(v\\) einer H√§ufigkeitsverteilung mit den Merkmalswerten \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) schlie√ülich ist die Standardabweichung \\(s\\) im Verh√§ltnis zum Mittelwert \\(\\bar x\\): \\[v=\\frac{s}{\\bar x}\\] Der Variationskoeffizient setzt die Streuung der Merkmalswerte in unmittelbare Relation zum arithmetischen Mittel. Dadurch werden unterschiedliche Verteilungen vergleichbar. Schauen wir uns die Streungsparameter f√ºr die Reisedaten mittels R an: # &quot;Entfernung&quot; in km # arithmethisches Mittel xbar &lt;- mean(dat$x/1000, na.rm = TRUE) xbar ## [1] 13.95896 # Varianz s2x &lt;- var(dat$x/1000, na.rm = TRUE) s2x ## [1] 68.74909 # Standardabweichung sx &lt;- sqrt(s2x) sx ## [1] 8.291507 sx &lt;- sd(dat$x/1000, na.rm = TRUE) sx ## [1] 8.291507 # Variationskoeffizient vx &lt;- sx / xbar vx ## [1] 0.5939919 # &quot;Reisezeit&quot; in min # arithmethisches Mittel tbar &lt;- mean(dat$t, na.rm = TRUE) tbar ## [1] 50.80612 # Varianz s2t &lt;- var(dat$t, na.rm = TRUE) s2t ## [1] 365.0445 # Standardabweichung st &lt;- sd(dat$t, na.rm = TRUE) st ## [1] 19.10614 # Variationskoeffizient vt &lt;- st / tbar vt ## [1] 0.3760598 Obwohl ‚ÄúReisezeit‚Äù im Vergleich zu ‚ÄúEntfernung‚Äù eine viel gr√∂√üere Varianz hat ist der Variationskoeffizient kleiner, da Reisezeit auf einer gr√∂√üeren Skala gemessen wird. 4.2 Schiefe und W√∂lbung von H√§ufigkeitsverteilungen Lesen Sie dazu bitte Kapitel 3.2.5 von Zimmermann-Janschitz (2014). Die Schiefe \\(a_3\\) einer H√§ufigkeitsverteilung von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) mit dem arithmetischen Mittel \\(\\bar x\\) und der Standardabweichung \\(s\\) bezeichnet die Abweichung der Verteilung der Merkmalswerte von der symmetrischen Form: \\[a_3=\\frac{\\sum_{i=1}^{n}\\left(x_i-\\bar x\\right)^3}{n\\cdot s^3}\\] F√ºr eine symmetrische Verteilung gilt: \\[a_3=0\\quad \\bar x_{mod}=\\bar x_{med}=\\bar x\\] D.h. Modus, Median und Arithmetisches Mittel sind identisch. F√ºr eine sogenannte rechtsschiefe (linkssteile) Verteilung gilt: \\[a_3&gt;0\\quad \\bar x_{mod}&lt;\\bar x_{med}&lt;\\bar x\\] F√ºr eine linkschiefe (rechtssteile) Verteilung gilt: \\[a_3&lt;0\\quad \\bar x_{mod}&gt;\\bar x_{med}&gt;\\bar x\\] Wie wir an Histogramm und Boxplot der Entfernungsdaten bereits gesehen haben ist die Verteilung des Merkmals ‚ÄúEntfernung‚Äù rechtsschief: library(moments) # Schiefe skewness(dat$x/1000, na.rm = TRUE) ## [1] 1.430997 # Modus(=12.5) &lt; Median &lt; arithm. Mittelwert median(dat$x/1000, na.rm = TRUE) ## [1] 13.065 mean(dat$x/1000, na.rm = TRUE) ## [1] 13.95896 Die Verteilung des Merkmals ‚ÄúReisezeit‚Äù dagegen ist weniger rechtsschief, ann√§hernd symmetrisch, was man auch daran sieht, dass der Median und das aritmetische Mittel fast identisch sind: # Schiefe skewness(dat$t, na.rm = TRUE) ## [1] 0.4462817 # Modus(=45) &lt; Median &lt; arithm. Mittelwert median(dat$t, na.rm = TRUE) ## [1] 50 mean(dat$t, na.rm = TRUE) ## [1] 50.80612 Die W√∂lbung \\(a_4\\) einer H√§ufigkeitsverteilung von Merkmalswerten ùë•\\(x_1, x_2, \\ldots, x_n\\) mit dem arithmetischen Mittel \\(\\bar x\\) und der Standardabweichung \\(s\\) bestimmt die Steilheit einer Verteilung: \\[a_4=\\frac{\\sum_{i=1}^{n}\\left(x_i-\\bar x\\right)^4}{n\\cdot s^4}-3\\] Die Subtraktion von ‚Äú-3‚Äù dient der Standardisierung auf die sogenannte Normalverteilung, eine symmetrische, glockenf√∂rmige Verteilung (s. Zimmermann-Janschitz (2014), Kapitel 3.2.5). Mehr zur Normalverteilung in Kapitel 7. F√ºr eine Normalverteilung gilt: \\[a_4=0\\] F√ºr eine spitzere Verteilung als die Normalverteilung gilt: \\[a_4&gt;0\\] F√ºr eine flachere Verteilung als die Normalverteilung gilt: \\[a_4&lt;0\\] Die Verteilungen der Merkmale unserer Reisedaten sind beide spitzer als die Normalverteilung, wobei ‚ÄúEntfernung‚Äù wegen der Rechtsschiefe garnicht mit der Normalverteilung vergleichbar ist: # W√∂lbung &quot;Entfernung&quot; kurtosis(dat$x/1000, na.rm = TRUE) - 3 ## [1] 3.86359 # W√∂lbung &quot;Reisezeit&quot; kurtosis(dat$t, na.rm = TRUE) - 3 ## [1] 0.9528005 Literatur "],
["korrelation.html", "Chapter 5 Korrelationsanalyse", " Chapter 5 Korrelationsanalyse "],
["wahrscheinlichkeit.html", "Chapter 6 Grundlagen der Wahrscheinlichkeitsrechnung", " Chapter 6 Grundlagen der Wahrscheinlichkeitsrechnung "],
["verteilungen.html", "Chapter 7 Verteilungen", " Chapter 7 Verteilungen "],
["schaetzen.html", "Chapter 8 Schaetzen von Verteilungsparametern", " Chapter 8 Schaetzen von Verteilungsparametern "],
["ttest.html", "Chapter 9 T-Test", " Chapter 9 T-Test "],
["ftest.html", "Chapter 10 F-Test", " Chapter 10 F-Test "],
["chi2test-kstest.html", "Chapter 11 Chi2- und Kolmogorow-Smirnow-Test", " Chapter 11 Chi2- und Kolmogorow-Smirnow-Test "],
["regression.html", "Chapter 12 Lineare Regression 12.1 Motivation 12.2 Definitionen", " Chapter 12 Lineare Regression 12.1 Motivation Kann man Ihre Reisezeit mit der Entfernung zu Ihrem Wohnort statistisch vorhersagen? (vgl. VL 5) Figure 12.1: Reisezeit in Abh√§ngigkeit zur Entfernung. Korrelationskoeffizient nach Bravais-Pearson r\\(x,y\\)=0,86 Ziel: Eine Gerade durch die Punktwolke zu legen, die den Trend beschreibt, so dass der Abstand der Punkte von der Geraden minimal ist. Es geht um 2 Variablen (Merkmale): die abh√§ngige Variable \\(y\\) (im Bsp. Reisezeit) die unabh√§ngige Variable \\(x\\) (im Bsp. Entfernung) Die Variablen m√ºssen metrisch skaliert sein. Wir wollen das generelle Verhalten von \\(y\\) mit \\(y\\) beschreiben. Eine Gerade ist das einfachste lineare Modell. 12.2 Definitionen Im Falle einer einzigen unabh√§ngigen Variable ist die Gleichung des linearen Models wie folgt: \\[\\begin{equation} y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\tag{12.1} \\end{equation}\\] Mit \\(i\\) = 1,2,‚Ä¶,\\(n\\) \\(y_i\\) Wert der abh√§ngigen Variable f√ºr Datenpunkt \\(i\\) \\(x_i\\) Wert der unabh√§ngigen Variable f√ºr Datenpunkt \\(i\\) \\(\\beta_0\\) Achsenabschnitt der Geraden (ein Parameter) \\(\\beta_1\\) Steigung der Geraden (ein Parameter) \\(\\epsilon_i\\) Residuum (Fehler) f√ºr Datenpunkt \\(i\\) "],
["literatur.html", "Literatur", " Literatur "]
]
